{"meta":{"title":"每天拾柴火","subtitle":"砍柴","description":"纪录一些看到的好文，收藏起来","author":625,"url":"https://kanchai.club","root":"/"},"pages":[{"title":"关于","date":"2014-12-22T04:39:04.000Z","updated":"2020-03-24T12:48:21.267Z","comments":true,"path":"about/index.html","permalink":"https://kanchai.club/about/index.html","excerpt":"","text":"一名菜鸟程序员，渴望力量！坚持从外边砍点柴火！"},{"title":"分类","date":"2020-03-17T15:24:33.000Z","updated":"2020-03-24T12:49:06.102Z","comments":true,"path":"categories/index.html","permalink":"https://kanchai.club/categories/index.html","excerpt":"","text":""},{"title":"搜索","date":"2016-05-24T05:45:13.000Z","updated":"2020-03-24T12:50:39.545Z","comments":true,"path":"search/index.html","permalink":"https://kanchai.club/search/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-03-17T15:25:26.000Z","updated":"2020-03-24T12:49:48.064Z","comments":true,"path":"tags/index.html","permalink":"https://kanchai.club/tags/index.html","excerpt":"","text":""},{"title":"文章","date":"2014-12-22T04:39:04.000Z","updated":"2020-03-25T01:28:04.400Z","comments":true,"path":"archives/index.html","permalink":"https://kanchai.club/archives/index.html","excerpt":"","text":""}],"posts":[{"title":"谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案","slug":"谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案","date":"2020-04-20T02:42:53.764Z","updated":"2020-04-20T02:42:22.000Z","comments":true,"path":"2020/04/20/谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案/","link":"","permalink":"https://kanchai.club/2020/04/20/%E8%B0%88%E8%B0%88%E5%85%B3%E4%BA%8E%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%EF%BC%8C%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%EF%BC%8C%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"","text":"作者：Tom-shushu cnblogs.com/Tom-shushu/p/10636382.html 1.我们使用缓存时的业务流程大概为： 当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能出现下面的一些现象。 2.缓存穿透2.1什么是缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 2.2缓存穿透带来的问题试想一下，如果有黑客对你的系统进行攻击，拿一个不存在的id去查询数据，会产生大量的请求到你的数据库去查询，可能会导致你的数据库由于压力过大而宕掉。 2.3解决的办法2.3.1缓存空值之所以会发生穿透，就是因为缓存中没有储存这些空数据的key。从而导致每次查询都到数据库去了。 那么我们就可以为这些key对应的值设置为null丢到缓存里面去。后面出现查询这个key的请求的时候直接返回null。 这样就不用再到数据库中去走一圈了，但是别忘了设置过期时间。 缓存空对象会有两个问题： 第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 ( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。 2.3.2用布隆过滤器BloomFilterBloomFilter类似于一个hbase set用来判断某个元素(key)是否存在于某个集合中。 这种方式在大数据场景应用比较多，比如Hbase中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url是否已经被爬取过。 这种方案可以加在第一种方案中，在缓存之前加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查缓存——–&gt;差数据库。 流程图如下： 2.4如何选择针对于一些恶意攻击，攻击带来大量key是不存在的，那么我们采用第一种方案就会缓存大量不存在的数据。此时我们采用第一种方案就不合适了，我们完全可以先使用第二种方案过滤掉这些key。 针对这些key异常多，请求多，重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。 而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。 3.缓存击穿3.1什么是缓存击穿缓存击穿是我们使用缓存可能遇到的第二个问题。 在平时高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去，这种现象我们称为缓存击穿。 3.2会带来什么问题会造成某一时刻数据请求量过大，压力剧增。 3.3如何解决上面现象是多个线程同时去查询数据库的这一条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。（如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）） 其他线程走到这一步拿不到锁就等着，等待第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有了缓存，就直接走缓存。 4.缓存雪崩4.1什么是缓存雪崩缓存雪崩的情况是指：当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到数据库上面，结果就是数据库挂掉。 4.2解决办法4.2.1雪崩前：使用集群缓存，保证缓存服务的高可用这种方案就是在发生雪崩前对缓存集群，实现高可用，如果是使用Redis，可以使用（主从 + 哨兵），Redis Cluster来避免Redis全盘崩溃的情况。 4.2.2雪崩中：ehcache本地缓存 + Hystrix限流 &amp; 降级，避免MySQl被打死使用ehcache本地缓存的目的也是考虑Redis Cluster完全不可用的时候，ehcache本地缓存还能够支撑一阵。 使用Hystrix进行限流 &amp; 降级，比如一秒来了5000个请求，我们可以设置假设一秒只能有2000个请求可以通过这个组件，那么其他剩余的3000请求就会走限流逻辑。 然后去调用我们自己开发的降级组件（降级）,比如设置的一些默认值等等之类的。以此来保护最后的MySQl不会被大量的请求打死。 4.2.3雪崩后：开启Redis持久化，尽快恢复缓存集群。5.解决热点数据集中失效问题我们在设置缓存的时候，一般会给缓存设置一个失效的时间，过了这个时间，缓存就失效了。 对于一些热点数据来说，当缓存失效后会存在大量的请求到数据库上来，从而可能导致数据库崩溃的情况。 5.1解决办法5.1.1设置不同的失效时间为了避免这些热点数据集体失效，那么我们在设置缓存过期时间的时侯，让他们失效的时间错开。比如我们可以在原有的失效时间基础上增加一个随机值。 5.1.2互斥锁结合上面的击穿情况，在第一个请求去查询数据库的时候对它加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。 但是也是由于它会阻塞其他线程，此时系统的吞吐量会下降。需要结合实际业务去考虑。","categories":[],"tags":[{"name":"JAVA缓存","slug":"JAVA缓存","permalink":"https://kanchai.club/tags/JAVA%E7%BC%93%E5%AD%98/"}]},{"title":"FFmpeg 视频处理教程！","slug":"FFmpeg_视频处理入门教程","date":"2020-04-01T03:55:50.809Z","updated":"2020-04-01T03:55:50.804Z","comments":true,"path":"2020/04/01/FFmpeg_视频处理入门教程/","link":"","permalink":"https://kanchai.club/2020/04/01/FFmpeg_%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2020年1月14日 FFmpeg 是视频处理最常用的开源软件。 它功能强大，用途广泛，大量用于视频网站和商业软件（比如 Youtube 和 iTunes），也是许多音频和视频格式的标准编码/解码实现。 FFmpeg 本身是一个庞大的项目，包含许多组件和库文件，最常用的是它的命令行工具。本文介绍 FFmpeg 命令行如何处理视频，比桌面视频处理软件更简洁高效。 如果你还没安装，可以根据官方文档 先完成安装。 一、概念介绍 FFmpeg 用法之前，需要了解一些视频处理的基本概念。 1.1 容器视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。 常见的容器格式有以下几种。一般来说，视频文件的后缀名反映了它的容器格式。 MP4 MKV WebM AVI 下面的命令查看 FFmpeg 支持的容器。 $ ffmpeg -formats 1.2 编码格式视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。 常用的视频编码格式如下。 H.262 H.264 H.265 上面的编码格式都是有版权的，但是可以免费使用。此外，还有几种无版权的视频编码格式。 VP8 VP9 AV1 常用的音频编码格式如下。 MP3 AAC 上面所有这些都是有损的编码格式，编码后会损失一些细节，以换取压缩后较小的文件体积。无损的编码格式压缩出来的文件体积较大，这里就不介绍了。 下面的命令可以查看 FFmpeg 支持的编码格式，视频编码和音频编码都在内。 $ ffmpeg -codecs 1.3 编码器编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。 以下是一些 FFmpeg 内置的视频编码器。 libx264：最流行的开源 H.264 编码器 NVENC：基于 NVIDIA GPU 的 H.264 编码器 libx265：开源的 HEVC 编码器 libvpx：谷歌的 VP8 和 VP9 编码器 libaom：AV1 编码器 音频编码器如下。 libfdk-aac aac 下面的命令可以查看 FFmpeg 已安装的编码器。 $ ffmpeg -encoders 二、FFmpeg 的使用格式FFmpeg 的命令行参数非常多，可以分成五个部分。 $ ffmpeg {1} {2} -i {3} {4} {5} 上面命令中，五个部分的参数依次如下。 全局参数 输入文件参数 输入文件 输出文件参数 输出文件 参数太多的时候，为了便于查看，ffmpeg 命令可以写成多行。 $ ffmpeg \\[全局参数] \\[输入文件参数] \\-i [输入文件] \\[输出文件参数] \\[输出文件] 下面是一个例子。 $ ffmpeg \\-y \\ # 全局参数-c:a libfdk_aac -c:v libx264 \\ # 输入文件参数-i input.mp4 \\ # 输入文件-c:v libvpx-vp9 -c:a libvorbis \\ # 输出文件参数output.webm # 输出文件 上面的命令将 mp4 文件转成 webm 文件，这两个都是容器格式。输入的 mp4 文件的音频编码格式是 aac，视频编码格式是 H.264；输出的 webm 文件的视频编码格式是 VP9，音频格式是 Vorbis。 如果不指明编码格式，FFmpeg 会自己判断输入文件的编码。因此，上面的命令可以简单写成下面的样子。 $ ffmpeg -i input.avi output.mp4 三、常用命令行参数FFmpeg 常用的命令行参数如下。 -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。 四、常见用法下面介绍 FFmpeg 几种常见用法。 4.1 查看文件信息查看视频文件的元信息，比如编码格式和比特率，可以只使用-i参数。 $ ffmpeg -i input.mp4 上面命令会输出很多冗余信息，加上-hide_banner参数，可以只显示元信息。 $ ffmpeg -i input.mp4 -hide_banner 4.2 转换编码格式转换编码格式（transcoding）指的是， 将视频文件从一种编码转成另一种编码。比如转成 H.264 编码，一般使用编码器libx264，所以只需指定输出文件的视频编码器即可。 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 下面是转成 H.265 编码的写法。 $ ffmpeg -i [input.file] -c:v libx265 output.mp4 4.3 转换容器格式转换容器格式（transmuxing）指的是，将视频文件从一种容器转到另一种容器。下面是 mp4 转 webm 的写法。 $ ffmpeg -i input.mp4 -c copy output.webm 上面例子中，只是转一下容器，内部的编码格式不变，所以使用-c copy指定直接拷贝，不经过转码，这样比较快。 4.4 调整码率调整码率（transrating）指的是，改变编码的比特率，一般用来将视频文件的体积变小。下面的例子指定码率最小为964K，最大为3856K，缓冲区大小为 2000K。 $ ffmpeg \\-i input.mp4 \\-minrate 964K -maxrate 3856K -bufsize 2000K output.mp4 4.5 改变分辨率（transsizing）下面是改变视频分辨率（transsizing）的例子，从 1080p 转为 480p 。 $ ffmpeg \\-i input.mp4 \\-vf scale=480:-1 output.mp4 4.6 提取音频有时，需要从视频里面提取音频（demuxing），可以像下面这样写。 $ ffmpeg \\-i input.mp4 \\-vn -c:a copy output.aac 上面例子中，-vn表示去掉视频，-c:a copy表示不改变音频编码，直接拷贝。 4.7 添加音轨添加音轨（muxing）指的是，将外部音频加入视频，比如添加背景音乐或旁白。 $ ffmpeg \\-i input.aac -i input.mp4 output.mp4 上面例子中，有音频和视频两个输入文件，FFmpeg 会将它们合成为一个文件。 4.8 截图下面的例子是从指定时间开始，连续对1秒钟的视频进行截图。 $ ffmpeg \\-y \\-i input.mp4 \\-ss 00:01:24 -t 00:00:01 output_%3d.jpg 如果只需要截一张图，可以指定只截取一帧。 $ ffmpeg \\-ss 01:23:45 \\-i input \\-vframes 1 -q:v 2 output.jpg 上面例子中，-vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。 4.9 裁剪裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output]$ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 下面是实际的例子。 $ ffmpeg -ss 00:01:50 -i [input] -t 10.5 -c copy [output]$ ffmpeg -ss 2.5 -i [input] -to 10 -c copy [output] 上面例子中，-c copy表示不改变音频和视频的编码格式，直接拷贝，这样会快很多。 4.10 为音频添加封面有些视频网站只允许上传视频文件。如果要上传音频文件，必须为音频添加封面，将其转为视频，然后上传。 下面命令可以将音频文件，转为带封面的视频文件。 $ ffmpeg \\-loop 1 \\-i cover.jpg -i input.mp3 \\-c:v libx264 -c:a aac -b:a 192k -shortest output.mp4 上面命令中，有两个输入文件，一个是封面图片cover.jpg，另一个是音频文件input.mp3。-loop 1参数表示图片无限循环，-shortest参数表示音频文件结束，输出视频就结束。 五、参考链接 FFmpeg libav tutorial Digital video introduction FFmpeg encoding and editing course Making Slideshows w/FFMpeg The Complete Guide for Using ffmpeg in Linux （完）","categories":[],"tags":[{"name":"视频处理","slug":"视频处理","permalink":"https://kanchai.club/tags/%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86/"}]},{"title":"GitHub 敏捷开发入门教程","slug":"敏捷开发入门教程","date":"2020-04-01T03:53:11.702Z","updated":"2020-04-01T03:51:42.000Z","comments":true,"path":"2020/04/01/敏捷开发入门教程/","link":"","permalink":"https://kanchai.club/2020/04/01/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2019年3月 6日 敏捷开发（agile development）是非常流行的软件开发方法。据统计，2018年90%的软件开发采用敏捷开发。 但是，到底什么是敏捷开发，能说清的人却不多。本文尝试用简洁易懂的语言，解释敏捷开发。 一、迭代开发敏捷开发的核心是迭代开发（iterative development）。敏捷一定是采用迭代开发的方式。 那么什么是”迭代开发”呢？迭代的英文是 iterative，直译为”重复”，迭代开发其实就是”重复开发”。 对于大型软件项目，传统的开发方式是采用一个大周期（比如一年）进行开发，整个过程就是一次”大开发”；迭代开发的方式则不一样，它将开发过程拆分成多个小周期，即一次”大开发”变成多次”小开发”，每次小开发都是同样的流程，所以看上去就好像重复在做同样的步骤。 举例来说，SpaceX 公司想造一个大推力火箭，将人类送到火星。但是，它不是一开始就造大火箭，而是先造一个最简陋的小火箭 Falcon 1。结果，第一次发射就爆炸了，直到第四次发射，才成功进入轨道。然后，开发了中型火箭 Falcon 9，九年中发射了70次。最后，才开发 Falcon 重型火箭。如果 SpaceX 不采用迭代开发，它可能直到现在还无法上天。 迭代开发将一个大任务，分解成多次连续的开发，本质就是逐步改进。开发者先快速发布一个有效但不完美的最简版本，然后不断迭代。每一次迭代都包含规划、设计、编码、测试、评估五个步骤，不断改进产品，添加新功能。通过频繁的发布，以及跟踪对前一次迭代的反馈，最终接近较完善的产品形态。 二、增量开发迭代开发只是要求将开发分成多个迭代，并没有回答一个重要的问题：怎么划分迭代，哪个任务在这个迭代，哪个任务在下个迭代？这时，一般采用”增量开发”（incremental development）划分迭代。 所谓”增量开发”，指的是软件的每个版本，都会新增一个用户可以感知的完整功能。也就是说，按照新增功能来划分迭代。 举例来说，房产公司开发一个10栋楼的小区。如果采用增量开发的模式，该公司第一个迭代就是交付一号楼，第二个迭代交付二号楼……每个迭代都是完成一栋完整的楼。而不是第一个迭代挖好10栋楼的地基，第二个迭代建好每栋楼的骨架，第三个迭代架设屋顶…… 增量开发加上迭代开发，才算真正的敏捷开发。 三、敏捷开发的好处3.1 早期交付敏捷开发的第一个好处，就是早期交付，从而大大降低成本。 还是以上一节的房产公司为例，如果按照传统的”瀑布开发模式”，先挖10栋楼的地基、再盖骨架、然后架设屋顶，每个阶段都等到前一个阶段完成后开始，可能需要两年才能一次性交付10栋楼。也就是说，如果不考虑预售，该项目必须等到两年后才能回款。 敏捷开发是六个月后交付一号楼，后面每两个月交付一栋楼。因此，半年就能回款10%，后面每个月都会有现金流，资金压力就大大减轻了。 3.2 降低风险敏捷开发的第二个好处是，及时了解市场需求，降低产品不适用的风险。 请想一想，哪一种情况损失比较小：10栋楼都造好以后，才发现卖不出去，还是造好第一栋楼，就发现卖不出去，从而改进或停建后面9栋楼？ 对于软件项目来说，先有一个原型产品，了解市场的接受程度，往往是项目成功的关键。有一本书叫做《梦断代码》，副标题就是”20+个程序员，三年时间，4732个bug，100+万美元，最后失败的故事”，这就是没有采用敏捷开发的结果。相反的，Instagram 最初是一个地理位置打卡 App，后来发现用户不怎么在乎地理位置，更喜欢上传照片，就改做照片上传软件，结果成了独角兽。 由于敏捷开发可以不断试错，找出对业务最重要的功能，然后通过迭代，调整软件方向。相比传统方式，大大增加了产品成功的可能性。如果市场需求不确定，或者你对该领域不熟悉，那么敏捷开发几乎是唯一可行的应对方式。 四、如何进行每一次迭代虽然敏捷开发将软件开发分成多个迭代，但是也要求，每次迭代都是一个完整的软件开发周期，必须按照软件工程的方法论，进行正规的流程管理。 具体来说，每次迭代都必须依次完成以下五个步骤。 需求分析（requirements analysis） 设计（design） 编码（coding） 测试（testing） 部署和评估（deployment / evaluation） 每个迭代大约持续2~6周。 五、敏捷开发的价值观《敏捷软件开发宣言》里面提到四个价值观。 程序员的主观能动性，以及程序员之间的互动，优于既定流程和工具。 软件能够运行，优于详尽的文档。 跟客户的密切协作，优于合同和谈判。 能够响应变化，优于遵循计划。 六、十二条原则该宣言还提出十二条敏捷开发的原则。 通过早期和持续交付有价值的软件，实现客户满意度。 欢迎不断变化的需求，即使是在项目开发的后期。要善于利用需求变更，帮助客户获得竞争优势。 不断交付可用的软件，周期通常是几周，越短越好。 项目过程中，业务人员与开发人员必须在一起工作。 项目必须围绕那些有内在动力的个人而建立，他们应该受到信任。 面对面交谈是最好的沟通方式。 可用性是衡量进度的主要指标。 提倡可持续的开发，保持稳定的进展速度。 不断关注技术是否优秀，设计是否良好。 简单性至关重要，尽最大可能减少不必要的工作。 最好的架构、要求和设计，来自团队内部自发的认识。 团队要定期反思如何更有效，并相应地进行调整。 七、参考链接 Iterative development: the secret to great product launches, Pavlo Zinchenko Agile software development, Wikipedia","categories":[],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"https://kanchai.club/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"OAuth 2.0 的四种方式！","slug":"OAuth_2.0_的四种方式","date":"2020-04-01T03:34:33.238Z","updated":"2020-04-01T03:31:54.000Z","comments":true,"path":"2020/04/01/OAuth_2.0_的四种方式/","link":"","permalink":"https://kanchai.club/2020/04/01/OAuth_2.0_%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月 9日 上一篇文章介绍了 OAuth 2.0 是一种授权机制，主要用来颁发令牌（token）。本文接着介绍颁发令牌的实务操作。 下面我假定，你已经理解了 OAuth 2.0 的含义和设计思想，否则请先阅读这个系列的上一篇文章。 进入正文之前，插播一则活动消息。 4月22日（周一）到4月29日（下周一），每天晚上八点都有两小时的免费直播课，体系化介绍高级前端开发知识，网易云课堂主办。详细介绍请看本文结尾，欢迎关注。 RFC 6749OAuth 2.0 的标准是 RFC 6749 文件。该文件先解释了 OAuth 是什么。 OAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。……资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。 这段话的意思就是，OAuth 的核心就是向第三方应用颁发令牌。然后，RFC 6749 接着写道： （由于互联网有多种场景，）本标准定义了获得令牌的四种授权方式（authorization grant ）。 也就是说，OAuth 2.0 规定了四种获得令牌的流程。你可以选择最适合自己的那一种，向第三方应用颁发令牌。下面就是这四种授权方式。 授权码（authorization-code） 隐藏式（implicit） 密码式（password）： 客户端凭证（client credentials） 注意，不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 第一种授权方式：授权码授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。 这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。 第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 https://b.com/oauth/authorize? response_type=code&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 上面 URL 中，response_type参数表示要求返回授权码（code），client_id参数让 B 知道是谁在请求，redirect_uri参数是 B 接受或拒绝请求后的跳转网址，scope参数表示要求的授权范围（这里是只读）。 第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回redirect_uri参数指定的网址。跳转时，会传回一个授权码，就像下面这样。 https://a.com/callback?code=AUTHORIZATION_CODE 上面 URL 中，code参数就是授权码。 第三步，A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。 https://b.com/oauth/token? client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; grant_type=authorization_code&amp; code=AUTHORIZATION_CODE&amp; redirect_uri=CALLBACK_URL 上面 URL 中，client_id参数和client_secret参数用来让 B 确认 A 的身份（client_secret参数是保密的，因此只能在后端发请求），grant_type参数的值是AUTHORIZATION_CODE，表示采用的授权方式是授权码，code参数是上一步拿到的授权码，redirect_uri参数是令牌颁发后的回调网址。 第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向redirect_uri指定的网址，发送一段 JSON 数据。 { “access_token”:”ACCESS_TOKEN”, “token_type”:”bearer”, “expires_in”:2592000, “refresh_token”:”REFRESH_TOKEN”, “scope”:”read”, “uid”:100101, “info”:{…}} 上面 JSON 数据中，access_token字段就是令牌，A 网站在后端拿到了。 第二种方式：隐藏式有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端。RFC 6749 就规定了第二种方式，允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）”隐藏式”（implicit）。 第一步，A 网站提供一个链接，要求用户跳转到 B 网站，授权用户数据给 A 网站使用。 https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 上面 URL 中，response_type参数为token，表示要求直接返回令牌。 第二步，用户跳转到 B 网站，登录后同意给予 A 网站授权。这时，B 网站就会跳回redirect_uri参数指定的跳转网址，并且把令牌作为 URL 参数，传给 A 网站。 https://a.com/callback#token=ACCESS_TOKEN 上面 URL 中，token参数就是令牌，A 网站因此直接在前端拿到令牌。 注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在”中间人攻击”的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。 这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。 第三种方式：密码式如果你高度信任某个应用，RFC 6749 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为”密码式”（password）。 第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。 https://oauth.b.com/token? grant_type=password&amp; username=USERNAME&amp; password=PASSWORD&amp; client_id=CLIENT_ID 上面 URL 中，grant_type参数是授权方式，这里的password表示”密码式”，username和password是 B 的用户名和密码。 第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。 这种方式需要用户给出自己的用户名/密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。 第四种方式：凭证式最后一种方式是凭证式（client credentials），适用于没有前端的命令行应用，即在命令行下请求令牌。 第一步，A 应用在命令行向 B 发出请求。 https://oauth.b.com/token? grant_type=client_credentials&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET 上面 URL 中，grant_type参数等于client_credentials表示采用凭证式，client_id和client_secret用来让 B 确认 A 的身份。 第二步，B 网站验证通过以后，直接返回令牌。 这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。 令牌的使用A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。 此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个Authorization字段，令牌就放在这个字段里面。 curl -H “Authorization: Bearer ACCESS_TOKEN” \\“https://api.b.com&quot; 上面命令中，ACCESS_TOKEN就是拿到的令牌。 更新令牌令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。 具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh token 字段）。令牌到期前，用户使用 refresh token 发一个请求，去更新令牌。 https://b.com/oauth/token? grant_type=refresh_token&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; refresh_token=REFRESH_TOKEN 上面 URL 中，grant_type参数为refresh_token表示要求更新令牌，client_id参数和client_secret参数用于确认身份，refresh_token参数就是用于更新令牌的令牌。 B 网站验证通过以后，就会颁发新的令牌。 写到这里，颁发令牌的四种方式就介绍完了。下一篇文章会编写一个真实的 Demo，演示如何通过 OAuth 2.0 向 GitHub 的 API 申请令牌，然后再用令牌获取数据。","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"GitHub 第三方登录示例教程！","slug":"GitHub_OAuth_第三方登录示例教程","date":"2020-04-01T03:34:33.147Z","updated":"2020-04-01T03:34:04.000Z","comments":true,"path":"2020/04/01/GitHub_OAuth_第三方登录示例教程/","link":"","permalink":"https://kanchai.club/2020/04/01/GitHub_OAuth_%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95%E7%A4%BA%E4%BE%8B%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月21日 这组 OAuth 系列教程，第一篇介绍了基本概念，第二篇介绍了获取令牌的四种方式，今天演示一个实例，如何通过 OAuth 获取 API 数据。 很多网站登录时，允许使用第三方网站的身份，这称为”第三方登录”。 下面就以 GitHub 为例，写一个最简单的应用，演示第三方登录。 一、第三方登录的原理所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。 举例来说，A 网站允许 GitHub 登录，背后就是下面的流程。 A 网站让用户跳转到 GitHub。 GitHub 要求用户登录，然后询问”A 网站要求获得 xx 权限，你是否同意？” 用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。 A 网站使用授权码，向 GitHub 请求令牌。 GitHub 返回令牌. A 网站使用令牌，向 GitHub 请求用户数据。 下面就是这个流程的代码实现。 二、应用登记一个应用要求 OAuth 授权，必须先到对方网站登记，让对方知道是谁在请求。 所以，你要先去 GitHub 登记一下。当然，我已经登记过了，你使用我的登记信息也可以，但为了完整走一遍流程，还是建议大家自己登记。这是免费的。 访问这个网址，填写登记表。 应用的名称随便填，主页 URL 填写http://localhost:8080，跳转网址填写 http://localhost:8080/oauth/redirect。 提交表单以后，GitHub 应该会返回客户端 ID（client ID）和客户端密钥（client secret），这就是应用的身份识别码。 三、示例仓库我写了一个代码仓库，请将它克隆到本地。 $ git clone git@github.com:ruanyf/node-oauth-demo.git$ cd node-oauth-demo 两个配置项要改一下，写入上一步的身份识别码。 index.js：改掉变量clientID and clientSecret public/index.html：改掉变量client_id 然后，安装依赖。 $ npm install 启动服务。 $ node index.js 浏览器访问http://localhost:8080，就可以看到这个示例了。 四、浏览器跳转 GitHub示例的首页很简单，就是一个链接，让用户跳转到 GitHub。 跳转的 URL 如下。 https://github.com/login/oauth/authorize? client_id=7e015d8ce32370079895&amp; redirect_uri=http://localhost:8080/oauth/redirect 这个 URL 指向 GitHub 的 OAuth 授权网址，带有两个参数：client_id告诉 GitHub 谁在请求，redirect_uri是稍后跳转回来的网址。 用户点击到了 GitHub，GitHub 会要求用户登录，确保是本人在操作。 五、授权码登录后，GitHub 询问用户，该应用正在请求数据，你是否同意授权。 用户同意授权， GitHub 就会跳转到redirect_uri指定的跳转网址，并且带上授权码，跳转回来的 URL 就是下面的样子。 http://localhost:8080/oauth/redirect? code=859310e7cecc9196f4af 后端收到这个请求以后，就拿到了授权码（code参数）。 六、后端实现示例的后端采用 Koa 框架编写，具体语法请看教程。 这里的关键是针对/oauth/redirect的请求，编写一个路由，完成 OAuth 认证。 const oauth = async ctx =&gt; { // …};app.use(route.get(‘/oauth/redirect’, oauth)); 上面代码中，oauth函数就是路由的处理函数。下面的代码都写在这个函数里面。 路由函数的第一件事，是从 URL 取出授权码。 const requestToken = ctx.request.query.code; 七、令牌后端使用这个授权码，向 GitHub 请求令牌。 const tokenResponse = await axios({ method: ‘post’, url: ‘https://github.com/login/oauth/access_token?&#39; + `client_id=${clientID}&amp;` + `client_secret=${clientSecret}&amp;` + `code=${requestToken}`, headers: { accept: ‘application/json’ }}); 上面代码中，GitHub 的令牌接口https://github.com/login/oauth/access_token需要提供三个参数。 client_id：客户端的 ID client_secret：客户端的密钥 code：授权码 作为回应，GitHub 会返回一段 JSON 数据，里面包含了令牌accessToken。 const accessToken = tokenResponse.data.access_token; 八、API 数据有了令牌以后，就可以向 API 请求数据了。 const result = await axios({ method: ‘get’, url: `https://api.github.com/user\\`, headers: { accept: ‘application/json’, Authorization: `token ${accessToken}` }}); 上面代码中，GitHub API 的地址是https://api.github.com/user，请求的时候必须在 HTTP 头信息里面带上令牌Authorization: token 361507da。 然后，就可以拿到用户数据，得到用户的身份。 const name = result.data.name;ctx.response.redirect(/welcome.html?name=${name}); （完）","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"OAuth 2.0 的一个简单解释！","slug":"OAuth_2.0_的一个简单解释","date":"2020-04-01T03:27:48.218Z","updated":"2020-04-01T03:26:59.000Z","comments":true,"path":"2020/04/01/OAuth_2.0_的一个简单解释/","link":"","permalink":"https://kanchai.club/2020/04/01/OAuth_2.0_%E7%9A%84%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E8%A7%A3%E9%87%8A/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月 4日 OAuth 2.0 是目前最流行的授权机制，用来授权第三方应用，获取用户数据。 这个标准比较抽象，使用了很多术语，初学者不容易理解。其实说起来并不复杂，下面我就通过一个简单的类比，帮助大家轻松理解，OAuth 2.0 到底是什么。 一、快递员问题我住在一个大型的居民小区。 小区有门禁系统。 进入的时候需要输入密码。 我经常网购和外卖，每天都有快递员来送货。我必须找到一个办法，让快递员通过门禁系统，进入小区。 如果我把自己的密码，告诉快递员，他就拥有了与我同样的权限，这样好像不太合适。万一我想取消他进入小区的权力，也很麻烦，我自己的密码也得跟着改了，还得通知其他的快递员。 有没有一种办法，让快递员能够自由进入小区，又不必知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？ 二、授权机制的设计于是，我设计了一套授权机制。 第一步，门禁系统的密码输入器下面，增加一个按钮，叫做”获取授权”。快递员需要首先按这个按钮，去申请授权。 第二步，他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。 我确认请求属实，就点击按钮，告诉门禁系统，我同意给予他进入小区的授权。 第三步，门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。 第四步，快递员向门禁系统输入令牌，进入小区。 有人可能会问，为什么不是远程为快递员开门，而要为他单独生成一个令牌？这是因为快递员可能每天都会来送货，第二天他还可以复用这个令牌。另外，有的小区有多重门禁，快递员可以使用同一个令牌通过它们。 三、互联网场景我们把上面的例子搬到互联网，就是 OAuth 的设计了。 首先，居民小区就是储存用户数据的网络服务。比如，微信储存了我的好友信息，获取这些信息，就必须经过微信的”门禁系统”。 其次，快递员（或者说快递公司）就是第三方应用，想要穿过门禁系统，进入小区。 最后，我就是用户本人，同意授权第三方应用进入小区，获取我的数据。 简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。 四、令牌与密码令牌（token）与密码（password）的作用是一样的，都可以进入系统，但是有三点差异。 （1）令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。 （2）令牌可以被数据所有者撤销，会立即失效。以上例而言，屋主可以随时取消快递员的令牌。密码一般不允许被他人撤销。 （3）令牌有权限范围（scope），比如只能进小区的二号门。对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。 上面这些设计，保证了令牌既可以让第三方应用获得权限，同时又随时可控，不会危及系统安全。这就是 OAuth 2.0 的优点。 注意，只要知道了令牌，就能进入系统。系统一般不会再次确认身份，所以令牌必须保密，泄漏令牌与泄漏密码的后果是一样的。 这也是为什么令牌的有效期，一般都设置得很短的原因。 OAuth 2.0 对于如何颁发令牌的细节，规定得非常详细。具体来说，一共分成四种授权类型（authorization grant），即四种颁发令牌的方式，适用于不同的互联网场景。下一篇文章，我就来介绍这四种类型，并给出代码实例。 （完） 文档信息 版权声明：自由转载-非商用-非衍生-保持署名（创意共享3.0许可证） 发表日期： 2019年4月 4日","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"【57期】面试官问，MySQL建索引需要遵循哪些原则呢？","slug":"【57期】面试官问，MySQL建索引需要遵循哪些原则呢？","date":"2020-03-25T03:41:06.399Z","updated":"2020-03-25T03:35:40.000Z","comments":true,"path":"2020/03/25/【57期】面试官问，MySQL建索引需要遵循哪些原则呢？/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9057%E6%9C%9F%E3%80%91%E9%9D%A2%E8%AF%95%E5%AE%98%E9%97%AE%EF%BC%8CMySQL%E5%BB%BA%E7%B4%A2%E5%BC%95%E9%9C%80%E8%A6%81%E9%81%B5%E5%BE%AA%E5%93%AA%E4%BA%9B%E5%8E%9F%E5%88%99%E5%91%A2%EF%BC%9F/","excerpt":"","text":"1.选择唯一性索引唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。 2.为经常需要排序、分组和联合操作的字段建立索引经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。 3.为常作为查询条件的字段建立索引如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 4.限制索引的数目索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。 5.尽量使用数据量少的索引如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。 6.尽量使用前缀来索引如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 7.删除不再使用或者很少使用的索引表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 8.最左前缀匹配原则，非常重要的原则。mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a 1=”” and=”” b=”2” c=”“&gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 9.=和in可以乱序。比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 10.尽量选择区分度高的列作为索引。区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就 是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条 记录 11.索引列不能参与计算，保持列“干净”。比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本 太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 12.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 注意：选择索引的最终目的是为了使查询的速度变快。上面给出的原则是最基本的准则，但不能拘泥于上面的准则。读者要在以后的学习和工作中进行不断的实践。根据应用的实际情况进行分析和判断，选择最合适的索引方式。## 目标 去除 iconfinder 上 icon 的水印 原理利用水印像素点和原图像素点颜色合并的原理，如果拥有加过水印的图片和水印图片，就可以反向推出原图原像素点的颜色；前提是你得拥有他的水印图片 来源：https://blog.csdn.net/u013412790/","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"【63期】谈谈MySQL 索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）","slug":"【63期】谈谈MySQL_索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）","date":"2020-03-25T03:41:04.566Z","updated":"2020-03-25T03:34:51.000Z","comments":true,"path":"2020/03/25/【63期】谈谈MySQL_索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9063%E6%9C%9F%E3%80%91%E8%B0%88%E8%B0%88MySQL_%E7%B4%A2%E5%BC%95%EF%BC%8CB+%E6%A0%91%E5%8E%9F%E7%90%86%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E5%87%A0%E5%A4%A7%E5%8E%9F%E5%88%99%EF%BC%88MySQL%E9%9D%A2%E8%AF%95%E7%AC%AC%E5%85%AD%E5%BC%B9%EF%BC%89/","excerpt":"","text":"MYSQL一直了解得都不多，之前写sql准备提交生产环境之前的时候，老员工帮我检查了下sql，让修改了一下存储引擎，当时我使用的是Myisam，后面改成InnoDB了。为什么要改成这样，之前都没有听过存储引擎，于是网上查了一下。 事实上使用不同的存储引擎也是有很大区别的，下面猿友们可以了解一下。 一、存储引擎的比较 注：上面提到的B树索引并没有指出是B-Tree和B+Tree索引，但是B-树和B+树的定义是有区别的。 在 MySQL 中，主要有四种类型的索引，分别为：B-Tree 索引， Hash 索引， Fulltext 索引和 R-Tree 索引。 B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B-Tree 索引。Archive 引擎直到 MySQL 5.1 才支持索引，而且只支持索引单个 AUTO_INCREMENT 列。 不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中B-Tree 索引也同样是作为最主要的索引类型，这主要是因为 B-Tree 索引的存储结构在数据库的数据检索中有非常优异的表现。 一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node(叶子节点) ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引。 当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息（增加了顺序访问指针），这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。 InnoDB是Mysql的默认存储引擎(Mysql5.5.5之前是MyISAM） 可能对于没有了解过索引的猿友这样看这篇文章十分吃力，这类猿友有必要先对Mysql索引有个大体的了解。 接下来我们先看看B-树、B+树的概念。弄清楚，为什么加了索引查询速度会加快？ 二、B-树、B+树概念B树即二叉搜索树： 所有非叶子结点至多拥有两个儿子（Left和Right）； 所有结点存储一个关键字； 非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； 如： B-树是一种多路搜索树（并不是二叉的）： 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； 如：（M=3） B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点； B-树的特性： 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； 由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少利用率。 所以B-树的性能总是等价于二分查找（与M值无关），也就没有B树平衡的问题； 由于M/2的限制，在插入结点时，如果结点已满，需要将结点分裂为两个各占M/2的结点；删除结点时，需将两个不足M/2的兄弟结点合并； B+树B+树是B-树的变体，也是一种多路搜索树： 其定义基本与B-树同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； 如：（M=3） B+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的特性： 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 更适合文件索引系统； 三、建索引的几大原则1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 3.尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 来源：blog.csdn.net/u013142781/article/details/51706790","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"【58期】盘点那些面试中最常问的MySQL问题，第一弹！","slug":"【58期】盘点那些面试中最常问的MySQL问题，第一弹！","date":"2020-03-25T03:41:02.744Z","updated":"2020-03-25T03:40:05.000Z","comments":true,"path":"2020/03/25/【58期】盘点那些面试中最常问的MySQL问题，第一弹！/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9058%E6%9C%9F%E3%80%91%E7%9B%98%E7%82%B9%E9%82%A3%E4%BA%9B%E9%9D%A2%E8%AF%95%E4%B8%AD%E6%9C%80%E5%B8%B8%E9%97%AE%E7%9A%84MySQL%E9%97%AE%E9%A2%98%EF%BC%8C%E7%AC%AC%E4%B8%80%E5%BC%B9%EF%BC%81/","excerpt":"","text":"1、MySQL中myisam与innodb的区别 MyISAM： 不支持事务，但是每次查询都是原子的； 支持表级锁，即每次操作对整个表加锁； 存储表的总行数； 一个MYISAM表有三个文件：索引文件、表结构文件、数据文件； 采用非聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。 InnoDb： 支持ACID的事务，支持事务的四种隔离级别； 支持行级锁及外键约束：因此可以支持写并发； 不存储总行数； 一个InnoDb引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制； 主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。 两者的适用场景： 因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原子性要求低。那么MyISAM最好的选择。且MyISAM恢复速度快。可直接用备份覆盖恢复。 如果系统读少，写多的时候，尤其是并发写入高的时候。InnoDB就是首选了。 扩展问题：myisam与innodb引擎下select count(*)哪个更快，为什么？ 知道的童鞋，欢迎留言说出正确答案~ 2、MySQL INT和CHAR隐式类型转换需要注意什么？ 主要需要记住下面两点： 1、当查询字段是INT类型，如果查询条件为CHAR，将查询条件转换为INT，如果是字符串前导都是数字，将截取前导数字用来比较，如果没有前导数字，则转换为0。 2.、当查询字段是CHAR/VARCHAR类型，如果查询条件为INT，将查询字段转换为INT再进行比较，可能会造成全表扫描。 答案解析 有如下一张测试表product，id为int类型，name为varchar类型。 +----+----------+| id | name |+----+----------+| 1 | apple || 2 | banana || 3 | 99cat |+----+----------+ 情况1: // 查询条件转化为数字1再比较mysql&gt; select * from product where id = &#39;1abc23&#39;;+----+---------+| id | name |+----+---------+| 1 | apple |+----+---------+ 情况2: // 查询字段全部转化成数字，id:1和id:2字段值转化为0，id:3转化成99，再比较mysql&gt; select * from product where name=0;+----+----------+| id | name |+----+----------+| 1 | apple || 2 | banana |+----+----------+ 3、MySQL 如何高效率随机获取N条数据？ 假设表叫做mm_account。 ID连续的情况下（注意不能带where，否则结果不好）： SELECT *FROM `mm_account` AS t1 JOIN (SELECT ROUND(RAND() * (SELECT MAX(id) FROM `mm_account`)) AS id) AS t2WHERE t1.id &gt;= t2.idORDER BY t1.id ASC LIMIT 4; ID不连续的情况下： SELECT * FROM `mm_account` WHERE id &gt;= (SELECT floor(RAND() * (SELECT MAX(id) FROM `mm_account`))) and city=&quot;city_91&quot; and showSex=1ORDER BY id LIMIT 4; 如果有一个字段叫id，最快的方法如下（随机获取5条）： SELECT * FROM mm_account WHERE id &gt;= ((SELECT MAX(id) FROM mm_account)-(SELECT MIN(id) FROM mm_account)) * RAND() + (SELECT MIN(id) FROM mm_account)limit 5; 如果带where语句，上面就不适合了，带where语句请看下面： SELECT *FROM `mm_account` AS t1 JOIN (SELECT ROUND(RAND() * ((SELECT MAX(id) FROM `mm_account` where id&lt;1000 )-(SELECT MIN(id) FROM `mm_account` where id&lt;1000 ))+(SELECT MIN(id) FROM `mm_account` where id&lt;1000 )) AS id) AS t2WHERE t1.id &gt;= t2.idORDER BY t1.id LIMIT 5; 4、说说你知道的MySQL的索引类型，并分别简述一下各自的场景。 普通索引：没有任何限制条件的索引，该索引可以在任何数据类型中创建。 唯一索引：使用UNIQUE参数可以设置唯一索引。创建该索引时，索引列的值必须唯一，但允许有空值。通过唯一索引，用户可以快速地定位某条记录，主键索引是一种特殊的唯一索引。 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引耗时耗空间。 空间索引：只能建立在空间数据类型上。这样可以提高系统获取空间数据类型的效率。仅可用于 MyISAM 表，索引的字段不能为空值。使用SPATIAL参数可以设置索引为空间索引。 单列索引：只对应一个字段的索引。 多列索引：在表的多个字段上创建一个索引。该索引指向创建时对应的多个字段，用户可以通过这几个字段进行查询，想使用该索引，用户必须使用这些字段中的一个字段。","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"POI-Excel的导出导入","slug":"excel","date":"2020-03-17T15:36:46.688Z","updated":"2020-03-17T15:33:59.000Z","comments":true,"path":"2020/03/17/excel/","link":"","permalink":"https://kanchai.club/2020/03/17/excel/","excerpt":"","text":"excel-poimaven使用方式123456&lt;!-- excel导入导出 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.stupdit1t&lt;/groupId&gt; &lt;artifactId&gt;poi-excel&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt;&lt;/dependency&gt; 前言 本工程并没有使用注解方式实现，完全是编码方式。个人觉得注解方式对代码侵入比较大。不如纯编码方便，请以maven版本为主，此源码可能不是最新版本。环境为，POI4.0.1 ，JDK1.8 导入 支持严格的单元格校验 支持数据行的图片导入 3支持数据回调处理 03和07都支持 导出 动态表头+表尾 支持List数据 支持图片导出， 支持复杂对象的导出 支持回调处理数据后再导出 支持单元格的样式设置 支持模板导出 导出03和07都支持，默认为03，具体看以下使用方式 支持多sheet导出 选择03还是07？ 03速度较快，单sheet最大65535行，体积大 07速度慢，单sheet最大1048576行，体积小 主要功能：导入1.简单的导入: 1234567891011121314// 1.获取源文件Workbook wb = WorkbookFactory.create(new FileInputStream(\"src\\\\test\\\\java\\\\excel\\\\imports\\\\import.xlsx\"));// 2.获取sheet0导入Sheet sheet = wb.getSheetAt(0);// 3.生成VO数据//参数：1.生成VO的class类型;2.校验规则;3.导入的sheet;3.从第几行导入;4.尾部非数据行数量ImportRspInfo&lt;ProjectEvaluate&gt; list = ExcelUtils.parseSheet(ProjectEvaluate.class, EvaluateVerifyBuilder.getInstance(), sheet, 3, 2);if (list.isSuccess()) &#123; // 导入没有错误，打印数据 System.out.println(JSON.toJSONString(list.getData()));&#125; else &#123; // 导入有错误，打印输出错误 System.out.println(list.getMessage());&#125; 2.复杂导入，带图片导入，带回调处理 1234567891011121314151617181920212223// 1.获取源文件Workbook wb = WorkbookFactory.create(new FileInputStream(\"src\\\\test\\\\java\\\\excel\\\\imports\\\\import.xlsx\"));// 2.获取sheet0导入Sheet sheet = wb.getSheetAt(0);// 3.生成VO数据//参数：1.生成VO的class类型;2.校验规则;3.导入的sheet;3.从第几行导入;4.尾部非数据行数量;5.导入每条数据的回调ImportRspInfo&lt;ProjectEvaluate&gt; list = ExcelUtils.parseSheet(ProjectEvaluate.class, ProjectVerifyBuilder.getInstance(), sheet, 3, 2, (row, rowNum) -&gt; &#123; //1.此处可以完成更多的校验 if(row.getAreaName() == \"中青旅\")&#123; throw new POIException(\"第\"+rowNum+\"行，区域名字不能为中青旅！\"); &#125; //2.图片导入，再ProjectEvaluate定义类型为byte[]的属性就可以，ProjectVerifyBuilder定义ImgVerfiy校验列.就OK了&#125;);if (list.isSuccess()) &#123; // 导入没有错误，打印数据 System.out.println(JSON.toJSONString(list.getData())); //打印图片byte数组长度 byte[] img = list.getData().get(0).getImg(); System.out.println(img);&#125; else &#123; // 导入有错误，打印输出错误 System.out.println(list.getMessage());&#125; 3.自定义校验器，导入需要校验字段,必须继承AbstractVerifyBuidler 1234567891011121314151617181920212223242526public class ProjectVerifyBuilder extends AbstractVerifyBuidler &#123; private static ProjectVerifyBuilder builder = new ProjectVerifyBuilder(); public static ProjectVerifyBuilder getInstance() &#123; return builder; &#125; /** * 定义列校验实体：提取的字段、提取列、校验规则 */ private ProjectVerifyBuilder() &#123; cellEntitys.add(new CellVerifyEntity(\"projectName\", \"B\", new StringVerify(\"项目名称\", true))); cellEntitys.add(new CellVerifyEntity(\"areaName\", \"C\", new StringVerify(\"所属区域\", true))); cellEntitys.add(new CellVerifyEntity(\"province\", \"D\", new StringVerify(\"省份\", true))); cellEntitys.add(new CellVerifyEntity(\"city\", \"E\", new StringVerify(\"市\", true))); cellEntitys.add(new CellVerifyEntity(\"people\", \"F\", new StringVerify(\"项目所属人\", true))); cellEntitys.add(new CellVerifyEntity(\"leader\", \"G\", new StringVerify(\"项目领导人\", true))); cellEntitys.add(new CellVerifyEntity(\"scount\", \"H\", new IntegerVerify(\"总分\", true))); cellEntitys.add(new CellVerifyEntity(\"avg\", \"I\", new DoubleVerify(\"历史平均分\", true))); cellEntitys.add(new CellVerifyEntity(\"createTime\", \"J\", new DateTimeVerify(\"创建时间\", \"yyyy-MM-dd HH:mm\", true))); cellEntitys.add(new CellVerifyEntity(\"img\", \"K\", new ImgVerify(\"图片\", false))); // 必须调用 super.init(); &#125;&#125; 导入示例图 导出0.基础数据构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 单sheet数据 */static List&lt;ProjectEvaluate&gt; sheetData = new ArrayList&lt;&gt;();/** * map型数据 */static List&lt;Map&lt;String, Object&gt;&gt; mapData = new ArrayList&lt;&gt;();/** * 复杂对象数据 */static List&lt;Student&gt; complexData = new ArrayList&lt;&gt;();/** * 多sheet数据 */static List&lt;List&lt;?&gt;&gt; moreSheetData = new ArrayList&lt;&gt;();static &#123; // 1.单sheet数据填充 for (int i = 0; i &lt; 10; i++) &#123; ProjectEvaluate obj = new ProjectEvaluate(); obj.setProjectName(\"中青旅\" + i); obj.setAreaName(\"华东长三角\"); obj.setProvince(\"河北省\"); obj.setCity(\"保定市\"); obj.setPeople(\"张三\" + i); obj.setLeader(\"李四\" + i); obj.setScount(50); obj.setAvg(60.0); obj.setCreateTime(new Date()); obj.setImg(ImageParseBytes(new File(\"src/test/java/excel/export/1.png\"))); sheetData.add(obj); &#125; // 2.map型数据填充 for (int i = 0; i &lt; 15; i++) &#123; Map&lt;String, Object&gt; obj = new HashMap&lt;&gt;(); obj.put(\"name\", \"张三\" + i); obj.put(\"age\", 5 + i); mapData.add(obj); &#125; // 3.复杂对象数据 for (int i = 0; i &lt; 20; i++) &#123; // 學生 Student stu = new Student(); // 學生所在的班級，用對象 stu.setClassRoom(new ClassRoom(\"六班\")); // 學生的更多信息，用map Map&lt;String, Object&gt; moreInfo = new HashMap&lt;&gt;(); moreInfo.put(\"parent\", new Parent(\"張無忌\")); stu.setMoreInfo(moreInfo); stu.setName(\"张三\"); complexData.add(stu); &#125; // 4.多sheet数据填充 moreSheetData.add(sheetData); moreSheetData.add(mapData); moreSheetData.add(complexData);&#125; 1.简单导出 12345678910111213141516171819// 1.获取导出的数据体 // 1.导出的hearder设置String[] hearder = &#123;\"序号\", \"项目名称\", \"所属区域\", \"省份\", \"市\", \"项目所属人\", \"项目领导人\", \"得分\", \"平均分\", \"创建时间\", \"项目图片\"&#125;;// 2.导出hearder对应的字段设置Column[] column = &#123;Column.field(\"projectName\"), Column.field(\"areaName\"), Column.field(\"province\"), Column.field(\"city\"), Column.field(\"people\"), Column.field(\"leader\"), Column.field(\"scount\"), Column.field(\"avg\"), Column.field(\"createTime\"), // 项目图片 Column.field(\"img\")&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(sheetData, ExportRules.simpleRule(column, hearder).title(\"项目资源统计\").sheetName(\"mysheet1\").autoNum(true), true, (feildName, value, t, customStyle) -&gt; &#123; //此处指向回调逻辑，可以修改写入excel的值,以及单元格样式，如颜色等 return value; &#125;);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export1.xlsx\")); 1导出图 2.复杂表格导出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 1.表头设置,可以对应excel设计表头，一看就懂HashMap&lt;String, String&gt; headerRules = new HashMap&lt;&gt;();headerRules.put(\"1,1,A,K\", \"项目资源统计\");headerRules.put(\"2,3,A,A\", \"序号\");headerRules.put(\"2,2,B,E\", \"基本信息\");headerRules.put(\"3,3,B,B\", \"项目名称\");headerRules.put(\"3,3,C,C\", \"所属区域\");headerRules.put(\"3,3,D,D\", \"省份\");headerRules.put(\"3,3,E,E\", \"市\");headerRules.put(\"2,3,F,F\", \"项目所属人\");headerRules.put(\"2,3,G,G\", \"市项目领导人\");headerRules.put(\"2,2,H,I\", \"分值\");headerRules.put(\"3,3,H,H\", \"得分\");headerRules.put(\"3,3,I,I\", \"平均分\");headerRules.put(\"2,3,J,J\", \"创建时间\");headerRules.put(\"2,3,K,K\", \"项目图片\");// 2.尾部设置，一般可以用来设计合计栏HashMap&lt;String, String&gt; footerRules = new HashMap&lt;&gt;();footerRules.put(\"1,2,A,C\", \"注释:\");footerRules.put(\"1,2,D,K\", \"导出参考代码！\");// 3.导出hearder对应的字段设置Column[] column = &#123; Column.field(\"projectName\"), // 4.1设置此列宽度为10 Column.field(\"areaName\").width(10), // 4.2设置此列下拉框数据 Column.field(\"province\").width(5).dorpDown(new String[]&#123;\"陕西省\", \"山西省\", \"辽宁省\"&#125;), // 4.3设置此列水平居右 Column.field(\"city\").align(HorizontalAlignment.RIGHT), // 4.4 设置此列垂直居上 Column.field(\"people\").valign(VerticalAlignment.TOP), // 4.5 设置此列单元格 自定义校验 只能输入文本 Column.field(\"leader\").width(4).verifyCustom(\"VALUE(F3:F500)\", \"我是提示\"), // 4.6设置此列单元格 整数 数据校验 ，同时设置背景色为棕色 Column.field(\"scount\").verifyIntNum(\"10~20\").backColor(IndexedColors.BROWN), // 4.7设置此列单元格 浮点数 数据校验， 同时设置字体颜色红色 Column.field(\"avg\").verifyFloatNum(\"10.0~20.0\").color(IndexedColors.RED), // 4.8设置此列单元格 日期 数据校验 ，同时宽度为20、限制用户表格输入、水平居中、垂直居中、背景色、字体颜色 Column.field(\"createTime\").width(20).verifyDate(\"2000-01-03 12:35~3000-05-06 23:23\") .align(HorizontalAlignment.LEFT).valign(VerticalAlignment.CENTER) .backColor(IndexedColors.YELLOW).color(IndexedColors.GOLD), // 4.9项目图片 Column.field(\"img\")&#125;;// 4.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook( sheetData, ExportRules.complexRule(column, headerRules).autoNum(true).footerRules(footerRules).sheetName(\"mysheet2\"), true, (fieldName, value, row, col) -&gt; &#123; if (\"projectName\".equals(fieldName) &amp;&amp; row.getProjectName().equals(\"中青旅23\")) &#123; col.align(HorizontalAlignment.LEFT); col.valign(VerticalAlignment.CENTER); col.height(2); col.backColor(IndexedColors.RED); col.color(IndexedColors.YELLOW); &#125; return value; &#125;);// 5.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export2.xlsx\")); 2导出图 3.复杂的对象级联导出 123456789 // 1.导出的hearder设置String[] hearder = &#123;\"學生姓名\", \"所在班級\", \"所在學校\", \"更多父母姓名\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"name\"), Column.field(\"classRoom.name\"), Column.field(\"classRoom.school.name\"), Column.field(\"moreInfo.parent.name\"),&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(complexData, ExportRules.simpleRule(column, hearder).title(\"學生基本信息\"), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export3.xlsx\")); 3导出图 4.map对象的简单导出 12345678910// 1.导出的hearder设置String[] hearder = &#123;\"姓名\", \"年龄\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"name\"), Column.field(\"age\"),&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(mapData, ExportRules.simpleRule(column, hearder), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export4.xlsx\")); 4导出图 5.模板导出 123456789101112131415161718 // 1.导出的hearder设置String[] hearder = &#123;\"宝宝姓名\", \"宝宝昵称\", \"家长姓名\", \"手机号码\", \"宝宝生日\", \"月龄\", \"宝宝性别\", \"来源渠道\", \"市场人员\", \"咨询顾问\", \"客服顾问\", \"分配校区\", \"备注\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"宝宝姓名\"), Column.field(\"宝宝昵称\"), Column.field(\"家长姓名\"), Column.field(\"手机号码\").verifyText(\"11~11\", \"请输入11位的手机号码！\"), Column.field(\"宝宝生日\").verifyDate(\"2000-01-01~3000-12-31\"), Column.field(\"月龄\").width(4).verifyCustom(\"VALUE(F3:F6000)\", \"月齡格式：如1年2个月则输入14\"), Column.field(\"宝宝性别\").dorpDown(new String[]&#123;\"男\", \"女\"&#125;), Column.field(\"来源渠道\").width(12).dorpDown(new String[]&#123;\"品推\", \"市场\"&#125;), Column.field(\"市场人员\").width(6).dorpDown(new String[]&#123;\"张三\", \"李四\"&#125;), Column.field(\"咨询顾问\").width(6).dorpDown(new String[]&#123;\"张三\", \"李四\"&#125;), Column.field(\"客服顾问\").width(6).dorpDown(new String[]&#123;\"大唐\", \"银泰\"&#125;), Column.field(\"分配校区\").width(6).dorpDown(new String[]&#123;\"大唐\", \"银泰\"&#125;), Column.field(\"备注\")&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(Collections.emptyList(), ExportRules.simpleRule(column, hearder), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export5.xlsx\")); 5导出图 6.多sheet合并导出 12345678910111213141516171819202122232425262728293031323334353637383940414243 // 1.导出的hearder设置Workbook emptyWorkbook = ExcelUtils.createEmptyWorkbook(true);// 2.执行导出到工作簿.1.项目数据2.map数据3.复杂对象数据for (int i = 0; i &lt; moreSheetData.size(); i++) &#123; if (i == 0) &#123; List&lt;ProjectEvaluate&gt; data1 = (ArrayList&lt;ProjectEvaluate&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"序号\", \"项目名称\", \"所属区域\", \"省份\", \"市\", \"项目所属人\", \"项目领导人\", \"得分\", \"平均分\", \"创建时间\", \"项目图片\"&#125;; // 2.导出hearder对应的字段设置 Column[] column = &#123;Column.field(\"projectName\"), Column.field(\"areaName\"), Column.field(\"province\"), Column.field(\"city\"), Column.field(\"people\"), Column.field(\"leader\"), Column.field(\"scount\"), Column.field(\"avg\"), Column.field(\"createTime\"), // 项目图片 Column.field(\"img\") &#125;; ExcelUtils.fillBook(emptyWorkbook, data1, ExportRules.simpleRule(column, hearder).title(\"项目资源统计\").sheetName(\"mysheet1\").autoNum(true)); &#125; if (i == 1) &#123; List&lt;Map&lt;String, Object&gt;&gt; data2 = (ArrayList&lt;Map&lt;String, Object&gt;&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"姓名\", \"年龄\"&#125;; // 2.导出hearder对应的字段设置，列宽设置 Column[] column = &#123;Column.field(\"name\"), Column.field(\"age\"), &#125;; ExcelUtils.fillBook(emptyWorkbook, data2, ExportRules.simpleRule(column, hearder).sheetName(\"mysheet2\")); &#125; if (i == 2) &#123; List&lt;Student&gt; data3 = (ArrayList&lt;Student&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"學生姓名\", \"所在班級\", \"所在學校\", \"更多父母姓名\"&#125;; // 2.导出hearder对应的字段设置，列宽设置 Column[] column = &#123;Column.field(\"name\"), Column.field(\"classRoom.name\"), Column.field(\"classRoom.school.name\"), Column.field(\"moreInfo.parent.name\"),&#125;; // 3.执行导出到工作簿 ExcelUtils.fillBook(emptyWorkbook, data3, ExportRules.simpleRule(column, hearder).title(\"學生基本信息\")); &#125;&#125;// 4.写出文件emptyWorkbook.write(new FileOutputStream(\"src/test/java/excel/export/export6.xlsx\"));","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"轮子工具","slug":"轮子工具","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90%E5%B7%A5%E5%85%B7/"},{"name":"POI","slug":"POI","permalink":"https://kanchai.club/tags/POI/"},{"name":"Excel","slug":"Excel","permalink":"https://kanchai.club/tags/Excel/"}]},{"title":"RedisKey设计类","slug":"RedisKey设计类","date":"2020-03-17T15:36:46.510Z","updated":"2020-03-17T15:34:22.000Z","comments":true,"path":"2020/03/17/RedisKey设计类/","link":"","permalink":"https://kanchai.club/2020/03/17/RedisKey%E8%AE%BE%E8%AE%A1%E7%B1%BB/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.ym.common.utils.redis;import org.apache.commons.lang3.StringUtils;/** * 生成RedisKey工具 * * @author: 李涛 * @version: 2019年05月07日 15:19 */public class RedisKeyUtil &#123; /** * 主数据系统标识 */ public static final String KEY_PREFIX = \"ym\"; /** * 分割字符，默认[:]，使用:可用于rdm分组查看 */ private static final String KEY_SPLIT_CHAR = \":\"; /** * redis的key键规则定义 * * @param module 模块名称 * @param func 方法名称 * @param args 参数.. * @return key */ public static String keyBuilder(String module, String func, String... args) &#123; return keyBuilder(null, module, func, args); &#125; /** * redis的key键规则定义 * * @param module 模块名称 * @param func 方法名称 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(String module, String func, String objStr) &#123; return keyBuilder(null, module, func, new String[]&#123;objStr&#125;); &#125; /** * redis的key键规则定义 * * @param prefix 项目前缀 * @param module 模块名称 * @param func 方法名称 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(String prefix, String module, String func, String objStr) &#123; return keyBuilder(prefix, module, func, new String[]&#123;objStr&#125;); &#125; /** * redis的key键规则定义 * * @param prefix 项目前缀 * @param module 模块名称 * @param func 方法名称 * @param args 参数.. * @return key */ public static String keyBuilder(String prefix, String module, String func, String... args) &#123; // 项目前缀 if (prefix == null) &#123; prefix = KEY_PREFIX; &#125; StringBuilder key = new StringBuilder(prefix); // KEY_SPLIT_CHAR 为分割字符 key.append(KEY_SPLIT_CHAR).append(module); if (StringUtils.isNotBlank(func)) &#123; key.append(KEY_SPLIT_CHAR).append(func); &#125; for (String arg : args) &#123; key.append(KEY_SPLIT_CHAR).append(arg); &#125; return key.toString(); &#125; /** * redis的key键规则定义 * * @param redisKeyEnum 枚举对象 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(RedisKeyEnum redisKeyEnum, String... objStr) &#123; return keyBuilder(redisKeyEnum.getKeyPrefix(), redisKeyEnum.getModule(), redisKeyEnum.getFunc(), objStr); &#125;&#125;","categories":[],"tags":[]},{"title":"短信发送模板","slug":"短信发送模板","date":"2020-03-17T15:36:46.400Z","updated":"2020-03-17T15:34:27.000Z","comments":true,"path":"2020/03/17/短信发送模板/","link":"","permalink":"https://kanchai.club/2020/03/17/%E7%9F%AD%E4%BF%A1%E5%8F%91%E9%80%81%E6%A8%A1%E6%9D%BF/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231package com.ym.enums.common;import com.alibaba.fastjson.JSONObject;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 阿里云短信模板 * * @author: 李涛 * @version: 2019年05月17日 17:58 */public enum SmsTemplateEnum &#123; /** * 模版名称:通用验证码 * &lt;p&gt; */ UNIVERSAL_VERIFICATION_CODE(\"SMS_173141326\", \"您的验证码$&#123;code&#125;，该验证码5分钟内有效，请勿泄漏于他人！\"), /** * 模版名称:身份验证验证码 * &lt;p&gt; */ AUTHENTICATION_CODE(\"SMS_173191624\", \"验证码$&#123;code&#125;，您正在进行身份验证，打死不要告诉别人哦！\"), /** * 模版名称:登录确认验证码 * &lt;p&gt; */ LOGON_CONFIRMATION_AUTHENTICATION_CODE(\"SMS_173191623\", \"验证码$&#123;code&#125;，您正在登录，若非本人操作，请勿泄露。\"), /** * 模版名称:登录异常验证码 * &lt;p&gt; */ LOGON_EXCEPTION_AUTHENTICATION_CODE(\"SMS_173191622\", \"验证码$&#123;code&#125;，您正尝试异地登录，若非本人操作，请勿泄露。\"), /** * 模版名称:用户注册验证码 * &lt;p&gt; */ USER_REGISTRATION_AUTHENTICATION_CODE(\"SMS_173191621\", \"验证码$&#123;code&#125;，您正在注册成为新用户，感谢您的支持！\"), /** * 模版名称:修改密码验证码 * &lt;p&gt; */ MODIFY_PASSWORD_AUTHENTICATION_CODE(\"SMS_173191620\", \"验证码$&#123;code&#125;，您正在尝试修改登录密码，请妥善保管账户信息。\"), /** * 模版名称:信息变更验证码 * &lt;p&gt; */ INFORMATION_CHANGE_VERIFICATION_CODE(\"SMS_173191619\", \"验证码$&#123;code&#125;，您正在尝试变更重要信息，请妥善保管账户信息。\"), /** * 模版名称:医生资料审核不通过 * &lt;p&gt; * 变量：p2-其他；p3-电话号码； * &lt;p&gt; * 备注：用户资料审核不通过，发送短信告诉用户！ */ DATA_AUDIT_FAILED(\"SMS_174986989\", \"抱歉，您暂未通过资质审核，未通过原因：$&#123;p2&#125;。客服电话：$&#123;p3&#125;\"), /** * 模版名称:医生资料审核通过 * &lt;p&gt; * 变量：p2-金额； * &lt;p&gt; * 备注：用户资料审核通过，发送短信通知用户！ */ DATA_AUDIT_SUCCESS(\"SMS_174986992\", \"恭喜，您已通过资质审核，请登录APP开启您的个人诊所之旅吧，完成首单可获得$&#123;p2&#125;元奖励哦！\"), /** * 模版名称:用户注册通知 * &lt;p&gt; * 变量：p2-其他；p3-电话号码；p4-其他号码；p5-金额；p6-电话号码； * &lt;p&gt; * 备注：注册我方亚米健康产品后，发送此短信通知用户注册成功！ */ USER_REGISTRATION_NOTICE(\"SMS_174986988\", \"您已成功注册$&#123;p2&#125;，账号$&#123;p3&#125; ，初始密码 $&#123;p4&#125;。快去亚米健康完成医疗资质认证开启您的线上诊所赢取 $&#123;p5&#125; 元奖励。客服电话：$&#123;p6&#125;。\"), /** * 模版名称:电话预约成功 * &lt;p&gt; * 变量：p2-其他；p3-其他；p4-时间；p5-时间；p6-电话号码； * &lt;p&gt; * 备注：用户电话预约成功后，发送短信通知用户 */ SUCCESSFUL_TELEPHONE_RESERVATION(\"SMS_174991908\", \"您预约了$&#123;p2&#125;医生的$&#123;p3&#125;，时间$&#123;p4&#125;，共$&#123;p5&#125;分钟，到时您会接到$&#123;p6&#125;的来电，请保持电话畅通。\"), /** * 模版名称:图文问诊支付成功 * &lt;p&gt; * 变量：p2-金额；p3-其他； * &lt;p&gt; * 备注：图文问诊支付成功后，向用户发送短信通知 */ SUCCESSFUL_PAYMENT_FOR_CONSULTATION(\"SMS_174991905\", \"您刚支付了$&#123;p2&#125;元向$&#123;p3&#125;医生医生提问。可在我的问诊/当前问诊中找到该问题，查看医生回复。\"), /** * 模版名称:图问问诊医生首次回复 * &lt;p&gt; * 变量：p2-其他；p3-其他号码；p4-电话号码； * &lt;p&gt; * 备注：图问问诊医生首次回复后，需要发送短信告诉用户，让用户及时查看订单 */ DOCTOR_FIRST_REPLY(\"SMS_174986972\", \"医生$&#123;p2&#125;回复了您的问题，请您及时查看并进行后续交流。问题将在$&#123;p3&#125;小时后关闭。 有疑问请联系客服 $&#123;p4&#125;。\"), /** * 模版名称:问诊电话开始短信提醒 * &lt;p&gt; * 变量：p2-其他；p3-其他；p4-电话号码； * &lt;p&gt; * 备注：问诊电话服务快要开始的时候，向患者发送短信提醒。 */ INQUIRY_TELEPHONE_START_SHORT_MESSAGE_REMINDER(\"SMS_174991891\", \"您预约了$&#123;p2&#125;医生的$&#123;p3&#125;服务即将开始，请您合理按排时间，注意接听。到时您会接到$&#123;p4&#125;的来电，请保持电话畅通。\"), /** * 模版名称:患者预约成功推送 * &lt;p&gt; * 变量：p0-其他；p1-其他；p2-时间； * &lt;p&gt; * 备注：患者预约成功推送短信给医生，让医生及时联系患者 */ SUCCESSFUL_PUSH_OF_PATIENT_APPOINTMENT(\"SMS_175245305\", \"$&#123;p0&#125;医生您好，$&#123;p1&#125;患者预约了电话问诊服务，请于$&#123;p2&#125;在亚米医疗APP端拨打电话\"), /** * 模版名称:医生电话问诊即将开始通知 * &lt;p&gt; * 变量：p0-其他；p1-其他； * &lt;p&gt; * 备注：医生电话问诊即将开始通知 */ DOCTOR_S_TELEPHONE_CONSULTATION_IS_ABOUT_TO_START(\"SMS_175240289\", \"$&#123;p0&#125;医生您好，$&#123;p1&#125;患者预约的电话问诊服务即将开始，请及时拨打电话。\"), ; private String code; private String content; private static final Logger LOGGER = LoggerFactory.getLogger(SmsTemplateEnum.class); private SmsTemplateEnum(String code, String content) &#123; this.code = code; this.content = content; &#125; public String getCode() &#123; return code; &#125; /** * 输入对应模板的参数，生成JSON格式 * * @param prams * @return */ public String buildParams(Object... prams) &#123; JSONObject buildParams = new JSONObject(); String content = this.content; Pattern pattern = Pattern.compile(\"\\\\$\\\\&#123;[^&#125;]*\\\\&#125;\"); Matcher matcher = pattern.matcher(content); int index = 0; List&lt;String&gt; logs = new ArrayList&lt;&gt;(); while (matcher.find()) &#123; String group = matcher.group(0); logs.add(group); String key = group.replaceAll(\"\\\\$|\\\\&#123;|\\\\&#125;\", \"\"); buildParams.put(key, prams[index]); index++; &#125; for (int i = 0; i &lt; logs.size(); i++) &#123; content = content.replace(logs.get(i), String.valueOf(prams[i])); &#125; String result = buildParams.toJSONString(); LOGGER.info(\"发送SMS内容为：&#123;&#125;\", content); LOGGER.info(\"发送SMS参数为：&#123;&#125;\", result); return result; &#125; /** * 根据code获取验证码发送模板 * * @param code * @return */ public static SmsTemplateEnum getCodeTemp(String code) &#123; SmsTemplateEnum codeTemp = null; switch (code) &#123; case \"01\": //身份验证 codeTemp = SmsTemplateEnum.AUTHENTICATION_CODE; break; case \"02\": //正常登录 codeTemp = SmsTemplateEnum.LOGON_CONFIRMATION_AUTHENTICATION_CODE; break; case \"03\": //登录异常 codeTemp = SmsTemplateEnum.LOGON_EXCEPTION_AUTHENTICATION_CODE; break; case \"04\": //用户注册 codeTemp = SmsTemplateEnum.USER_REGISTRATION_AUTHENTICATION_CODE; break; case \"05\": //修改密码 codeTemp = SmsTemplateEnum.MODIFY_PASSWORD_AUTHENTICATION_CODE; break; case \"06\": //信息变更 codeTemp = SmsTemplateEnum.INFORMATION_CHANGE_VERIFICATION_CODE; break; default: codeTemp = SmsTemplateEnum.UNIVERSAL_VERIFICATION_CODE; &#125; return codeTemp; &#125;&#125;","categories":[],"tags":[]},{"title":"rabbitmq实现延时队列任务","slug":"rabbitmq实现延时队列任务","date":"2020-03-17T15:36:46.276Z","updated":"2020-03-17T15:34:31.000Z","comments":true,"path":"2020/03/17/rabbitmq实现延时队列任务/","link":"","permalink":"https://kanchai.club/2020/03/17/rabbitmq%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97%E4%BB%BB%E5%8A%A1/","excerpt":"此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时。","text":"此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时。 此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时… 要开发肯定先安装MQ,MQ的安装方式可以自行百度，我这里介绍简单的docker安装，首先安装docker服务，再安装带管理界面的rabbitMQ。1234567891011121314151617181920212223#### 1.更新yum源&gt; yum update#### 2.安装docker&gt; yum install -y docker#### 3拉取镜像&gt; docker pull rabbitmq:management#### 4启动容器&gt; docker run -d --name rabbitmq --privileged=true -p 9158:5672 -p 9159:15672 -v /home/rabbit/data:/var/lib/rabbitmq -v /home/rabbit/log:/var/log/rabbitmq -v /home/rabbit/plugins:/plugins --hostname ymRabbit -e RABBITMQ_DEFAULT_VHOST=/ -e RABBITMQ_DEFAULT_USER=ym_rabbit -e RABBITMQ_DEFAULT_PASS=ym_rabbit d8f707718f06#### 5进入容器方式&gt; docker exec -it 容器ID /bin/bash#### 6退出容器&gt; exit 或者 Ctrl+p+q#### 7向容器发送命令&gt; docker exec -d 13dc7c8ce0bd rabbitmq-plugins enable rabbitmq_delayed_message_exchange 两种延时方式 死信+普通交换器，依靠消息过期自动进入死信队列，然后消费死信队列的数据这个思路，但是由于这种方式不管设置队列过期时间还是消息过期时间，都不能达到单个队列消息灵活过期的目的。比如，先放入队列10s过期消息，再放入2s过期。mq会检测头部10s是否过期，10s不过期的情况下，2s就算过去也不会跑到死信。 使用插件rabbitmq_delayed_message_exchange。这个可以很好的解决消息不能灵活过期的问题，但是有个弊端就是很难查看消息堆积的情况，因为他把要发送的延时消息存在本地的分布式mnesia 数据库中，其次过期时间为最大int值，超过这个值得代码判定重复过期设置。 延时插件的使用方式 去MQ官网下载插件 ++https://www.rabbitmq.com/community-plugins.html++(rabbitmq_delayed_message_exchange) 把插件放到MQ的安装目录的plugins下 然后执行rabbitmq-plugins enable rabbitmq_delayed_message_exchange 命令启用插件 然后就也可以在web页面查看新的交换器x-delayed-message（其实并不是真正意义上的，真正的只有4个） 然后上代码实现延时任务，配置文件1234567891011121314151617181920212223spring: rabbitmq: host: 192.168.0.245 port: 9158 username: ym_rabbit password: ym_rabbit listener: simple: acknowledge-mode: manual #手动应答 retry: enabled: true# 用户自定义配置config-center: rabbitRuleConfig: # 系统标志 systemMark: local # 普通消息 normalExchange: topic.normal # 延时消息 delayExchange: topic.delay # 普通和延时消息死信 deadExchange: topic.dead spring中MQ的配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174/** * RabbitMQConfig 配置 * * @author: 李涛 * @version: 2019年05月07日 14:47 */@Configurationpublic class RabbitMQConfig &#123; //----------------------------常量定义----------------------- private static final String POINT = \".\"; private static final String NORMAL = \"nml\"; private static final String DELAY = \"dly\"; private static final String QUEUE = \"que\"; //----------------------------交换器定义---------------------------- /** * 普通交换器名字 */ public static String NORMAL_EXCHANGE = \"\"; /** * 死信交换器名字 */ public static String DEAD_EXCHANGE = \"\"; /** * 延时交换器名字 */ public static String DELAY_EXCHANGE = \"\"; //-------------------------队列定义-------------------------- /** * 普通队列 */ public static String NORMAL_QUEUE = null; /** * 延时队列存放任务 */ public static String DELAY_QUEUE = null; /** * 普通死信队列 */ public static String DEAD_NORMAL_QUEUE = null; /** * 延时死信队列 */ public static String DEAD_DELAY_QUEUE = null; @Autowired private ConfigCenterProperties configCenterProperties; @Bean public RabbitTemplate rabbitTemplate(CachingConnectionFactory rabbitListenerContainerFactory) &#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(rabbitListenerContainerFactory); rabbitTemplate.setUsePublisherConnection(true); rabbitTemplate.setChannelTransacted(true); return rabbitTemplate; &#125; @PostConstruct public void init() &#123; RabbitRuleConfig rabbitRuleConfig = configCenterProperties.getRabbitRuleConfig(); NORMAL_EXCHANGE = rabbitRuleConfig.getNormalExchange() + POINT + rabbitRuleConfig.getSystemMark(); DEAD_EXCHANGE = rabbitRuleConfig.getDeadExchange() + POINT + rabbitRuleConfig.getSystemMark(); DELAY_EXCHANGE = rabbitRuleConfig.getDelayExchange() + POINT + rabbitRuleConfig.getSystemMark(); NORMAL_QUEUE = rabbitRuleConfig.getNormalExchange() + POINT + QUEUE + POINT + rabbitRuleConfig.getSystemMark(); DELAY_QUEUE = rabbitRuleConfig.getDelayExchange() + POINT + QUEUE + POINT + rabbitRuleConfig.getSystemMark(); DEAD_NORMAL_QUEUE = rabbitRuleConfig.getDeadExchange() + POINT + QUEUE + POINT + NORMAL + POINT + rabbitRuleConfig.getSystemMark(); DEAD_DELAY_QUEUE = rabbitRuleConfig.getDeadExchange() + POINT + QUEUE + POINT + DELAY + POINT + rabbitRuleConfig.getSystemMark(); &#125; @Bean public RabbitListenerContainerFactory&lt;?&gt; rabbitListenerContainerFactory(ConnectionFactory connectionFactory) &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setChannelTransacted(true); return factory; &#125; @Bean public RabbitListenerContainerFactory&lt;?&gt; rabbitListenerContainerFactory2(ConnectionFactory connectionFactory) &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setMessageConverter(new SerializerMessageConverter()); factory.setChannelTransacted(true); return factory; &#125; //------------------------------交换器声明start--------------------------- @Bean public TopicExchange normalExchange() &#123; return new TopicExchange(NORMAL_EXCHANGE); &#125; @Bean public TopicExchange deadExchange() &#123; return new TopicExchange(DEAD_EXCHANGE); &#125; @Bean public CustomExchange delayExchange() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(\"x-delayed-type\", \"topic\"); return new CustomExchange(DELAY_EXCHANGE, \"x-delayed-message\", true, false, args); &#125; //------------------------------交换器声明end--------------------------- //-------------------------------队列start--------------------------------- @Bean public Queue deadNormalQueue() &#123; return new Queue(DEAD_NORMAL_QUEUE); &#125; @Bean public Queue deadDelayQueue() &#123; return new Queue(DEAD_DELAY_QUEUE); &#125; @Bean public Queue normalQueue() &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); params.put(\"x-dead-letter-routing-key\", DEAD_NORMAL_QUEUE); return new Queue(NORMAL_QUEUE, true, false, false, params); &#125; @Bean public Queue delayQueue() &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); params.put(\"x-dead-letter-routing-key\", DEAD_DELAY_QUEUE); return new Queue(DELAY_QUEUE, true, false, false, params); &#125; //-------------------------------队列end--------------------------------- //-------------------------------绑定start--------------------------------- @Bean public Binding bindingNormalExchange(Queue normalQueue, TopicExchange normalExchange) &#123; return BindingBuilder.bind(normalQueue).to(normalExchange).with(NORMAL_QUEUE); &#125; @Bean public Binding bindingNormalDeadExchange(Queue deadNormalQueue, TopicExchange deadExchange) &#123; return BindingBuilder.bind(deadNormalQueue).to(deadExchange).with(DEAD_NORMAL_QUEUE); &#125; @Bean public Binding bindingDelayExchange(Queue delayQueue, CustomExchange delayExchange) &#123; return BindingBuilder.bind(delayQueue).to(delayExchange).with(DELAY_QUEUE).noargs(); &#125; @Bean public Binding bindingDelayDeadExchange(Queue deadDelayQueue, TopicExchange deadExchange) &#123; return BindingBuilder.bind(deadDelayQueue).to(deadExchange).with(DEAD_DELAY_QUEUE); &#125; //-----------------------------------------绑定end------------------------------------------&#125; 7.生产者代码开发,我这里将延时任务和普通消息分开了，所以有2个发送方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * 发送消息给MQ * * @author: 李涛 * @version: 2019年09月19日 11:58 */@Servicepublic class IMessageSenderSV &#123; private static final Logger LOG = LoggerFactory.getLogger(IMessageSenderSV.class); @Autowired private RabbitTemplate rabbitTemplate; /** * 发送云信消息 * * @param messageTask 消息内容 */ public void sendMsg(NormalMessageTask messageTask) &#123; LOG.info(\"发送[ &#123;&#125; ]消息到MQ\", messageTask.getMessageTypeEnum().getDescribe()); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.NORMAL_EXCHANGE, RabbitMQConfig.NORMAL_QUEUE, messageTask, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); messageProperties.setMessageId(messageTask.getUuid()); messageProperties.setType(messageTask.getMessageTypeEnum().getDescribe()); messageProperties.setContentType(MessageProperties.CONTENT_TYPE_JSON); String sendTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date()); // 发送时间 messageProperties.setHeader(\"send_time\", sendTime); return message; &#125;); &#125; /** * 发送延时任务给队列 * * @param task 任务 */ public void sendDelayTask(AbstractDelayedTask task) &#123; LOG.info(\"发送延时任务 [ &#123;&#125;:&#123;&#125; ] 到MQ\", task.getDescribe(), task.getDelay()); rabbitTemplate.setMessageConverter(new SerializerMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.DELAY_EXCHANGE, RabbitMQConfig.DELAY_QUEUE, task, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); long nextDelay = 0; if (task.getDelay() &gt; Integer.MAX_VALUE) &#123; //如果延时时间大于erlang最大数值，多次延时 messageProperties.setDelay(Integer.MAX_VALUE); nextDelay = task.getDelay() - Integer.MAX_VALUE; &#125; else &#123; messageProperties.setDelay(task.getDelay().intValue()); &#125; // 下次延时的时间 messageProperties.setHeader(\"next_delay\", nextDelay); messageProperties.setMessageId(task.getUuid()); messageProperties.setType(task.getDescribe()); messageProperties.setContentType(MessageProperties.CONTENT_TYPE_SERIALIZED_OBJECT); String sendTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date()); // 发送时间 messageProperties.setHeader(\"send_time\", sendTime); String expirationTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date(System.currentTimeMillis() + task.getDelay())); // 过期时间 messageProperties.setHeader(\"expiration_time\", expirationTime); // 任务的入参 messageProperties.setHeader(\"params\", task.getParams().toString()); return message; &#125;); &#125; /** * 多次延时，再次发送任务 * @param task 任务 * @param nextDelay 下次延时时间 */ public void sendAgain(Message task, final long nextDelay) &#123; rabbitTemplate.setMessageConverter(new SerializerMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.DELAY_EXCHANGE, RabbitMQConfig.DELAY_QUEUE, task, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); long nextDelayNew = 0; if (nextDelay &gt; Integer.MAX_VALUE) &#123; //如果延时时间大于erlang最大数值，多次延时 messageProperties.setDelay(Integer.MAX_VALUE); nextDelayNew = nextDelay - Integer.MAX_VALUE; &#125; else &#123; messageProperties.setDelay((int) nextDelay); &#125; // 下次延时的时间 messageProperties.setHeader(\"next_delay\", nextDelayNew); return message; &#125;); &#125;&#125; 8.消费者代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158/** * 消费MQ消息 * * @author: 李涛 * @version: 2019年09月18日 10:41 */@Service@EnableRabbitpublic class IMessageReceiveSV &#123; private static final Logger LOG = LoggerFactory.getLogger(IMessageReceiveSV.class); @Autowired private IMessageSenderSV messageSenderSV; @Autowired private IYunxinUserSV yunxinUserSV; @Autowired private RabbitTemplate rabbitTemplate; @Value(\"$&#123;config-center.rabbitRuleConfig.deadExchange&#125;.que.nml.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\") private String normalDeadQueue; @Value(\"$&#123;config-center.rabbitRuleConfig.deadExchange&#125;.que.dly.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\") private String delayDeadQueue; /** * 普通消息 */ @RabbitListener(queues = \"$&#123;config-center.rabbitRuleConfig.normalExchange&#125;.que.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\", containerFactory = \"rabbitListenerContainerFactory\") public void autoNormalMsg(@Payload NormalMessageTask messageTask, @Headers Map&lt;String, Object&gt; headers, Channel channel) throws Exception &#123; channel.txSelect(); boolean success = normalHandle(messageTask); if (success) &#123; channel.basicAck((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; else &#123; channel.basicReject((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; channel.txCommit(); &#125; /** * 手动消费普通消息 */ public void manualConsumptionNormal() &#123; rabbitTemplate.receiveAndReply(normalDeadQueue, (payload) -&gt; &#123; NormalMessageTask normalMessageTask = (NormalMessageTask) payload; boolean success = normalHandle(normalMessageTask); if (!success) &#123; throw new AmqpException(\"普通消息消费异常\"); &#125; return true; &#125;); &#125; /** * 消费普通消息方法 * * @param messageTask */ private boolean normalHandle(NormalMessageTask messageTask) &#123; try &#123; MessageTypeEnum messageTypeEnum = messageTask.getMessageTypeEnum(); Object msg = messageTask.getMsg(); LOG.info(\"消费消息 [ &#123;&#125; ],消息ID为[ &#123;&#125; ]\", messageTypeEnum.getDescribe(), messageTask.getUuid()); switch (messageTypeEnum) &#123; case YUN_XIN: &#123; yunxinUserSV.syncMessages((String) msg); &#125; break; default: &#123; // do LOG.info(\"未知消息:&#123;&#125;\", (String) msg); &#125; &#125; &#125; catch (Exception e) &#123; if (e instanceof BusinessException) &#123; LOG.info(e.getMessage()); return true; &#125; else &#123; LOG.error(\"消费异常:&#123;&#125;\", ExceptionUtil.getExceptionMessage(e)); return false; &#125; &#125; return true; &#125; /** * 延时消息,执行策略 * &lt;p&gt; * 能收到说明已经到时间了 */ @RabbitListener(queues = \"$&#123;config-center.rabbitRuleConfig.delayExchange&#125;.que.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\", containerFactory = \"rabbitListenerContainerFactory2\") public void autoDelayMsg(@Payload Message message, @Headers Map&lt;String, Object&gt; headers, Channel channel) throws Exception &#123; channel.txSelect(); boolean success = delayHandle(message); if (success) &#123; channel.basicAck((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; else &#123; channel.basicReject((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; channel.txCommit(); &#125; /** * 消费延时消息方法 * * @param message */ private boolean delayHandle(Message message) &#123; MessageProperties messageProperties = message.getMessageProperties(); Map&lt;String, Object&gt; headers = messageProperties.getHeaders(); try &#123; // 判定是否要多次延时 long nextDelay = (long) headers.get(\"next_delay\"); if (nextDelay &gt; 0) &#123; messageSenderSV.sendAgain(message, nextDelay); return true; &#125; byte[] body = message.getBody(); if (body != null &amp;&amp; body.length &gt; 0) &#123; //判定为一个有效消息，进行执行 try (ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(body));) &#123; AbstractDelayedTask abstractDelayedTask = (AbstractDelayedTask) ois.readObject(); LOG.info(\"执行延时任务 [ &#123;&#125; ],消息ID为[ &#123;&#125; ],参数为:&#123;&#125;\", abstractDelayedTask.getDescribe(), abstractDelayedTask.getUuid(), JSONObject.toJSONString(headers)); abstractDelayedTask.excute(); &#125; &#125; return true; &#125; catch (Throwable e) &#123; if (e instanceof BusinessException) &#123; LOG.info(e.getMessage()); return true; &#125; else &#123; LOG.error(\"消费异常:&#123;&#125;\", ExceptionUtil.getExceptionMessage(e)); return false; &#125; &#125; &#125; /** * 手动消费延时消息 */ public void manualConsumptionDelay() &#123; rabbitTemplate.receiveAndReply(delayDeadQueue, (payload) -&gt; &#123; AbstractDelayedTask abstractDelayedTask = (AbstractDelayedTask) payload; try &#123; abstractDelayedTask.excute(); &#125; catch (Exception e) &#123; LOG.error(ExceptionUtil.getExceptionMessage(e)); throw new AmqpException(\"延时消息异常\"); &#125; return true; &#125;); &#125;&#125; 9.延时任务抽象类定义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 延时队列Task * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:34:43 */@Datapublic abstract class AbstractDelayedTask implements Serializable &#123; protected static final Logger LOG = LoggerFactory.getLogger(AbstractDelayedTask.class); /** * 任务唯一性标志 */ private String uuid = UUID.uuid(); /** * 任务描述 */ private String describe; /** * 多久后执行，单位毫秒 */ private Long delay; /** * 方法需要执行的参数 */ private JSONObject params; public AbstractDelayedTask(String describe, long delay, JSONObject params) &#123; this.describe = describe; this.delay = delay; this.params = params; &#125; /** * 执行任务 */ public void excute() throws Exception &#123; LOG.info(\"执行延时任务开始===========》&#123;&#125;\", describe); this.run(); LOG.info(\"执行延时任务结束===========》&#123;&#125;\", describe); &#125; public abstract void run() throws Exception;&#125; 使用方式 12345//15分钟未支付取消订单操作JSONObject params = new JSONObject();params.put(\"id\",\"订单ID\");UnPayCancelOrderTask unPayCancelOrderTask = new UnPayCancelOrderTask(\"下单后不支付自动取消订单\", TimeUnit.MINUTES.toMillis(15), params);messageSenderSV.sendDelayTask(unPayCancelOrderTask);","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://kanchai.club/tags/rabbitMQ/"}]},{"title":"基于注解的Redis分布式锁","slug":"基于注解的Redis分布式锁","date":"2020-03-17T15:36:46.103Z","updated":"2020-03-17T15:34:34.000Z","comments":true,"path":"2020/03/17/基于注解的Redis分布式锁/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂…………","text":"基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂………… 为什么使用基于注解的方式？ 基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂考虑利用AOP的方式，完成这一重复性的工作。在没利用注解之前加锁方式如下,基本每次都要这样写 123456789101112// 会话IDString uuid = UUID.uuid();try &#123; boolean getLock = RedisLockUtil.tryGetDistributedLock(key, uuid, 5000); if (getLock) &#123; //如果获取锁，执行业务代码 // todo &#125;&#125; finally &#123; RedisLockUtil.releaseDistributedLock(key, uuid);&#125; 基于注解的使用放入如下，比较便捷 12345@Locker(key &#x3D; RedisKeyEnum.POOL_ORDER_LOCK, paramExp &#x3D; &quot;0&quot;, noGetMsg &#x3D; &quot;老铁来晚了!&quot;)public GrabAndAnswerVo grabOrderAnswer(String orderId, RedisKeyEnum poolType, User currentUser) &#123; Long workId &#x3D; orderExist(poolType, orderId); return doctorGrabOrderAnswer(poolType, orderId, currentUser);&#125; 下面介绍以下代码 首先AOP的使用方式我定义为利用注解来判断是否需要加锁，类似事务的方式，我们定义一个Locker注解,这个注解的功能可以看代码; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 锁注解 * * @author 625 */@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Locker &#123; /** * 要锁定的Key * * @return */ RedisKeyEnum key(); /** * 要锁定的参数 * 格式: * 0 表示一个参数toString * 0?payOrder 表示一个参数toString，且额外拼接锁定的Key为payOrder * 0#name 表示第一个参数的name字段 * 0#name?payOrder 表示第一个参数的name字段，且额外拼接锁定的Key为payOrder * 0#name+1#name?payOrder 表示第一个参数的name字段+第二个参数的name字段，且额外拼接锁定的Key为payOrder * * @return */ String paramExp(); /** * 业务超时自动释放锁的时间,应该大于正常业务执行时间 * * @return */ long expireTime() default 10000; /** * 最小持有锁的时间 * * @return */ long limitTime() default 0; /** * 是否持续竞争锁，是则阻塞方法直至获取锁，或者达到最大竞争次数释放锁 * * @return */ boolean continueGet() default false; /** * 最大竞争次数。默认0不限次 * * @return */ int maxGetNum() default 0; /** * 拿不到锁，异常返回信息 * * @return */ String noGetMsg() default \"未获取锁\";&#125; 实现AOP的拦截规则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&#x2F;** * 锁AOP拦截规则 *&#x2F;@Aspect@Componentpublic class LockerAspect &#123; private static Logger LOGGER &#x3D; LoggerFactory.getLogger(LockerAspect.class); @Pointcut(&quot;@annotation(com.ym.common.utils.annotation.Locker)&quot;) public void pointcut() &#123; &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint joinPoint) &#123; Object proceed &#x3D; null; long startTime &#x3D; System.currentTimeMillis(); Locker locker &#x3D; getAnnotation(joinPoint, Locker.class); Object[] args &#x3D; joinPoint.getArgs(); &#x2F;&#x2F; 最大尝试次数 int maxGetNum &#x3D; locker.maxGetNum(); &#x2F;&#x2F; 会话标志 String uuid &#x3D; UUID.uuid(); &#x2F;&#x2F; 锁key String lockFiled &#x3D; getLockFiled(args, locker.paramExp()); String lockKey &#x3D; RedisKeyUtil.keyBuilder(locker.key(), lockFiled); &#x2F;&#x2F; 过期时间 long expireTime &#x3D; locker.expireTime(); boolean lock &#x3D; RedisLockUtil.tryGetDistributedLock(lockKey, uuid, expireTime); int getNum &#x3D; 0; while (!lock &amp;&amp; locker.continueGet() &amp;&amp; (maxGetNum &#x3D;&#x3D; 0 || getNum &lt; maxGetNum)) &#123; &#x2F;&#x2F; 如果获取失败，且持续获取，且尝试次数小于最大次数 Threads.sleep(100); lock &#x3D; RedisLockUtil.tryGetDistributedLock(lockKey, uuid, expireTime); &#125; if (!lock) &#123; throw new BusinessException(locker.noGetMsg()); &#125; &#x2F;&#x2F; -------------------------------before------------------------- try &#123; proceed &#x3D; joinPoint.proceed(); &#x2F;&#x2F; -------------------------------after------------------------- &#x2F;&#x2F; 如果业务时间小于最小持有锁时间，休眠一会 long sleepTime &#x3D; locker.limitTime() - (System.currentTimeMillis() - startTime); if (sleepTime &gt; 0) &#123; Threads.sleep(sleepTime); &#125; &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 释放锁 RedisLockUtil.releaseDistributedLock(lockKey, uuid); &#125; return proceed; &#125; &#x2F;** * 根据表达式获取要锁的字段 * * @param args * @param expression 表达式 * @return *&#x2F; private String getLockFiled(Object[] args, String expression) &#123; if (args &#x3D;&#x3D; null || args.length &#x3D;&#x3D; 0 || StringUtils.isBlank(expression)) &#123; throw new UnsupportedOperationException(&quot;Locker所在方法参数为空! 请使用代码锁&quot;); &#125; String[] extraParams &#x3D; expression.split(&quot;\\\\?&quot;); String extraKey &#x3D; null; if (extraParams.length &gt; 1) &#123; extraKey &#x3D; extraParams[1]; expression &#x3D; extraParams[0]; &#125; String[] commboExpression &#x3D; expression.split(&quot;\\\\+&quot;); StringBuilder field &#x3D; new StringBuilder(); for (String commbo : commboExpression) &#123; String[] split &#x3D; commbo.split(&quot;#&quot;); int argsNum &#x3D; 0; try &#123; if (split.length &#x3D;&#x3D; 1) &#123; argsNum &#x3D; Integer.parseInt(split[0]); field.append(String.valueOf(args[argsNum])); &#125; else &#123; argsNum &#x3D; Integer.parseInt(split[0]); Object fieldValue &#x3D; ReflectUtils.getFieldValue(args[argsNum], split[1]); field.append(String.valueOf(fieldValue)); &#125; &#125; catch (Exception e) &#123; throw new UnsupportedOperationException(&quot;Locker表达式paramExp不正确！&quot;); &#125; &#125; if (extraKey !&#x3D; null) &#123; field.append(extraKey); &#125; return field.toString(); &#125; &#x2F;** * 是否存在注解，如果存在就获取 *&#x2F; private &lt;T&gt; T getAnnotation(JoinPoint joinPoint, Class&lt;? extends Annotation&gt; t) &#123; Signature signature &#x3D; joinPoint.getSignature(); MethodSignature methodSignature &#x3D; (MethodSignature) signature; Method method &#x3D; methodSignature.getMethod(); if (method !&#x3D; null) &#123; return (T) method.getAnnotation(t); &#125; return null; &#125;&#125;","categories":[{"name":"分布式锁","slug":"分布式锁","permalink":"https://kanchai.club/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}],"tags":[{"name":"Redis锁","slug":"Redis锁","permalink":"https://kanchai.club/tags/Redis%E9%94%81/"},{"name":"分布式","slug":"分布式","permalink":"https://kanchai.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Java根据文件流准确判定文件类型","slug":"Java根据文件流准确判定文件类型","date":"2020-03-17T15:36:45.980Z","updated":"2020-03-17T15:34:34.000Z","comments":true,"path":"2020/03/17/Java根据文件流准确判定文件类型/","link":"","permalink":"https://kanchai.club/2020/03/17/Java%E6%A0%B9%E6%8D%AE%E6%96%87%E4%BB%B6%E6%B5%81%E5%87%86%E7%A1%AE%E5%88%A4%E5%AE%9A%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B/","excerpt":"判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀…..","text":"判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀….. 判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀判断的。而是通过文件本身的二进制数据，软件来解析到底一定的目的。话不多说上代码，通过判断文件流的前几个字节，来判断文件的类型。可以自己添加新的类型，类型不一定对，可以自己调试调整一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161package com.ym.common.utils.qiniu;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import java.io.InputStream;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Map.Entry;public class FileTypeHelper &#123; public final static Map&lt;String, String&gt; FILE_TYPE_MAP = new HashMap&lt;String, String&gt;(); private FileTypeHelper() &#123; &#125; static &#123; //初始化文件类型信息 getAllFileType(); &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getAllFileType,常见文件头信息]&lt;/p&gt; * * @author:[shixing_11@sina.com] */ private static void getAllFileType() &#123; FILE_TYPE_MAP.put(\"jpg\", \"FFD8FF\"); //JPEG (jpg) FILE_TYPE_MAP.put(\"png\", \"89504E47\"); //PNG (png) FILE_TYPE_MAP.put(\"gif\", \"47494638\"); //GIF (gif) FILE_TYPE_MAP.put(\"tif\", \"49492A00\"); //TIFF (tif) FILE_TYPE_MAP.put(\"bmp\", \"424D\"); //Windows Bitmap (bmp) FILE_TYPE_MAP.put(\"dwg\", \"41433130\"); //CAD (dwg) FILE_TYPE_MAP.put(\"html\", \"68746D6C3E\"); //HTML (html) FILE_TYPE_MAP.put(\"rtf\", \"7B5C727466\"); //Rich Text Format (rtf) FILE_TYPE_MAP.put(\"xml\", \"3C3F786D6C\"); FILE_TYPE_MAP.put(\"zip\", \"504B03041400000008005959104FFE4A759FF1\"); FILE_TYPE_MAP.put(\"rar\", \"52617221\"); FILE_TYPE_MAP.put(\"psd\", \"38425053\"); //Photoshop (psd) FILE_TYPE_MAP.put(\"eml\", \"44656C69766572792D646174653A\"); //Email [thorough only] (eml) FILE_TYPE_MAP.put(\"dbx\", \"CFAD12FEC5FD746F\"); //Outlook Express (dbx) FILE_TYPE_MAP.put(\"pst\", \"2142444E\"); //Outlook (pst) FILE_TYPE_MAP.put(\"xls\", \"D0CF11E0A1B11AE1000000000000000000000000000000003B\"); //MS Word FILE_TYPE_MAP.put(\"xlsx\", \"504B03041400060008000000210097454E26A\"); //MS Word FILE_TYPE_MAP.put(\"docx\", \"504B030414000600080000002100DFA4D26C5A\"); //MS Excel 注意：word 和 excel的文件头一样 FILE_TYPE_MAP.put(\"pptx\", \"504B030414000600080000002100DFCC18F5AD\"); FILE_TYPE_MAP.put(\"doc\", \"D0CF11E0A1B11AE1000000000000000000000000000000003E000300FEFF090006000000000000000000000001\"); FILE_TYPE_MAP.put(\"ppt\", \"D0CF11E0A1B11AE1000000000000000000000000000000003E000300FEFF090006000000000000000000000003\"); FILE_TYPE_MAP.put(\"mdb\", \"5374616E64617264204A\"); //MS Access (mdb) FILE_TYPE_MAP.put(\"wpd\", \"FF575043\"); //WordPerfect (wpd) FILE_TYPE_MAP.put(\"eps\", \"252150532D41646F6265\"); FILE_TYPE_MAP.put(\"ps\", \"252150532D41646F6265\"); FILE_TYPE_MAP.put(\"pdf\", \"255044462D312E\"); //Adobe Acrobat (pdf) FILE_TYPE_MAP.put(\"qdf\", \"AC9EBD8F\"); //Quicken (qdf) FILE_TYPE_MAP.put(\"pwl\", \"E3828596\"); //Windows Password (pwl) FILE_TYPE_MAP.put(\"wav\", \"57415645,52494646\"); //Wave (wav) FILE_TYPE_MAP.put(\"avi\", \"41564920\"); FILE_TYPE_MAP.put(\"ram\", \"2E7261FD\"); //Real Audio (ram) FILE_TYPE_MAP.put(\"rm\", \"2E524D46\"); //Real Media (rm) FILE_TYPE_MAP.put(\"mpg\", \"000001BA\"); // FILE_TYPE_MAP.put(\"mov\", \"6D6F6F76\"); //Quicktime (mov) FILE_TYPE_MAP.put(\"asf\", \"3026B2758E66CF11\"); //Windows Media (asf) FILE_TYPE_MAP.put(\"mid\", \"4D546864\"); //MIDI (mid) FILE_TYPE_MAP.put(\"aac\", \"FFF15C4013\"); //aac语音 FILE_TYPE_MAP.put(\"mp3\", \"FFE368\"); //mp3 FILE_TYPE_MAP.put(\"webm\", \"1A45DFA39F42868101\"); //webm FILE_TYPE_MAP.put(\"m4a\", \"0000001C667479704D344120000000004D3441206D70\"); //webm &#125; /** * 根据文件判定流类型 * * @param file * @return */ public final static String getFileTypeByFile(File file) &#123; InputStream is = null; try &#123; is = new FileInputStream(file); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; return getFileTypeByStream(is); &#125; /** * 根据流判定文件类型 * * @param is * @return */ public final static String getFileTypeByStream(InputStream is) &#123; String filetype = null; byte[] b = new byte[50]; try &#123; is.read(b); filetype = getFileTypeByByte(b); is.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return filetype; &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getFileTypeByStream]&lt;/p&gt; * * @param b * @return fileType * @author:[shixing_11@sina.com] */ public final static String getFileTypeByByte(byte[] b) &#123; String filetypeHex = String.valueOf(getFileHexString(b)); Iterator&lt;Entry&lt;String, String&gt;&gt; entryiterator = FILE_TYPE_MAP.entrySet().iterator(); while (entryiterator.hasNext()) &#123; Entry&lt;String, String&gt; entry = entryiterator.next(); String fileTypeHexValue = entry.getValue(); String[] split = fileTypeHexValue.split(\",\"); for (String sufix : split) &#123; if (filetypeHex.toUpperCase().startsWith(sufix)) &#123; return entry.getKey(); &#125; &#125; &#125; return \"txt\"; &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getFileHexString]&lt;/p&gt; * * @param b * @return fileTypeHex * @author:[shixing_11@sina.com] */ private final static String getFileHexString(byte[] b) &#123; StringBuilder stringBuilder = new StringBuilder(); int byteLength = 50; if (b == null || b.length &lt;= 0) &#123; return null; &#125; else if (b.length &lt; byteLength) &#123; byteLength = b.length; &#125; for (int i = 0; i &lt; byteLength; i++) &#123; int v = b[i] &amp; 0xFF; String hv = Integer.toHexString(v); if (hv.length() &lt; 2) &#123; stringBuilder.append(0); &#125; stringBuilder.append(hv); &#125; return stringBuilder.toString(); &#125;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"文件类型判断","slug":"文件类型判断","permalink":"https://kanchai.club/tags/%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD/"}]},{"title":"一些常用的linux基础命令","slug":"Linux命令记录","date":"2020-03-17T15:36:45.859Z","updated":"2020-03-17T15:34:47.000Z","comments":true,"path":"2020/03/17/Linux命令记录/","link":"","permalink":"https://kanchai.club/2020/03/17/Linux%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"记录一些日常用到的基础命令,防止重复去百度搜索,主要是Centos中,个人记不住的一些命令,ls什么的肯定没有记录","text":"记录一些日常用到的基础命令,防止重复去百度搜索,主要是Centos中,个人记不住的一些命令,ls什么的肯定没有记录 端口 端口占用情况 12&gt; lsof -i tcp:8000 &gt; netstat -tunlp |grep 8000 列出所有端口 1&gt; netstat -ntlp 根据程序名找进程 1&gt; ps axu |grep 程序名&#x2F;端口号&#x2F;IP等等 查询指定端口是否已开 1&gt; firewall-cmd --query-port&#x3D;666&#x2F;tcp 查看所有开放的端口 1&gt; iptables -t filter -L INPUT 防火墙 查看防火墙状态 1&gt; systemctl status firewalld 开启防火墙 123456&gt; systemctl start firewalld&gt; service firewalld start &gt; ##若遇到无法开启,先用：&gt; systemctl unmask firewalld.service &gt; 然后：&gt; systemctl start firewalld.service 关闭防火墙 1&gt; systemctl stop firewalld 对外开放端口 123456&gt; firewall-cmd --zone&#x3D;public --add-port&#x3D;8080&#x2F;tcp --permanent&gt; iptables -I INPUT -p tcp --dport 9150 -j ACCEPT&gt; ##或者&gt; sudo vi sysconfig&#x2F;iptables&gt; ##然后&gt; -A INPUT -m state --state NEW -m tcp -p tcp --dport 9150 -j ACCEPT 查看对外开放的端口 1&gt; iptables -t filter -L INPUT 重启防火墙 12&gt; firewall-cmd --reload systemctl &gt; restart firewalld.service； 关闭指定端口 1&gt; firewall-cmd --permanent --remove-port&#x3D;123&#x2F;tcp 查看文件内容 关键词查找 12&gt; ##执行的是返回的内容 &gt; grep 正则 文件目录 关键词查找及随后的目录中搜索字符串 1&gt; grep -R 正则 文件目录 jvm相关 查看JAVA进程并输出JVM参数 1&gt; jps -v dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名 1&gt; jmap -dump:live,format&#x3D;b,file&#x3D;dump.hprof 28920 查看堆的使用情况 1&gt; jmap -heap 28920 查看堆中的对象信息 1&gt; jmap -histo:live 28920 | more 查看当前程序的线程快照 1&gt; jstack -l 11494|more 实时查看调整Jvm参数 1&gt; jinfo -flag 11494 系统信息查看 显示电脑以及操作系统的相关信息1&gt; uname -a 正在运行的内核版本1&gt; cat &#x2F;proc&#x2F;version 发行版本信息1&gt; cat &#x2F;etc&#x2F;issue","categories":[{"name":"Linux","slug":"Linux","permalink":"https://kanchai.club/categories/Linux/"}],"tags":[{"name":"基础命令","slug":"基础命令","permalink":"https://kanchai.club/tags/%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"name":"Jvm","slug":"Jvm","permalink":"https://kanchai.club/tags/Jvm/"}]},{"title":"基于Delayed实现一个定时延时任务","slug":"实现一个延时任务","date":"2020-03-17T15:36:45.731Z","updated":"2020-03-17T15:34:54.000Z","comments":true,"path":"2020/03/17/实现一个延时任务/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"在spring中加入一个守护线程+延时队列来处理一些延时任务.比如用户注册后5分钟后发送短信.等等","text":"在spring中加入一个守护线程+延时队列来处理一些延时任务.比如用户注册后5分钟后发送短信.等等 延时任务Bean的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package com.ym.common.utils;import java.util.concurrent.Delayed;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;/** * 延时队列Task * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:34:43 */public class DelayedTask&lt;T extends Runnable&gt; implements Delayed &#123; /** * 任务名称 */ private final String name; /** * 到期时间 */ private final long time; /** * 问题对象 */ private final T task; private static final AtomicLong atomic = new AtomicLong(0); private final long n; public DelayedTask(long timeout, T t, String name) &#123; this.time = System.nanoTime() + timeout; this.task = t; this.name = name; this.n = atomic.getAndIncrement(); &#125; /** * 返回与此对象相关的剩余延迟时间，以给定的时间单位表示 */ @Override public long getDelay(TimeUnit unit) &#123; return unit.convert(this.time - System.nanoTime(), TimeUnit.NANOSECONDS); &#125; @Override public int compareTo(Delayed other) &#123; // TODO Auto-generated method stub if (other == this) // compare zero ONLY if same object return 0; if (other instanceof DelayedTask) &#123; DelayedTask&lt;Runnable&gt; x = (DelayedTask) other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (getN() &lt; x.getN()) return -1; else return 1; &#125; long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS)); return (d == 0) ? 0 : ((d &lt; 0) ? -1 : 1); &#125; public T getTask() &#123; return this.task; &#125; @Override public int hashCode() &#123; return task.hashCode(); &#125; @Override public boolean equals(Object object) &#123; if (object instanceof DelayedTask) &#123; return object.hashCode() == hashCode() ? true : false; &#125; return false; &#125; public String getName() &#123; return name; &#125; public long getN() &#123; return n; &#125;&#125; Spring容器Bean的定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144package com.ym.web.bean;import com.ym.common.utils.DelayedTask;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import java.util.concurrent.DelayQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;/** * 延时队列任务管理 * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:35:39 */@Componentpublic class TaskQueueBean &#123; private static final Logger LOG = LoggerFactory.getLogger(TaskQueueBean.class); private static volatile boolean started = false; private TaskQueueBean() &#123; &#125; private static class LazyHolder &#123; private static TaskQueueBean taskQueueDaemonThread = new TaskQueueBean(); &#125; public static TaskQueueBean getInstance() &#123; return LazyHolder.taskQueueDaemonThread; &#125; /** * 执行任务的线程 */ private ExecutorService executor = null; /** * 创建一个最初为空的新 DelayQueue */ private DelayQueue&lt;DelayedTask&lt;Runnable&gt;&gt; queue = null; /** * 守护线程 */ private Thread daemonThread; /** * 初始化守护线程 */ @PostConstruct public synchronized void start() &#123; // 1.初始化线程池 if (!started) &#123; started = true; executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); queue = new DelayQueue&lt;&gt;(); // 2.判断是否启动 if (daemonThread != null &amp;&amp; daemonThread.isInterrupted()) &#123; daemonThread.start(); return; &#125; &#125; daemonThread = new Thread() &#123; public void run() &#123; try &#123; execute(); &#125; catch (InterruptedException e) &#123; daemonThread.interrupt(); &#125; &#125; &#125;; daemonThread.setDaemon(true); daemonThread.setName(\"DelayedTask\"); daemonThread.start(); LOG.info(\"~~~~~~~~~~~~~~~~~~~~延时任务开启~~~~~~~~~~~~~~~~~~~~~~~~~\"); &#125; private void execute() throws InterruptedException &#123; LOG.info(\"[ task start &#123;&#125; ]:\", System.currentTimeMillis()); while (started) &#123; // 从延迟队列中取值,如果没有对象过期则队列一直等待， DelayedTask&lt;Runnable&gt; t1 = queue.take(); if (t1 != null) &#123; // 修改问题的状态 Runnable task = t1.getTask(); if (task == null) &#123; continue; &#125; executor.execute(task); LOG.info(\"[ &#123;&#125; task &#123;&#125; execute ] \", t1.getN(), t1.getName()); &#125; &#125; &#125; /** * 添加任务， time 延迟时间 task 任务 用户为问题设置延迟时间 */ public void put(long time, Runnable task, String taskName) &#123; if (!started) &#123; throw new UnsupportedOperationException(\"请先启动taskQueneBean！\"); &#125; // 转换成ns long nanoTime = TimeUnit.NANOSECONDS.convert(time, TimeUnit.MILLISECONDS); // 创建一个任务 DelayedTask&lt;Runnable&gt; k = new DelayedTask&lt;Runnable&gt;(nanoTime, task, taskName); // 将任务放在延迟的队列中 queue.put(k); LOG.info(\"新任务：&#123;&#125;加入队列，当前队列任务数量：&#123;&#125;\", taskName, queue.size()); &#125; /** * 结束 * * @param task */ public boolean endTask(DelayedTask&lt;Runnable&gt; task) &#123; if (!started) &#123; throw new UnsupportedOperationException(\"请先启动taskQueneBean！\"); &#125; return queue.remove(task); &#125; /** * 手动关闭任务 */ public synchronized void stop() &#123; if (started) &#123; LOG.info(\"shutdown TaskQueueBean\"); started = false; daemonThread.interrupt(); executor.shutdown(); daemonThread = null; queue = null; &#125; &#125;&#125;`","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"},{"name":"Spring","slug":"Spring","permalink":"https://kanchai.club/tags/Spring/"}]},{"title":"实现基于Redis的lua的分布式锁","slug":"实现基于Redis的lua的分布式锁","date":"2020-03-17T15:36:45.602Z","updated":"2020-03-17T15:34:57.000Z","comments":true,"path":"2020/03/17/实现基于Redis的lua的分布式锁/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERedis%E7%9A%84lua%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"基于目前有需求需要实现一个分布式锁,用zk的话由于项目本身暂时没有用到zk,所以暂不考虑zk锁.用redis的lua脚本来实现安全的分布式锁,保证指令的原子性.","text":"基于目前有需求需要实现一个分布式锁,用zk的话由于项目本身暂时没有用到zk,所以暂不考虑zk锁.用redis的lua脚本来实现安全的分布式锁,保证指令的原子性. 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.ym.common.utils.redis;import com.ym.common.utils.Sha1Util;import com.ym.common.utils.spring.SpringUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.script.RedisScript;import java.util.Collections;/** * 基于redis lua分布式锁 * * @author: 李涛 * @version: 2019年05月08日 16:15 */public class RedisLockUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisLockUtil.class); /** * 成功标识 */ private static final Long SUCCESS = 1L; /** * 加锁lua脚本,不可重入,reqId只是为了解锁使用,代表当前线程在使用资源,给UUID比较好 */ private static final String SCRIPT_LOCK = \"if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then redis.call('pexpire', KEYS[1], ARGV[2]) return 1 else return 0 end\"; /** * 解锁lua脚本 */ private static final String SCRIPT_UNLOCK = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; /** * 加锁脚本sha1值 */ private static final String SCRIPT_LOCK_SHA1 = Sha1Util.encrypt(SCRIPT_LOCK); /** * 解锁脚本sha1值 */ private static final String SCRIPT_UNLOCK_SHA1 = Sha1Util.encrypt(SCRIPT_UNLOCK); /** * 内部持有模板 */ private static final RedisTemplate redisTemplate = (RedisTemplate) SpringUtil.getObject(\"redisTemplate\"); /** * 尝试获取分布式锁 * * @param lockKey 锁 * @param requestId 请求标识,唯一ID * @param expireTimeMilliseconds 超期时间，多少毫秒后这把锁自动释放 * @return 返回true表示拿到锁 */ public static boolean tryGetDistributedLock(String lockKey, String requestId, int expireTimeMilliseconds) &#123; LOGGER.info(\"[&#123;&#125;]尝试获取[&#123;&#125;]锁,超时时间为:&#123;&#125;毫秒\", requestId, lockKey, expireTimeMilliseconds); /** * 脚本设置 */ RedisScript&lt;Long&gt; redisScript = new RedisScript&lt;Long&gt;() &#123; @Override public String getSha1() &#123; return SCRIPT_LOCK_SHA1; &#125; @Override public Class&lt;Long&gt; getResultType() &#123; return Long.class; &#125; @Override public String getScriptAsString() &#123; return SCRIPT_LOCK; &#125; &#125;; Object result = redisTemplate.execute( redisScript,// lua脚本 Collections.singletonList(lockKey),// KEYS[1] requestId, // ARGV[1] expireTimeMilliseconds // ARGV[2] ); boolean b = SUCCESS.equals(result); LOGGER.info(\"释放结果:\", b); return b; &#125; /** * 释放分布式锁 * * @param lockKey 锁 * @param requestId 请求标识 * @return 返回true表示释放锁成功 */ public static boolean releaseDistributedLock(String lockKey, String requestId) &#123; LOGGER.info(\"[&#123;&#125;]释放锁[&#123;&#125;]锁\", requestId, lockKey); /** * lua脚本 */ RedisScript&lt;Long&gt; redisScript = new RedisScript&lt;Long&gt;() &#123; @Override public String getSha1() &#123; return SCRIPT_UNLOCK_SHA1; &#125; @Override public Class&lt;Long&gt; getResultType() &#123; return Long.class; &#125; @Override public String getScriptAsString() &#123; return SCRIPT_UNLOCK; &#125; &#125;; Object result = redisTemplate.execute( redisScript, Collections.singletonList(lockKey), requestId ); boolean b = SUCCESS.equals(result); LOGGER.info(\"释放结果:\", b); return b; &#125;&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/categories/Redis/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://kanchai.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/tags/Redis/"}]},{"title":"上传自己的git项目到maven","slug":"上传自己的git项目到maven","date":"2020-03-17T15:36:45.470Z","updated":"2020-03-17T15:35:02.000Z","comments":true,"path":"2020/03/17/上传自己的git项目到maven/","link":"","permalink":"https://kanchai.club/2020/03/17/%E4%B8%8A%E4%BC%A0%E8%87%AA%E5%B7%B1%E7%9A%84git%E9%A1%B9%E7%9B%AE%E5%88%B0maven/","excerpt":"上传自己的git项目到maven，结合两位博客成功上传。","text":"上传自己的git项目到maven，结合两位博客成功上传。 感谢两位博主，地址分别为 https://www.jianshu.com/p/8c3d7fb09bce https://blog.csdn.net/sinat_23290725/article/details/85018092","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://kanchai.club/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://kanchai.club/tags/maven/"}]},{"title":"mongo搭建副本集","slug":"mongo搭建副本集","date":"2020-03-17T15:36:45.353Z","updated":"2020-03-17T15:35:06.000Z","comments":true,"path":"2020/03/17/mongo搭建副本集/","link":"","permalink":"https://kanchai.club/2020/03/17/mongo%E6%90%AD%E5%BB%BA%E5%89%AF%E6%9C%AC%E9%9B%86/","excerpt":"搭建副本集的作用和其他数据库思路大致一样，主从配置，仲裁节点，也就是说最起码要保证3个节点….","text":"搭建副本集的作用和其他数据库思路大致一样，主从配置，仲裁节点，也就是说最起码要保证3个节点…. Replica Set介绍 中文翻译叫做副本集,其实简单来说就是集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。 搭建集群 般情况下不会把数据目录建立在mongodb的解压目录下，不过这里方便起见，就建在mongodb解压目录下吧。 1234mkdir -p &#x2F;mongodb&#x2F;data&#x2F;master mkdir -p &#x2F;mongodb&#x2F;data&#x2F;slaver mkdir -p &#x2F;mongodb&#x2F;data&#x2F;arbiter #三个目录分别对应主，备，仲裁节点 建立配置文件,由于配置比较多，所以我们将配置写到文件里，以文件的方式启动，以下配置文件仔细看可以说是只有端口不同，搭建的伪集群。 123456789101112131415161718192021222324#master.conf 主节点配置#数据存放目录dbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;master #日志存放路径logpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;master.log#进程文件pidfilepath&#x3D;&#x2F;mongodb&#x2F;master.pid#为每一个数据库按照数据库名建立文件夹存放directoryperdb&#x3D;true#以追加的方式记录日志logappend&#x3D;true#replica set的名字replSet&#x3D;testrs#绑定暴露的ID地址bind_ip&#x3D;127.0.0.1#端口port&#x3D;27017#mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%oplogSize&#x3D;10000#以后台方式运行进程fork&#x3D;true#不预先分配存储noprealloc&#x3D;true 12345678910111213#master.conf 副本节点配置#slaver.confdbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;slaverlogpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;slaver.logpidfilepath&#x3D;&#x2F;mongodb&#x2F;slaver.piddirectoryperdb&#x3D;truelogappend&#x3D;truereplSet&#x3D;testrsbind_ip&#x3D;127.0.0.1port&#x3D;27018oplogSize&#x3D;10000fork&#x3D;truenoprealloc&#x3D;true 123456789101112#arbiter.conf 仲裁节点配置dbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;arbiterlogpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;arbiter.logpidfilepath&#x3D;&#x2F;mongodb&#x2F;arbiter.piddirectoryperdb&#x3D;truelogappend&#x3D;truereplSet&#x3D;testrsbind_ip&#x3D;127.0.0.1port&#x3D;27019oplogSize&#x3D;10000fork&#x3D;truenoprealloc&#x3D;true 启动mongo 123.&#x2F;monood -f master.conf.&#x2F;mongod -f slaver.conf.&#x2F;mongod -f arbiter.conf 开始配置主从、仲裁节点，可以通过客户端连接mongodb，也可以直接在三个节点中选择一个连接mongodb。 12345&gt;.&#x2F;mongo 127.0.0.1:27017 #ip和port是某个节点的地址&gt;use admin&gt;cfg&#x3D;&#123; _id:&quot;testrs&quot;, members:[ &#123;_id:0,host:&#39;127.0.0.1:27017&#39;,priority:2&#125;, &#123;_id:1,host:&#39;127.0.0.1:27017&#39;,priority:1&#125;, &#123;_id:2,host:&#39;127.0.0.1:27017&#39;,arbiterOnly:true&#125;] &#125;;&gt;rs.initiate(cfg) #使配置生效 cfg是可以任意的名字，当然最好不要是mongodb的关键字，conf，config都可以。最外层的_id表示replica set的名字，members里包含的是所有节点的地址以及优先级。优先级最高的即成为主节点，即这里的127.0.0.1:27017。特别注意的是，对于仲裁节点，需要有个特别的配置——arbiterOnly:true。这个千万不能少了，不然主备模式就不能生效。配置的生效时间根据不同的机器配置会有长有短，配置不错的话基本上十几秒内就能生效，有的配置需要一两分钟。如果生效了，执行rs.status()命令会看到如下信息： 1234567891011121314151617181920212223242526272829303132333435363738394041 &#123; &quot;set&quot; : &quot;testrs&quot;, &quot;date&quot; : ISODate(&quot;2013-01-05T02:44:43Z&quot;), &quot;myState&quot; : 1, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;name&quot; : &quot;127.0.0.1:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 200, &quot;optime&quot; : Timestamp(1357285565000, 1), &quot;optimeDate&quot; : ISODate(&quot;2013-01-04T07:46:05Z&quot;), &quot;self&quot; : true &#125;, &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;127.0.0.1:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 200, &quot;optime&quot; : Timestamp(1357285565000, 1), &quot;optimeDate&quot; : ISODate(&quot;2013-01-04T07:46:05Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2013-01-05T02:44:42Z&quot;), &quot;pingMs&quot; : 0 &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;127.0.0.1:27019&quot;, &quot;health&quot; : 1, &quot;state&quot; : 7, &quot;stateStr&quot; : &quot;ARBITER&quot;, &quot;uptime&quot; : 200, &quot;lastHeartbeat&quot; : ISODate(&quot;2013-01-05T02:44:42Z&quot;), &quot;pingMs&quot; : 0 &#125; ], &quot;ok&quot; : 1&#125;如果配置正在生效，其中会包含如下信息,同时可以查看对应节点的日志，发现正在等待别的节点生效或者正在分配数据文件： 1&quot;stateStr&quot; : &quot;RECOVERING&quot; 现在基本上已经完成了集群的所有搭建工作。至于测试工作，可以留给大家自己试试。一个是往主节点插入数据，能从备节点查到之前插入的数据（查询备节点可能会遇到某个问题，可以自己去网上查查看）。二是停掉主节点，备节点能变成主节点提供服务。三是恢复主节点，备节点也能恢复其备的角色，而不是继续充当主的角色。二和三都可以通过rs.status()命令实时查看集群的变化。 转载来源","categories":[{"name":"Mongo","slug":"Mongo","permalink":"https://kanchai.club/categories/Mongo/"}],"tags":[{"name":"mongo集群","slug":"mongo集群","permalink":"https://kanchai.club/tags/mongo%E9%9B%86%E7%BE%A4/"}]},{"title":"IDEA快捷键","slug":"史上最全IDEA快捷键","date":"2020-03-17T15:36:45.229Z","updated":"2020-03-17T15:35:12.000Z","comments":true,"path":"2020/03/17/史上最全IDEA快捷键/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8IDEA%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"IDEA快捷键比较全面的","text":"IDEA快捷键比较全面的 常规 Ctrl+Shift + Enter，语句完成 “！”，否定完成，输入表达式时按 “！”键 Ctrl+E，最近的文件 Ctrl+Shift+E，最近更改的文件 Shift+Click，可以关闭文件 Ctrl+[ OR ]，可以跑到大括号的开头与结尾 Ctrl+F12，可以显示当前文件的结构 Ctrl+F7，可以查询当前元素在当前文件中的引用，然后按 F3 可以选择 Ctrl+N，可以快速打开类 Ctrl+Shift+N，可以快速打开文件 Alt+Q，可以看到当前方法的声明 Ctrl+P，可以显示参数信息 Ctrl+Shift+Insert，可以选择剪贴板内容并插入 Alt+Insert，可以生成构造器/Getter/Setter等 Ctrl+Alt+V，可以引入变量。例如：new String(); 自动导入变量定义 Ctrl+Alt+T，可以把代码包在一个块内，例如：try/catch Ctrl+Enter，导入包，自动修正 Ctrl+Alt+L，格式化代码 Ctrl+Alt+I，将选中的代码进行自动缩进编排，这个功能在编辑 JSP 文件时也可以工作 Ctrl+Alt+O，优化导入的类和包 Ctrl+R，替换文本 Ctrl+F，查找文本 Ctrl+Shift+Space，自动补全代码 Ctrl+空格，代码提示（与系统输入法快捷键冲突） Ctrl+Shift+Alt+N，查找类中的方法或变量 Alt+Shift+C，最近的更改 Alt+Shift+Up/Down，上/下移一行 Shift+F6，重构 - 重命名 Ctrl+X，删除行 Ctrl+D，复制行 Ctrl+/或Ctrl+Shift+/，注释（//或者/**/） Ctrl+J，自动代码（例如：serr） Ctrl+Alt+J，用动态模板环绕 Ctrl+H，显示类结构图（类的继承层次） Ctrl+Q，显示注释文档 Alt+F1，查找代码所在位置 Alt+1，快速打开或隐藏工程面板 Ctrl+Alt+left/right，返回至上次浏览的位置 Alt+left/right，切换代码视图 Alt+Up/Down，在方法间快速移动定位 Ctrl+Shift+Up/Down，向上/下移动语句 F2 或 Shift+F2，高亮错误或警告快速定位 Tab，代码标签输入完成后，按 Tab，生成代码 Ctrl+Shift+F7，高亮显示所有该文本，按 Esc 高亮消失 Alt+F3，逐个往下查找相同文本，并高亮显示 Ctrl+Up/Down，光标中转到第一行或最后一行下 Ctrl+B/Ctrl+Click，快速打开光标处的类或方法（跳转到定义处） Ctrl+Alt+B，跳转到方法实现处 Ctrl+Shift+Backspace，跳转到上次编辑的地方 Ctrl+O，重写方法 Ctrl+Alt+Space，类名自动完成 Ctrl+Alt+Up/Down，快速跳转搜索结果 Ctrl+Shift+J，整合两行 Alt+F8，计算变量值 Ctrl+Shift+V，可以将最近使用的剪贴板内容选择插入到文本 Ctrl+Alt+Shift+V，简单粘贴 Shift+Esc，不仅可以把焦点移到编辑器上，而且还可以隐藏当前（或最后活动的）工具窗口 F12，把焦点从编辑器移到最近使用的工具窗口 Shift+F1，要打开编辑器光标字符处使用的类或者方法 Java 文档的浏览器 Ctrl+W，可以选择单词继而语句继而行继而函数 Ctrl+Shift+W，取消选择光标所在词 Alt+F7，查找整个工程中使用地某一个类、方法或者变量的位置 Ctrl+I，实现方法 Ctrl+Shift+U，大小写转化 Ctrl+Y，删除当前行 Shift+Enter，向下插入新行 psvm/sout，main/System.out.println(); Ctrl+J，查看更多 Ctrl+Shift+F，全局查找 Ctrl+F，查找/Shift+F3，向上查找/F3，向下查找 Ctrl+Shift+S，高级搜索 Ctrl+U，转到父类 Ctrl+Alt+S，打开设置对话框 Alt+Shift+Inert，开启/关闭列选择模式 Ctrl+Alt+Shift+S，打开当前项目/模块属性 Ctrl+G，定位行 Alt+Home，跳转到导航栏 Ctrl+Enter，上插一行 Ctrl+Backspace，按单词删除 Ctrl+”+/-“，当前方法展开、折叠 Ctrl+Shift+”+/-“，全部展开、折叠 调试部分、编译 Ctrl+F2，停止 Alt+Shift+F9，选择 Debug Alt+Shift+F10，选择 Run Ctrl+Shift+F9，编译 Ctrl+Shift+F10，运行 Ctrl+Shift+F8，查看断点 F8，步过 F7，步入 Shift+F7，智能步入 Shift+F8，步出 Alt+Shift+F8，强制步过 Alt+Shift+F7，强制步入 Alt+F9，运行至光标处 Ctrl+Alt+F9，强制运行至光标处 F9，恢复程序 Alt+F10，定位到断点 Ctrl+F8，切换行断点 Ctrl+F9，生成项目 Alt+1，项目 Alt+2，收藏 Alt+6，TODO Alt+7，结构 Ctrl+Shift+C，复制路径 Ctrl+Alt+Shift+C，复制引用，必须选择类名 Ctrl+Alt+Y，同步 Ctrl+~，快速切换方案（界面外观、代码风格、快捷键映射等菜单） Shift+F12，还原默认布局 Ctrl+Shift+F12，隐藏/恢复所有窗口 Ctrl+F4，关闭 Ctrl+Shift+F4，关闭活动选项卡 Ctrl+Tab，转到下一个拆分器 Ctrl+Shift+Tab，转到上一个拆分器 重构 Ctrl+Alt+Shift+T，弹出重构菜单 Shift+F6，重命名 F6，移动 F5，复制 Alt+Delete，安全删除 Ctrl+Alt+N，内联 查找 Ctrl+F，查找 Ctrl+R，替换 F3，查找下一个 Shift+F3，查找上一个 Ctrl+Shift+F，在路径中查找 Ctrl+Shift+R，在路径中替换 Ctrl+Shift+S，搜索结构 Ctrl+Shift+M，替换结构 Alt+F7，查找用法 Ctrl+Alt+F7，显示用法 Ctrl+F7，在文件中查找用法 Ctrl+Shift+F7，在文件中高亮显示用法 VCS Alt+~，VCS 操作菜单 Ctrl+K，提交更改 Ctrl+T，更新项目 Ctrl+Alt+Shift+D，显示变化","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://kanchai.club/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"IDEA快捷键","slug":"IDEA快捷键","permalink":"https://kanchai.club/tags/IDEA%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"Java实现天平秤秤球？","slug":"Java实现天平秤球","date":"2020-03-17T15:36:45.109Z","updated":"2020-03-17T15:35:16.000Z","comments":true,"path":"2020/03/17/Java实现天平秤球/","link":"","permalink":"https://kanchai.club/2020/03/17/Java%E5%AE%9E%E7%8E%B0%E5%A4%A9%E5%B9%B3%E7%A7%A4%E7%90%83/","excerpt":"一朋友发来一道面试题，百度半天没有很合适的，自己实现这个。题目：有N个铁球，其中一个是塑料球。仅使用一个天平，如何快速找到球？","text":"一朋友发来一道面试题，百度半天没有很合适的，自己实现这个。题目：有N个铁球，其中一个是塑料球。仅使用一个天平，如何快速找到球？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public static void main(String[] args) &#123; Boolean[] balls = new Boolean[] &#123; false, false, false, false, true, false, false System.out.println(\"已知的空球为:\" + balls[4].hashCode()); searchBall(balls, true);&#125;/** * 天平称重找出不同的球，此处通过打印hashCode来判断球的唯一标志 * * @param balls * @param findValue */public static void searchBall(Boolean[] balls, boolean findValue) &#123; System.out.println(\"称重.....\"); if (balls == null) &#123; return; &#125; int size = 0; int indexSize = 0; if (balls.length % 2 != 0) &#123; size = balls.length - 1; &#125; else &#123; size = balls.length; &#125; indexSize = size / 2; Boolean[] preBalls = Arrays.copyOfRange(balls, 0, indexSize); Boolean[] lastBalls = Arrays.copyOfRange(balls, indexSize, size); int weight1 = getWeight(preBalls); int weight2 = getWeight(lastBalls); if (weight1 == weight2) &#123; System.out.println(\"已找到不同的球：\" + balls[balls.length - 1].hashCode()); &#125; else if (weight1 &gt; weight2) &#123; if (lastBalls.length == 1) &#123; System.out.println(\"已找到不同的球：：\" + lastBalls[0].hashCode()); return; &#125; searchBall(lastBalls, findValue); &#125; else &#123; if (preBalls.length == 1) &#123; System.out.println(\"已找到不同的球：：\" + lastBalls[0].hashCode()); return; &#125; searchBall(preBalls, findValue); &#125;&#125;/** * 称重方法 * * @param balls * @return */public static int getWeight(Boolean[] balls) &#123; int count = 0; for (boolean b : balls) &#123; if (!b) &#123; count++; &#125; &#125; return count;&#125; 运行结果为:1234已知的空球为:1231称重.....称重.....已找到不同的球：：1231 可以看出来2次称重，找到不规则的球。","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"算法基础题","slug":"算法基础题","permalink":"https://kanchai.club/tags/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E9%A2%98/"}]},{"title":"一致性hash是什么意思？","slug":"一致性hash解释","date":"2020-03-17T15:36:44.999Z","updated":"2020-03-17T15:35:22.000Z","comments":true,"path":"2020/03/17/一致性hash解释/","link":"","permalink":"https://kanchai.club/2020/03/17/%E4%B8%80%E8%87%B4%E6%80%A7hash%E8%A7%A3%E9%87%8A/","excerpt":"在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么…","text":"在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么… &nbsp; 在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么，我们先来描述一下这个经典的分布式缓存的应用场景。 场景描述假设，我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为0号、1号、2号，现在，有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么，我们应该怎样做呢？如果我们没有任何规律的将3万张图片平均的缓存在3台服务器上，可以满足我们的要求吗？可以！但是如果这样做，当我们需要访问某个缓存项时，则需要遍历3台缓存服务器，从3万个缓存项中找到我们需要访问的缓存，遍历的过程效率太低，时间太长，当我们找到需要访问的缓存项时，时长可能是不能被接受的，也就失去了缓存的意义，缓存的目的就是提高速度，改善用户体验，减轻后端服务器压力，如果每次访问一个缓存项都需要遍历所有缓存服务器的所有缓存项，想想就觉得很累，那么，我们该怎么办呢？原始的做法是对缓存项的键进行哈希，将hash后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上，这样说可能不太容易理解，我们举例说明，仍然以刚才描述的场景为例，假设我们使用图片名称作为访问图片的key，假设图片名称是不重复的，那么，我们可以使用如下公式，计算出图片应该存放在哪台服务器上。 hash（图片名称）% N 因为图片的名称是不重复的，所以，当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的，如果我们有3台服务器，使用哈希后的结果对3求余，那么余数一定是0、1或者2，没错，正好与我们之前的服务器编号相同，如果求余的结果为0， 我们就把当前图片名称对应的图片缓存在0号服务器上，如果余数为1，就把当前图片名对应的图片缓存在1号服务器上，如果余数为2，同理，那么，当我们访问任意一个图片的时候，只要再次对图片名称进行上述运算，即可得出对应的图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可，如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了，通过这样的方法，即可将3万张图片随机的分布到3台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，这样就能满足我们的需求了，我们暂时称上述算法为HASH算法或者取模算法，取模算法的过程可以用下图表示。 但是，使用上述HASH算法进行缓存时，会出现一些缺陷，试想一下，如果3台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？没错，很简单，多增加两台缓存服务器不就行了，假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由3台变成了4台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变，换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据，同理，假设3台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从3台变为2台，如果想要访问一张图片，这张图片的缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义，由于大量缓存在同一时间失效，造成了缓存的雪崩，此时前端缓存已经无法起到承担部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述HASH算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。 &nbsp; 我们来回顾一下使用上述算法会出现的问题。 问题1：当缓存服务器数量发生变化时，会引起缓存的雪崩，可能会引起整体系统压力过大而崩溃（大量缓存同一时间失效）。 问题2：当缓存服务器数量发生变化时，几乎所有缓存的位置都会发生改变，怎样才能尽量减少受影响的缓存呢？ &nbsp; 其实，上面两个问题是一个问题，那么，一致性哈希算法能够解决上述问题吗？ 我们现在就来了解一下一致性哈希算法。 &nbsp; &nbsp; 一致性哈希算法的基本概念其实，一致性哈希算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性哈希算法是对2^32取模，什么意思呢？我们慢慢聊。 &nbsp; 首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆，示意图如下： 圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1&nbsp; 我们把这个由2的32次方个点组成的圆环称为hash环。 &nbsp; 那么，一致性哈希算法与上图中的圆环有什么关系呢？我们继续聊，仍然以之前描述的场景为例，假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产环境中，这三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模，可以使用如下公式示意。 hash（服务器A的IP地址） % &nbsp;2^32 通过上述公式算出的结果一定是一个0到2^32-1之间的一个整数，我们就用算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环上必定有一个点与这个整数对应，而我们刚才已经说明，使用这个整数代表服务器A，那么，服务器A就可以映射到这个环上，用下图示意 同理，服务器B与服务器C也可以通过相同的方法映射到上图中的hash环中 hash（服务器B的IP地址） % &nbsp;2^32 hash（服务器C的IP地址） % &nbsp;2^32 通过上述方法，可以将服务器B与服务器C映射到上图中的hash环上，示意图如下 假设3台服务器映射到hash环上以后如上图所示（当然，这是理想的情况，我们慢慢聊）。 &nbsp; 好了，到目前为止，我们已经把缓存服务器与hash环联系在了一起，我们通过上述方法，把缓存服务器映射到了hash环上，那么使用同样的方法，我们也可以将需要缓存的对象映射到hash环上。 &nbsp; 假设，我们需要使用缓存服务器缓存图片，而且我们仍然使用图片的名称作为找到图片的key，那么我们使用如下公式可以将图片映射到上图中的hash环上。 hash（图片名称） % &nbsp;2^32 映射后的示意图如下，下图中的橘黄色圆形表示图片 好了，现在服务器与图片都被映射到了hash环上，那么上图中的这个图片到底应该被缓存到哪一台服务器上呢？上图中的图片将会被缓存到服务器A上，为什么呢？因为从图片的位置开始，沿顺时针方向遇到的第一个服务器就是A服务器，所以，上图中的图片将会被缓存到服务器A上，如下图所示。 没错，一致性哈希算法就是通过这种方法，判断一个对象应该被缓存到哪台服务器上的，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一张图片必定会被缓存到固定的服务器上，那么，当下次想要访问这张图片时，只要再次使用相同的算法进行计算，即可算出这个图片被缓存在哪个服务器上，直接去对应的服务器查找对应的图片即可。 &nbsp; 刚才的示例只使用了一张图片进行演示，假设有四张图片需要缓存，示意图如下 1号、2号图片将会被缓存到服务器A上，3号图片将会被缓存到服务器B上，4号图片将会被缓存到服务器C上。 &nbsp; &nbsp; 一致性哈希算法的优点经过上述描述，我想兄弟你应该已经明白了一致性哈希算法的原理了，但是话说回来，一致性哈希算法能够解决之前出现的问题吗，我们说过，如果简单的对服务器数量进行取模，那么当服务器数量发生变化时，会产生缓存的雪崩，从而很有可能导致系统崩溃，那么使用一致性哈希算法，能够避免这个问题吗？我们来模拟一遍，即可得到答案。 &nbsp; 假设，服务器B出现了故障，我们现在需要将服务器B移除，那么，我们将上图中的服务器B从hash环上移除即可，移除服务器B以后示意图如下。 在服务器B未移除时，图片3应该被缓存到服务器B中，可是当服务器B移除以后，按照之前描述的一致性哈希算法的规则，图片3应该被缓存到服务器C中，因为从图片3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器C，也就是说，如果服务器B出现故障被移除时，图片3的缓存位置会发生改变 &nbsp; &nbsp; 但是，图片4仍然会被缓存到服务器C中，图片1与图片2仍然会被缓存到服务器A中，这与服务器B移除之前并没有任何区别，这就是一致性哈希算法的优点，如果使用之前的hash算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分缓存会失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一时间集中到后端服务器上。 &nbsp; 这就是一致性哈希算法所体现出的优点。 &nbsp; &nbsp; hash环的偏斜在介绍一致性哈希的概念时，我们理想化的将3台服务器均匀的映射到了hash环上，如下图所示 但是，理想很丰满，现实很骨感，我们想象的与实际情况往往不一样。 在实际的映射中，服务器可能会被映射成如下模样。 聪明如你一定想到了，如果服务器被映射成上图中的模样，那么被缓存的对象很有可能大部分集中缓存在某一台服务器上，如下图所示。 上图中，1号、2号、3号、4号、6号图片均被缓存在了服务器A上，只有5号图片被缓存在了服务器B上，服务器C上甚至没有缓存任何图片，如果出现上图中的情况，A、B、C三台服务器并没有被合理的平均的充分利用，缓存分布的极度不均匀，而且，如果此时服务器A出现故障，那么失效缓存的数量也将达到最大值，在极端情况下，仍然有可能引起系统的崩溃，上图中的情况则被称之为hash环的偏斜，那么，我们应该怎样防止hash环的偏斜呢？一致性hash算法中使用”虚拟节点”解决了这个问题，我们继续聊。 &nbsp; &nbsp; 虚拟节点话接上文，由于我们只有3台服务器，当我们把服务器映射到hash环上的时候，很有可能出现hash环偏斜的情况，当hash环偏斜以后，缓存往往会极度不均衡的分布在各服务器上，聪明如你一定已经想到了，如果想要均衡的将缓存分布到3台服务器上，最好能让这3台服务器尽量多的、均匀的出现在hash环上，但是，真实的服务器资源只有3台，我们怎样凭空的让它们多起来呢，没错，就是凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。加入虚拟节点以后的hash环如下。 “虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。 从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了，上图中，1号、3号图片被缓存在服务器A中，5号、4号图片被缓存在服务器B中，6号、2号图片被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点，以便减小hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 &nbsp; &nbsp; 好了，一致性哈希算法的原理就总结到这里，如有错误，欢迎赐教，如需转载，请联系作者。 原文链接：白话解析：一致性哈希算法 consistent hashing &nbsp;","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://kanchai.club/tags/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Redis基本介绍","slug":"Redis基本介绍","date":"2020-03-17T15:36:44.819Z","updated":"2020-03-17T15:35:35.000Z","comments":true,"path":"2020/03/17/Redis基本介绍/","link":"","permalink":"https://kanchai.club/2020/03/17/Redis%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/","excerpt":"Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。","text":"Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。 Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。 特性 速度快，数据放在内存中，官方给出的读写性能10万/S，与机器性能也有关 数据放内存中是速度快的主要原因 C语言实现，与操作系统距离近 使用了单线程架构，预防多线程可能产生的竞争问题 键值对的数据结构服务器 丰富的功能：见上功能 简单稳定：单线程 持久化：发生断电或机器故障，数据可能会丢失，持久化到硬盘 主从复制：实现多个相同数据的redis副本 高可用和分布式：哨兵机制实现高可用，保证redis节点故障发现和自动转移 客户端语言多：java php python c c++ nodejs等 使用场景 缓存：合理使用缓存加快数据访问速度，降低后端数据源压力 排行榜：按照热度排名，按照发布时间排行，主要用到列表和有序集合 计数器应用：视频网站播放数，网站浏览数，使用redis计数 社交网络：赞、踩、粉丝、下拉刷新 消息队列：发布和订阅 常用客户端命令 可执行文件 作用 redis-server 启动redis redis-cli redis命令行客户端 redis-benchmark 基准测试工具 redis-check-aof AOF持久化文件检测和修复工具 redis-check-dump RDB持久化文件检测和修复工具 redis-sentinel 启动哨兵 &gt;1. redis-server启动： &gt;&gt;1. 默认配置：redis-server, 日志输出版本信息，端口6379 &gt;&gt;2. 运行启动：redis-server –port 6380 不建议 &gt;&gt;3. 配置文件启动： redis-server /opt/redis/redis.conf，灵活，生产环境使用这种 &gt;2. redis-cli 启动 &gt;&gt;1. 交互式：redis-cli -h {host} -p {prot}连接到redis服务，没有h默认连127.0 redis-cli -h 127.0.0.1 -p 6379 //没有p 默认连6379 &gt;&gt;2. 命令式：redis-cli -h 127.0.0.1 -p 6379 get hello //取key=hello的value &gt;3. 停止redis服务： redis-cli shutdown &gt;&gt;* a.关闭时：断开连接，持久化文件生成，相对安 &gt;&gt;* b.还可以用kill关闭，此方式不会做持久化，还会造成缓冲区非法关闭，可能会造成AOF和丢失数据 &gt;4. 版本： &gt;&gt;* 版本号第二位为奇数，为非稳定版本（2.7、2.9、3.1） &gt;&gt;* 第二为偶数，为稳定版本（2.6、2.8、3.0） &gt;&gt;* 当前奇数版本是下一个稳定版本的开发版本，如2.9是3.0的开发版本","categories":[{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/categories/Redis/"}],"tags":[{"name":"redis基本介绍","slug":"redis基本介绍","permalink":"https://kanchai.club/tags/redis%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"}]},{"title":"POI-Excel的导出导入","slug":"并发编程-线程基础-基础概念","date":"2020-03-17T15:36:44.711Z","updated":"2020-03-17T15:35:39.000Z","comments":true,"path":"2020/03/17/并发编程-线程基础-基础概念/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"计算机中线程的基本概念","text":"计算机中线程的基本概念 计算机中线程的基本概念 CPU核心数，线程数之间有什么关系？ CPU核心数量和线程数量一般情况下为1:1的关系，但是使用了超线程技术后，比例为1:2，这个技术是指CPU的工业技术。window可以在任务管理器查看，就是我们常说的4核八线程，4核4线程。 什么是指CPU时间片轮转机制？ 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。每个进程被分配一时间段，称作它的时间片，即该进程允许运行的时间。又叫RR调度，在JAVA中过多的线程会导致上下文切换。比如你4核4线程，你new了8个线程，那么其实4个物理线程公平的分配给8个JAVA线程使用。 什么是进程和线程? 进程:程序运行资源分配的最小单位，进程内部有多个线程，会共享这个进程的资源 线程:CPU调度的最小单位，必须依赖进程而存在。 什么是并发和并行? 并行:同一时刻，可以同时处理事情的能力 并发:与单位时间相关，在单位时间内可以处理事情的能力 高并发编程的意义、好处和注意事项 好处:充分利用cpu的资源、加快用户响应的时间，程序模块化，异步化 问题:线程共享资源，存在冲突；容易导致死锁；启用太多的线程，就有搞垮机器的可能","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://kanchai.club/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"计算机线程","slug":"计算机线程","permalink":"https://kanchai.club/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BA%BF%E7%A8%8B/"}]},{"title":"SpringBoot配置","slug":"springboot配置","date":"2020-03-17T15:36:44.596Z","updated":"2020-03-17T15:36:00.000Z","comments":true,"path":"2020/03/17/springboot配置/","link":"","permalink":"https://kanchai.club/2020/03/17/springboot%E9%85%8D%E7%BD%AE/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179# ----------------------------------------# 核心属性# ----------------------------------------# 文件编码banner.charset&#x3D; UTF-8# 文件位置banner.location&#x3D; classpath:banner.txt# 日志配置# 日志配置文件的位置。 例如对于Logback的&#96;classpath：logback.xml&#96;logging.config&#x3D; # ％wEx#记录异常时使用的转换字。logging.exception-conversion-word&#x3D; # 日志文件名。 例如&#96;myapp.log&#96;logging.file&#x3D; # 日志级别严重性映射。 例如&#96;logging.level.org.springframework &#x3D; DEBUG&#96;logging.level.*&#x3D; # 日志文件的位置。 例如&#96;&#x2F; var &#x2F; log&#96;logging.path&#x3D; # 用于输出到控制台的Appender模式。 只支持默认的logback设置。logging.pattern.console&#x3D; # 用于输出到文件的Appender模式。 只支持默认的logback设置。logging.pattern.file&#x3D; # 日志级别的Appender模式（默认％5p）。 只支持默认的logback设置。logging.pattern.level&#x3D; #注册日志记录系统的初始化挂钩。logging.register-shutdown-hook&#x3D; false# AOP 切面# 添加@EnableAspectJAutoProxy。spring.aop.auto&#x3D; true# 是否要创建基于子类（CGLIB）的代理（true），而不是基于标准的基于Java接口的代理（false）。spring.aop.proxy-target-class&#x3D; false# 应用程序上下文初始化器# 应用指标。spring.application.index&#x3D; # 应用程序名称。spring.application.name&#x3D; # 国际化（消息源自动配置）#spring.messages.basename&#x3D; messages# 以逗号分隔的基础名称列表，每个都在ResourceBundle约定之后。# 加载的资源束文件缓存到期，以秒为单位。 设置为-1时，软件包将永久缓存。spring.messages.cache-seconds&#x3D; -1# 消息编码。spring.messages.encoding&#x3D; UTF-8# 设置是否返回到系统区域设置，如果没有找到特定语言环境的文件。spring.messages.fallback-to-system-locale&#x3D; true# REDIS (Redis 配置)# 连接工厂使用的数据库索引。spring.redis.database&#x3D; 0# Redis服务器主机。spring.redis.host&#x3D; localhost# 登录redis服务器的密码。spring.redis.password&#x3D; # 给定时间池可以分配的最大连接数。 使用负值为无限制。spring.redis.pool.max-active&#x3D; 8# 池中“空闲”连接的最大数量。 使用负值来表示无限数量的空闲连接。spring.redis.pool.max-idle&#x3D; 8# 连接分配在池耗尽之前在抛出异常之前应阻止的最大时间量（以毫秒为单位）。 使用负值无限期地阻止。spring.redis.pool.max-wait&#x3D; -1# 定义池中维护的最小空闲连接数。 此设置只有在正值时才有效果。spring.redis.pool.min-idle&#x3D; 0# redis服务器端口spring.redis.port&#x3D; 6379# redis服务器名称spring.redis.sentinel.master&#x3D;# spring.redis.sentinel.nodes&#x3D; # 连接超时（毫秒）。spring.redis.timeout&#x3D; 0# 管理员 （Spring应用程序管理员JMX自动配置）# 开启应用管理功能。spring.application.admin.enabled&#x3D; false# JMX应用程序名称MBean。spring.application.admin.jmx-name&#x3D; org.springframework.boot:type&#x3D; Admin,name&#x3D; SpringApplication# 自动配置# 自动配置类排除。spring.autoconfigure.exclude&#x3D; # spring 核心配置# 跳过搜索BeanInfo类。spring.beaninfo.ignore&#x3D; true# spring 缓存配置# 由底层缓存管理器支持的要创建的缓存名称的逗号分隔列表。spring.cache.cache-names&#x3D; # 用于初始化EhCache的配置文件的位置。spring.cache.ehcache.config&#x3D; # 用于创建缓存的规范。 检查CacheBuilderSpec有关规格格式的更多细节。spring.cache.guava.spec&#x3D; # 用于初始化Hazelcast的配置文件的位置。spring.cache.hazelcast.config&#x3D; # 用于初始化Infinispan的配置文件的位置。spring.cache.infinispan.config&#x3D; # 用于初始化缓存管理器的配置文件的位置。spring.cache.jcache.config&#x3D; # 用于检索符合JSR-107的缓存管理器的CachingProvider实现的完全限定名称。 只有在类路径上有多个JSR-107实现可用时才需要。spring.cache.jcache.provider&#x3D; # 缓存类型，默认情况下根据环境自动检测。spring.cache.type&#x3D; # spring配置 （配置文件应用侦听器）# 配置文件位置。spring.config.location&#x3D; # 配置文件名。spring.config.name&#x3D; application# hazelcast配置(Hazelcast是一个高度可扩展的数据分发和集群平台，提供了高效的、可扩展的分布式数据存储、数据缓存.)# 用于初始化Hazelcast的配置文件的位置。spring.hazelcast.config&#x3D; # JMX# JMX域名。spring.jmx.default-domain&#x3D; # 将管理bean暴露给JMX域。spring.jmx.enabled&#x3D; true# MBean服务器bean名称。spring.jmx.server&#x3D; mbeanServer# Email (MailProperties) 邮件属性# 默认MimeMessage编码。spring.mail.default-encoding&#x3D; UTF-8# SMTP服务器主机。 例如&#96;smtp.example.com&#96;spring.mail.host&#x3D; # 会话JNDI名称。 设置时，优先于其他邮件设置。spring.mail.jndi-name&#x3D; # 登录SMTP服务器的密码。spring.mail.password&#x3D; # SMTP服务器端口。spring.mail.port&#x3D; # 其他JavaMail会话属性。spring.mail.properties.*&#x3D; # SMTP服务器使用的协议。spring.mail.protocol&#x3D; smtp# 测试邮件服务器在启动时可用。spring.mail.test-connection&#x3D; false# 登录SMTP服务器的用户。spring.mail.username&#x3D; # 应用设置（spring应用）# 用于在应用程序运行时显示横幅的模式。spring.main.banner-mode&#x3D; console# 源（类名，包名或XML资源位置）包含在ApplicationContext中。spring.main.sources&#x3D; # 在Web环境中运行应用程序（默认情况下自动检测）。spring.main.web-environment&#x3D; # 文件编码（文件编码应用程序侦听器）# 应用程序使用的预期字符编码。spring.mandatory-file-encoding&#x3D; # 输出# 配置ANSI输出（可以是“detect”，“always”，“never”）--&gt;“检测”，“永远”，“从不”spring.output.ansi.enabled&#x3D; detect# PID文件（应用程序文件写入器）# 如果使用ApplicationPidFileWriter但是无法写入PID文件，则失败。spring.pid.fail-on-write-error&#x3D; # 要写入的PID文件的位置（如果使用ApplicationPidFileWriter）。spring.pid.file&#x3D; # 简介（profiles 这个单词翻译过来就是这样... 没用过这个属性，有哪位大神用过请留言我改正，感谢。）# 活动配置文件的逗号分隔列表。spring.profiles.active&#x3D; # 无条件地激活指定的逗号分隔的配置文件。spring.profiles.include&#x3D; # SendGrid（SendGrid自动配置）# SendGrid帐号用户名spring.sendgrid.username&#x3D; # SendGrid帐号密码spring.sendgrid.password&#x3D; # SendGrid代理主机spring.sendgrid.proxy.host&#x3D; # SendGrid代理端口spring.sendgrid.proxy.port&#x3D; # ----------------------------------------# WEB属性# ----------------------------------------# 文件上传属性# 启用对文件上传的支持。multipart.enabled&#x3D; true# 将文件写入磁盘后的阈值。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.file-size-threshold&#x3D; 0# 上传文件的位置。multipart.location&#x3D; # 最大文件大小。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.max-file-size&#x3D; 1Mb# 最大请求大小。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.max-request-size&#x3D; 10Mb# 嵌入式服务器配置（服务器属性）# 服务器应绑定到的网络地址。server.address&#x3D; # 如果启用响应压缩。server.compression.enabled&#x3D; false# 从压缩中排除的用户代理列表。server.compression.excluded-user-agents&#x3D; # 应该压缩的MIME类型的逗号分隔列表。 例如&#96;text &#x2F; html，text &#x2F; css，application &#x2F; json&#96;server.compression.mime-types&#x3D; # 执行压缩所需的最小响应大小。 例如2048server.compression.min-response-size&#x3D; # Servlet上下文初始化参数。 例如&#96;server.context-parameters.a &#x3D; alpha&#96;server.context-parameters.*&#x3D; # 应用程序的上下文路径。server.context-path&#x3D; # 显示应用程序的名称。server.display-name&#x3D; application# 何时包含“stacktrace”属性。server.error.include-stacktrace&#x3D; never# 错误控制器的路径。server.error.path&#x3D; &#x2F;error# 启动浏览器中出现服务器错误时显示的默认错误页面。server.error.whitelabel.enabled&#x3D; true# JSP servlet的类名。server.jsp-servlet.class-name&#x3D; org.apache.jasper.servlet.JspServlet# Init参数用于配置JSP servletserver.jsp-servlet.init-parameters.*&#x3D; # JSP servlet是否被注册server.jsp-servlet.registered&#x3D; true# 服务器HTTP端口。server.port&#x3D; 8080# 主调度程序servlet的路径。server.servlet-path&#x3D; &#x2F;# 会话cookie的注释。server.session.cookie.comment&#x3D; # 会话cookie的域。server.session.cookie.domain&#x3D; # “HttpOnly”标志为会话cookie。server.session.cookie.http-only&#x3D; # 会话cookie的最大时长（以秒为单位）。server.session.cookie.max-age&#x3D; # 会话cookie名称。server.session.cookie.name&#x3D; # 会话cookie的路径。server.session.cookie.path&#x3D; # 会话cookie的“安全”标志。server.session.cookie.secure&#x3D; # 重启之间持续会话数据。server.session.persistent&#x3D; false# 用于存储会话数据的目录。server.session.store-dir&#x3D; # 会话超时（秒）。server.session.timeout&#x3D; # 会话跟踪模式（以下一个或多个：“cookie”，“url”，“ssl”）。server.session.tracking-modes&#x3D; # 支持SSL密码。server.ssl.ciphers&#x3D; # 客户端认证是否需要（“want”）或需要（“need”）。 需要信任存储。server.ssl.client-auth&#x3D; # ssl配置server.ssl.enabled&#x3D; server.ssl.key-alias&#x3D; server.ssl.key-password&#x3D; server.ssl.key-store&#x3D; server.ssl.key-store-password&#x3D; server.ssl.key-store-provider&#x3D; server.ssl.key-store-type&#x3D; server.ssl.protocol&#x3D; server.ssl.trust-store&#x3D; server.ssl.trust-store-password&#x3D; server.ssl.trust-store-provider&#x3D; server.ssl.trust-store-type&#x3D; # 创建日志文件的目录。 可以相对于tomcat base dir或absolute。server.tomcat.accesslog.directory&#x3D; # 启用访问日志。server.tomcat.accesslog.enabled&#x3D; false# 访问日志的格式化模式。server.tomcat.accesslog.pattern&#x3D; common# 日志文件名前缀。server.tomcat.accesslog.prefix&#x3D; access_log# 日志文件名后缀。server.tomcat.accesslog.suffix&#x3D; .log# 在调用backgroundProcess方法之间延迟秒。server.tomcat.background-processor-delay&#x3D; 30# Tomcat基本目录。 如果未指定，将使用临时目录。server.tomcat.basedir&#x3D; # 正则表达式匹配可信IP地址。server.tomcat.internal-proxies&#x3D; 10\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\192\\\\.168\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\169\\\\.254\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\127\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.1[6-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.2[0-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.3[0-1]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;# HTTP消息头的最大大小（以字节为单位）。server.tomcat.max-http-header-size&#x3D; 0# 最大工作线程数。server.tomcat.max-threads&#x3D; 0# 用于覆盖原始端口值的HTTP头的名称。server.tomcat.port-header&#x3D; X-Forwarded-Port# 头文件，保存传入协议，通常命名为“X-Forwarded-Proto”。server.tomcat.protocol-header&#x3D; # 表示传入请求使用SSL的协议头的值。server.tomcat.protocol-header-https-value&#x3D; https# 提取远程ip的HTTP头的名称。 例如&#96;X-FORWARDED-FOR&#96;server.tomcat.remote-ip-header&#x3D; # 用于解码URI的字符编码。server.tomcat.uri-encoding&#x3D; UTF-8# 访问日志目录。server.undertow.accesslog.dir&#x3D; # 启用访问日志。server.undertow.accesslog.enabled&#x3D; false# 访问日志的格式化模式。server.undertow.accesslog.pattern&#x3D; common# 每个缓冲区的大小字节数。server.undertow.buffer-size&#x3D; # 每个区域的缓冲区数。server.undertow.buffers-per-region&#x3D; # 在Java堆之外分配缓冲区。server.undertow.direct-buffers&#x3D; # 为工作者创建的I &#x2F; O线程数。server.undertow.io-threads&#x3D; # 工作线程数。server.undertow.worker-threads&#x3D; # 如果X-Forwarded- *头应该应用于HttpRequest。server.use-forward-headers&#x3D; # 自由标记（自由标记自动配置）# 设置是否允许HttpServletRequest属性重写（隐藏）控制器生成的同名模型属性。spring.freemarker.allow-request-override&#x3D; false# 设置是否允许HttpSession属性重写（隐藏）控制器生成的相同名称的模型属性。spring.freemarker.allow-session-override&#x3D; false# 启用模板缓存。spring.freemarker.cache&#x3D; false# 模板编码。spring.freemarker.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.freemarker.check-template-location&#x3D; true# Content-Type值。spring.freemarker.content-type&#x3D; text&#x2F;html# 启用此技术的MVC视图分辨率。spring.freemarker.enabled&#x3D; true# 设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.freemarker.expose-request-attributes&#x3D; false# 设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.freemarker.expose-session-attributes&#x3D; false# 设置是否公开一个RequestContext供Spring 的宏库使用，名称为“springMacroRequestContext”。spring.freemarker.expose-spring-macro-helpers&#x3D; true# 首选文件系统访问模板加载。 文件系统访问可以对模板更改进行热检测。spring.freemarker.prefer-file-system-access&#x3D; true# 前缀，在构建URL时先查看名称。spring.freemarker.prefix&#x3D; # 所有视图的RequestContext属性的名称。spring.freemarker.request-context-attribute&#x3D; # 公开的FreeMarker密钥将被传递给FreeMarker的配置。spring.freemarker.settings.*&#x3D; # 后缀，在构建URL时附加到查看名称。spring.freemarker.suffix&#x3D; # 逗号分隔的模板路径列表。spring.freemarker.template-loader-path&#x3D; classpath:&#x2F;templates&#x2F;# 可以解决的视图名称的白名单。spring.freemarker.view-names&#x3D; # groovr模板（Groovy模板自动配置）# 设置是否允许HttpServletRequest属性重写（隐藏）控制器生成的同名模型属性。spring.groovy.template.allow-request-override&#x3D; false# 设置是否允许HttpSession属性重写（隐藏）控制器生成的相同名称的模型属性。spring.groovy.template.allow-session-override&#x3D; false# 启用模板缓存。spring.groovy.template.cache&#x3D; # 模板编码。spring.groovy.template.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.groovy.template.check-template-location&#x3D; true# 请参阅GroovyMarkupConfigurerspring.groovy.template.configuration.*&#x3D; # Content-Type值。spring.groovy.template.content-type&#x3D; test&#x2F;html# 启用此技术的MVC视图分辨率。spring.groovy.template.enabled&#x3D; true# 设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.groovy.template.expose-request-attributes&#x3D; false# 设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.groovy.template.expose-session-attributes&#x3D; false# 设置是否公开一个RequestContext供Spring Spring的宏库使用，名称为“springMacroRequestContext”。spring.groovy.template.expose-spring-macro-helpers&#x3D; true# 前缀，在构建URL时先查看名称。spring.groovy.template.prefix&#x3D; # 所有视图的RequestContext属性的名称。spring.groovy.template.request-context-attribute&#x3D; # 模板路径。spring.groovy.template.resource-loader-path&#x3D; classpath:&#x2F;templates&#x2F;# 后缀，在构建URL时附加到查看名称。spring.groovy.template.suffix&#x3D; .tpl# 可以解决的视图名称的白名单。spring.groovy.template.view-names&#x3D; # spring Hateoas 配置# 指定应用程序&#x2F; hal + json响应是否应发送到接受application &#x2F; json的请求。spring.hateoas.use-hal-as-default-json-media-type&#x3D; true# HTTP 消息转换# 首选JSON映射程序用于HTTP消息转换。 设置为“gson”强制使用Gson，当它和Jackson都在类路径上时。spring.http.converters.preferred-json-mapper&#x3D; jackson# HTTP 编码（Http编码属性）# HTTP请求和响应的字符集。 如果未明确设置，则添加到“Content-Type”头。spring.http.encoding.charset&#x3D; UTF-8# 启用http编码支持。spring.http.encoding.enabled&#x3D; true# 将编码强制到HTTP请求和响应上配置的字符集。spring.http.encoding.force&#x3D; true# Jackson(解析json和序列化json) 配置# 日期格式字符串或全限定日期格式类名。 例如&#96;yyyy-MM-dd HH：mm：ss&#96;。spring.jackson.date-format&#x3D; # Jones开&#x2F;关功能，影响Java对象反序列化的方式。spring.jackson.deserialization.*&#x3D; # 关闭或者打开Jackson 功能spring.jackson.generator.*&#x3D; # Joda日期时间格式字符串。 如果未配置，如果配置了格式字符串，则“日期格式”将用作后备。spring.jackson.joda-date-time-format&#x3D; # 用于格式化的区域设置。spring.jackson.locale&#x3D; # jackson通用开&#x2F;关功能。spring.jackson.mapper.*&#x3D; # Jackson 解析器的开&#x2F;关功能。spring.jackson.parser.*&#x3D; # Jackson的PropertyNamingStrategy的一个常量。 也可以是PropertyNamingStrategy子类的完全限定类名。spring.jackson.property-naming-strategy&#x3D; # Jones开&#x2F;关功能，影响Java对象序列化的方式。spring.jackson.serialization.*&#x3D; # 控制在序列化期间包含属性。 配置了Jackson的JsonInclude.Include枚举中的一个值。spring.jackson.serialization-inclusion&#x3D; # 格式化日期时使用的时区。 例如&#96;America &#x2F; Los_Angeles&#96;spring.jackson.time-zone&#x3D; # Jersey 配置# 作为应用程序的基本URI的路径。 如果指定，则覆盖“@ApplicationPath”的值。spring.jersey.application-path&#x3D; # jersey过滤器链顺序。spring.jersey.filter.order&#x3D; 0# init参数传递到Jersey通过servlet或过滤器。spring.jersey.init.*&#x3D; # jersey整合型。可以是“servlet”也可以是“filter”。spring.jersey.type&#x3D; servlet# spring 视图分解器 配置# 启用后退解析支持。spring.mobile.devicedelegatingviewresolver.enable-fallback&#x3D; false# 启用设备视图解析器。spring.mobile.devicedelegatingviewresolver.enabled&#x3D; false# 前缀，用于查看移动设备的名称。spring.mobile.devicedelegatingviewresolver.mobile-prefix&#x3D; mobile&#x2F;# 后缀，附加到查看移动设备的名称。spring.mobile.devicedelegatingviewresolver.mobile-suffix&#x3D; # 前缀，用于查看普通设备的名称。spring.mobile.devicedelegatingviewresolver.normal-prefix&#x3D; # 后缀，附加到查看普通设备的名称。spring.mobile.devicedelegatingviewresolver.normal-suffix&#x3D; # 前缀，用于查看平板设备的名称。spring.mobile.devicedelegatingviewresolver.tablet-prefix&#x3D; tablet&#x2F;# 后缀，附加到查看平板电脑设备的名称。spring.mobile.devicedelegatingviewresolver.tablet-suffix&#x3D; # 移动网站首选项 （站点首选项自动配置）# 启用SitePreferenceHandler。spring.mobile.sitepreference.enabled&#x3D; true# MUSTACHE模板（Mustache AutoConfiguration）# 启用模板缓存。spring.mustache.cache&#x3D; false# 模板编码。spring.mustache.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.mustache.check-template-location&#x3D; true# Content-Type值spring.mustache.content-type&#x3D; text&#x2F;html# 启用此技术的MVC视图分辨率。spring.mustache.enabled&#x3D; true# 前缀应用于模板名称。spring.mustache.prefix&#x3D; classpath:&#x2F;templates&#x2F;# 后缀应用于模板名称。spring.mustache.suffix&#x3D; .html# 可以解决的视图名称的白名单。spring.mustache.view-names&#x3D; # SPRING MVC (Web Mvc 配置)# 异步请求处理超时之前的时间量（以毫秒为单位）。spring.mvc.async.request-timeout&#x3D; # 要使用的日期格式。 例如&#96;dd &#x2F; MM &#x2F; yyyy&#96;。spring.mvc.date-format&#x3D; # 发送TRACE请求到FrameworkServlet doService方法。spring.mvc.dispatch-trace-request&#x3D; false# 发送OPTIONS请求到FrameworkServlet doService方法。spring.mvc.dispatch-options-request&#x3D; false# 启用favicon.ico的解析。spring.mvc.favicon.enabled&#x3D; true# 如果在重定向方案期间应该忽略“默认”模型的内容。spring.mvc.ignore-default-model-on-redirect&#x3D; true# 要使用的区域设置。spring.mvc.locale&#x3D; # 将文件扩展名映射到内容协商的媒体类型。spring.mvc.media-types.*&#x3D; # 消息代码格式策略。 例如&#96;PREFIX_ERROR_CODE&#96;。spring.mvc.message-codes-resolver-format&#x3D; # 用于静态资源的路径模式。spring.mvc.static-path-pattern&#x3D; &#x2F;**# 如果没有发现处理程序来处理请求，则应抛出“NoHandlerFoundException”。spring.mvc.throw-exception-if-no-handler-found&#x3D; false# Spring MVC视图前缀。spring.mvc.view.prefix&#x3D; # Spring MVC视图后缀。spring.mvc.view.suffix&#x3D; #SPRING RESOURCES HANDLING（ResourceProperties）资源处理spring.resources.add-mappings &#x3D; true #启用默认资源处理。spring.resources.cache-period &#x3D; #由资源处理程序提供的资源的缓存期，以秒为单位。spring.resources.chain.cache &#x3D; true #在资源链中启用缓存。spring.resources.chain.enabled &#x3D; #启用Spring资源处理链。默认情况下禁用，除非启用了至少一个策略。spring.resources.chain.html-application-cache &#x3D; false #启用HTML5应用程序缓存清单重写。spring.resources.chain.strategy.content.enabled &#x3D; false #启用内容版本策略。spring.resources.chain.strategy.content.paths &#x3D; &#x2F; ** #应用于版本策略的模式的逗号分隔列表。spring.resources.chain.strategy.fixed.enabled &#x3D; false #启用固定版本策略。spring.resources.chain.strategy.fixed.paths &#x3D; #应用于版本策略的逗号分隔的模式列表。spring.resources.chain.strategy.fixed.version &#x3D; #用于版本策略的版本字符串。spring.resources.static-locations &#x3D; classpath：&#x2F; META-INF &#x2F; resources &#x2F;，classpath：&#x2F; resources &#x2F;，classpath：&#x2F; static &#x2F;，classpath：&#x2F; public &#x2F; #静态资源的位置。 #SPRING SOCIAL（SocialWebAutoConfiguration）集群spring.social.auto-connection-views &#x3D; false #启用支持的提供程序的连接状态视图。 #SPRING SOCIAL FACEBOOK（FacebookAutoConfiguration）spring.social.facebook.app-id &#x3D; #您的应用程序的Facebook应用程序IDspring.social.facebook.app-secret &#x3D; #你的应用程序的Facebook应用程序密码 #SPRING SOCIAL LINKEDIN（LinkedInAutoConfiguration）spring.social.linkedin.app-id &#x3D; #您的应用程序的LinkedIn应用程序IDspring.social.linkedin.app-secret &#x3D; #您的应用程序的LinkedIn App Secret #SPRING SOCIAL TWITTER（TwitterAutoConfiguration）spring.social.twitter.app-id &#x3D; #你的应用程序的Twitter应用程序IDspring.social.twitter.app-secret &#x3D; #你的应用程序的Twitter App Secret #THYMELEAF Thymeleaf模板引擎配置spring.thymeleaf.cache &#x3D; true #启用模板缓存。spring.thymeleaf.check-template-location &#x3D; true #检查模板位置是否存在。spring.thymeleaf.content-type &#x3D; text &#x2F; html #Content-Type值。spring.thymeleaf.enabled &#x3D; true #启用MVC Thymeleaf视图分辨率。spring.thymeleaf.encoding &#x3D; UTF-8 #模板编码。spring.thymeleaf.excluded-view-names &#x3D; #应该从解决方案中排除的视图名称的逗号分隔列表。spring.thymeleaf.mode &#x3D; HTML5 #应用于模板的模板模式。另请参见StandardTemplateModeHandlers。spring.thymeleaf.prefix &#x3D; classpath：&#x2F; templates &#x2F; #在构建URL时预先查看名称的前缀。spring.thymeleaf.suffix &#x3D; .html #构建URL时附加查看名称的后缀。spring.thymeleaf.template-resolver-order &#x3D; #链中模板解析器的顺序。spring.thymeleaf.view-names &#x3D; #可以解析的视图名称的逗号分隔列表。 #VELOCITY TEMPLATES（VelocityAutoConfiguration）spring.velocity.allow-request-override &#x3D; false #设置是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名的模型属性。spring.velocity.allow-session-override &#x3D; false #设置是否允许HttpSession属性重写（隐藏）控制器生成的同名的模型属性。spring.velocity.cache &#x3D; #启用模板缓存。spring.velocity.charset &#x3D; UTF-8 #模板编码。spring.velocity.check-template-location &#x3D; true #检查模板位置是否存在。spring.velocity.content-type &#x3D; text &#x2F; html #Content-Type值。spring.velocity.date-tool-attribute &#x3D; #在视图的Velocity上下文中公开的DateTool辅助对象的名称。spring.velocity.enabled &#x3D; true #启用此技术的MVC视图分辨率。spring.velocity.expose-request-attributes &#x3D; false #设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.velocity.expose-session-attributes &#x3D; false #设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.velocity.expose-spring-macro-helpers &#x3D; true #设置是否公开一个RequestContext供Spring Spring的宏库使用，名称为“springMacroRequestContext”。spring.velocity.number-tool-attribute &#x3D; #在视图的Velocity上下文中公开的NumberTool帮助对象的名称。spring.velocity.prefer-file-system-access &#x3D; true #首选文件系统访问模板加载。文件系统访问可以对模板更改进行热检测。spring.velocity.prefix &#x3D; #前缀，用于在构建URL时查看名称。spring.velocity.properties。* &#x3D; #附加速度属性。spring.velocity.request-context-attribute &#x3D; #所有视图的RequestContext属性的名称。spring.velocity.resource-loader-path &#x3D; classpath：&#x2F; templates &#x2F; #模板路径。spring.velocity.suffix &#x3D; .vm #构建URL时附加到查看名称的后缀。spring.velocity.toolbox-config-location &#x3D; #Velocity Toolbox配置位置。例如&#96;&#x2F; WEB-INF &#x2F; toolbox.xml&#39;spring.velocity.view-names &#x3D; #可以解决的视图名称的白名单。 #---------------------------------------- #安全属性 #---------------------------------------- #SECURITY（SecurityProperties）security.basic.authorize-mode &#x3D; role #应用安全授权模式。security.basic.enabled &#x3D; true #启用基本身份验证。security.basic.path &#x3D; &#x2F; ** #安全路径的逗号分隔列表。security.basic.realm &#x3D; Spring #HTTP基本的领域名称。security.enable-csrf &#x3D; false #启用跨站点请求伪造支持。security.filter-order &#x3D; 0 #安全过滤器连锁订单。security.headers.cache &#x3D; true #启用缓存控制HTTP头。security.headers.content-type &#x3D; true# 启用“X-Content-Type-Options”头。security.headers.frame &#x3D; true #启用“X-Frame-Options”标题。security.headers.hsts &#x3D; # HTTP严格传输安全（HSTS）模式（无，域，全部）。security.headers.xss &#x3D; true #启用跨站点脚本（XSS）保护。security.ignored &#x3D; #从默认安全路径中排除的路径的逗号分隔列表。security.require-ssl &#x3D; false #为所有请求启用安全通道。security.sessions &#x3D; stateless #会话创建策略（永远不会，if_required，无状态）。security.user.name &#x3D; user #默认用户名。security.user.password &#x3D; #默认用户名的密码。默认情况下，启动时会记录随机密码。security.user.role &#x3D; USER #为默认用户名授予角色。 #SECURITY OAUTH2 CLIENT（OAuth2ClientPropertiessecurity.oauth2.client.client-id &#x3D; #OAuth2客户端ID。security.oauth2.client.client-secret &#x3D; #OAuth2客户机密码。默认生成随机密码 #SECURITY OAUTH2 RESOURCES（ResourceServerPropertiessecurity.oauth2.resource.id &#x3D; #资源的标识符。security.oauth2.resource.jwt.key-uri &#x3D; #JWT令牌的URI。如果值不可用并且密钥是公共的，可以设置。security.oauth2.resource.jwt.key-value &#x3D; #JWT令牌的验证密钥。可以是对称秘密或PEM编码的RSA公钥。security.oauth2.resource.prefer-token-info &#x3D; true #使用令牌信息，可以设置为false以使用用户信息。security.oauth2.resource.service-id &#x3D; resource #security.oauth2.resource.token-info-uri &#x3D; #令牌解码端点的URI。security.oauth2.resource.token-type &#x3D; #使用userInfoUri时发送的令牌类型。security.oauth2.resource.user-info-uri &#x3D; #用户端点的URI。 #SECURITY OAUTH2 SSO（OAuth2SsoPropertiessecurity.oauth2.sso.filter-order &#x3D; #如果不提供显式的WebSecurityConfigurerAdapter，则应用过滤器顺序security.oauth2.sso.login-path &#x3D; &#x2F; login #登录页面的路径，即触发重定向到OAuth2授权服务器的路径# ----------------------------------------# DATA PROPERTIES 数据性能# ----------------------------------------# FLYWAY (FlywayProperties)flyway.baseline-description &#x3D; #flyway.baseline-version &#x3D; 1 #版本开始迁移flyway.baseline-on-migrate &#x3D; #flyway.check-location &#x3D; false #检查迁移脚本位置是否存在。flyway.clean-on-validation-error &#x3D; #flyway.enabled &#x3D; true #启用飞行路线。flyway.encoding &#x3D; #flyway.ignore-failed-future-migration &#x3D; #flyway.init-sqls &#x3D; #执行SQL语句，以便在获取连接后立即初始化连接。flyway.locations &#x3D; classpath：db &#x2F; migration #迁移脚本的位置flyway.out-of-order &#x3D; #如果您希望Flyway创建自己的DataSource，则需要使用#path密码flyway.placeholder-prefix &#x3D; #flyway.placeholder-replacement &#x3D; #flyway.placeholder-suffix &#x3D; #flyway.placeholders。* &#x3D; #flyway.schemas &#x3D; #schemas来更新flyway.sql-migration-prefix &#x3D; V #flyway.sql-migration-separator &#x3D; #flyway.sql-migration-suffix &#x3D; .sql #flyway.table &#x3D; #flyway.url &#x3D; #要迁移的数据库的JDBC url。如果未设置，则使用主配置的数据源。flyway.user &#x3D; #登录要迁移的数据库的用户。flyway.validate-on-migrate &#x3D; ## LIQUIBASE (LiquibaseProperties)liquibase.change-log &#x3D; classpath：&#x2F;db&#x2F;changelog&#x2F;db.changelog-master.yaml #更改日志配置路径。liquibase.check-change-log-location &#x3D; true #检查更改日志位置是否存在。liquibase.contexts &#x3D; #使用逗号分隔的运行时上下文列表。liquibase.default-schema &#x3D; #默认数据库模式。liquibase.drop-first &#x3D; false #首先删除数据库模式。liquibase.enabled &#x3D; true #启用liquidibase支持。liquibase.labels &#x3D; #使用逗号分隔的运行时标签列表。liquibase.parameters。* &#x3D; #更改日志参数。liquibase.password &#x3D; #登录要迁移的数据库的密码。liquibase.url &#x3D; #要迁移的数据库的JDBC url。 如果未设置，则使用主配置的数据源。liquibase.user &#x3D; #登录要迁移的数据库的用户。# DAO (PersistenceExceptionTranslationAutoConfiguration)spring.dao.exceptiontranslation.enabled&#x3D; true # 启用持久异常翻译后处理器。# CASSANDRA (CassandraProperties)spring.data.cassandra.cluster-name &#x3D; #Cassandra群集的名称。spring.data.cassandra.compression &#x3D; #由Cassandra二进制协议支持的压缩。spring.data.cassandra.connect-timeout-millis &#x3D; #套接字选项：连接超时。spring.data.cassandra.consistency-level &#x3D; #查询一致性级别。spring.data.cassandra.contact-points &#x3D; localhost #集群节点地址的逗号分隔列表。spring.data.cassandra.fetch-size &#x3D; #查询默认的抓取大小。spring.data.cassandra.keyspace-name &#x3D; #要使用的密钥空间名称。spring.data.cassandra.load-balancing-policy &#x3D; #负载均衡策略的类名。spring.data.cassandra.port &#x3D; #Cassandra服务器端口。spring.data.cassandra.password &#x3D; #登录服务器的密码。spring.data.cassandra.read-timeout-millis &#x3D; #套接字选项：读取超时。spring.data.cassandra.reconnection-policy &#x3D; #重新连接策略类。spring.data.cassandra.retry-policy &#x3D; #重试策略的类名。spring.data.cassandra.serial-consistency-level &#x3D; #查询串行一致性级别。spring.data.cassandra.ssl &#x3D; false #启用SSL支持。spring.data.cassandra.username &#x3D; #登录用户的服务器。# ELASTICSEARCH (ElasticsearchProperties)spring.data.elasticsearch.cluster-name &#x3D; elasticsearch #弹性搜索集群名称。spring.data.elasticsearch.cluster-nodes &#x3D; #集群节点地址的逗号分隔列表。 如果未指定，则启动客户端节点。spring.data.elasticsearch.properties。* &#x3D; #用于配置客户端的其他属性。spring.data.elasticsearch.repositories.enabled &#x3D; true #启用Elasticsearch存储库。# MONGODB (MongoProperties)spring.data.mongodb.authentication-database &#x3D; #验证数据库名称。spring.data.mongodb.database &#x3D; test #数据库名称。spring.data.mongodb.field-naming-strategy &#x3D; #要使用的FieldNamingStrategy的完全限定名称。spring.data.mongodb.grid-fs-database &#x3D; #GridFS数据库名称。spring.data.mongodb.host &#x3D; localhost #Mongo服务器主机。spring.data.mongodb.password &#x3D; #登录mongo服务器的密码。spring.data.mongodb.port &#x3D; 27017 #Mongo服务器端口。spring.data.mongodb.repositories.enabled &#x3D; true #启用Mongo存储库。spring.data.mongodb.uri &#x3D; mongodb：&#x2F;&#x2F; localhost &#x2F; test #Mongo数据库URI。 设置时，主机和端口将被忽略。spring.data.mongodb.username &#x3D; #登录mongo服务器的用户。# DATA REST (RepositoryRestProperties)spring.data.rest.base-path &#x3D; #由Spring Data REST用于公开存储库资源的基本路径。spring.data.rest.default-page-size &#x3D; #页面的默认大小。spring.data.rest.enable-enum-translation &#x3D; #通过Spring Data REST默认资源包启用枚举值转换。spring.data.rest.limit-param-name &#x3D; #指示一次返回多少结果的URL查询字符串参数的名称。spring.data.rest.max-page-size &#x3D; #最大页面大小。spring.data.rest.page-param-name &#x3D; #指示要返回的页面的URL查询字符串参数的名称。spring.data.rest.return-body-on-create &#x3D; #创建一个实体后返回响应体。spring.data.rest.return-body-on-update &#x3D; #更新实体后返回响应体。spring.data.rest.sort-param-name &#x3D; #指示排序结果的方向的URL查询字符串参数的名称。# SOLR (SolrProperties)spring.data.solr.host &#x3D; http:&#x2F;&#x2F;127.0.0.1:8983&#x2F;solr #Solr主机。 如果设置了“zk-host”，则被忽略。spring.data.solr.repositories.enabled &#x3D; true #启用Solr存储库。spring.data.solr.zk-host &#x3D; #ZooKeeper主机地址，格式为HOST：PORT。# 数据源 配置 (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.continue-on-error &#x3D; false #初始化数据库时发生错误时不要停止。spring.datasource.data &#x3D; #Data（DML）脚本资源引用。spring.datasource.driver-class-name &#x3D; #JDBC驱动程序的完全限定名称。默认情况下，根据URL自动检测。spring.datasource.initialize &#x3D; true #使用&#39;data.sql&#39;填充数据库。spring.datasource.jmx-enabled &#x3D; false #启用JMX支持（如果由底层池提供）。spring.datasource.jndi-name &#x3D; #数据源的JNDI位置。设置时，类，网址，用户名和密码将被忽略。spring.datasource.max-active &#x3D; #例如100spring.datasource.max-idle &#x3D; #例如8spring.datasource.max等待&#x3D;spring.datasource.min-evictable空闲时间-米利斯&#x3D;spring.datasource.min-idle &#x3D; 8spring.datasource.name &#x3D; testdb #数据源的名称。spring.datasource.password &#x3D; #登录数据库的密码。spring.datasource.platform &#x3D; all #在资源模式（schema - $ &#123;platform&#125; .sql）中使用的平台。spring.datasource.schema &#x3D; #Schema（DDL）脚本资源引用。spring.datasource.separator &#x3D;; #语句分隔符在SQL初始化脚本中。spring.datasource.sql-script-encoding &#x3D; #SQL脚本编码。spring.datasource.test-on-borrow &#x3D; #例如&#96;false&#96;spring.datasource.test-on-return &#x3D; #例如&#96;false&#96;spring.datasource.test-while-idle &#x3D; #spring.datasource.time-between-eviction-runs-millis &#x3D; 1spring.datasource.type &#x3D; #要使用的连接池实现的完全限定名称。默认情况下，它是从类路径自动检测的。spring.datasource.url &#x3D; #数据库的JDBC url。spring.datasource.username&#x3D; spring.datasource.validation-query&#x3D; # H2 Web Console (H2ConsoleProperties) spring.h2.console.enabled &#x3D; false #启用控制台。spring.h2.console.path &#x3D; &#x2F; h2-console #控制台可用的路径。# JOOQ (JooqAutoConfiguration)spring.jooq.sql-dialect&#x3D; # 与配置的数据源通信时使用的SQLDialect JOOQ。 例如&#96;POSTGRES&#96;# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.data.jpa.repositories.enabled &#x3D; true #启用JPA存储库。spring.jpa.database &#x3D; #目标数据库进行操作，默认情况下自动检测。可以使用“databasePlatform”属性设置。spring.jpa.database-platform &#x3D; #要运行的目标数据库的名称，默认情况下自动检测。可以使用“数据库”枚举来设置。spring.jpa.generate-ddl &#x3D; false #启动时初始化模式。spring.jpa.hibernate.ddl-auto &#x3D; #DDL模式。这实际上是“hibernate.hbm2ddl.auto”属性的快捷方式。使用嵌入式数据库时默认为“创建删除”，否则为“否”。spring.jpa.hibernate.naming-strategy &#x3D; #命名策略完全限定名。spring.jpa.open-in-view &#x3D; true #注册OpenEntityManagerInViewInterceptor。将JPA EntityManager绑定到线程以进行请求的整个处理。spring.jpa.properties。* &#x3D; #在JPA提供程序上设置的其他本机属性。spring.jpa.show-sql &#x3D; false #启用SQL语句的日志记录。# JTA (JtaAutoConfiguration)spring.jta。* &#x3D; #技术特定配置spring.jta.log-dir &#x3D; #Transaction logs目录。# ATOMIKOSspring.jta.atomikos.connectionfactory.borrow-connection-timeout &#x3D; 30 #从池中借用连接的超时（以秒为单位）。spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag &#x3D; true #创建会话时是否忽略事务标志。spring.jta.atomikos.connectionfactory.local-transaction-mode &#x3D; false #是否需要本地事务。spring.jta.atomikos.connectionfactory.maintenance-interval &#x3D; 60 #池的维护线程运行之间的时间（以秒为单位）。spring.jta.atomikos.connectionfactory.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.atomikos.connectionfactory.max-lifetime &#x3D; 0 #在被破坏之前可以将连接合并的时间（以秒为单位）。 0表示无限制。spring.jta.atomikos.connectionfactory.max-pool-size &#x3D; 1 #池的最大大小。spring.jta.atomikos.connectionfactory.min-pool-size &#x3D; 1 #池的最小大小。spring.jta.atomikos.connectionfactory.reap-timeout &#x3D; 0 #借用连接的收获超时（以秒为单位）。 0表示无限制。spring.jta.atomikos.connectionfactory.unique-resource-name &#x3D; jmsConnectionFactory #用于在恢复期间标识资源的唯一名称。spring.jta.atomikos.datasource.borrow-connection-timeout &#x3D; 30 #从池中借出连接的超时（秒）。spring.jta.atomikos.datasource.default-isolation-level &#x3D; #池提供的连接的默认隔离级别。spring.jta.atomikos.datasource.login-timeout &#x3D; #用于建立数据库连接的超时（以秒为单位）。spring.jta.atomikos.datasource.maintenance-interval &#x3D; 60 #池的维护线程运行之间的时间（以秒为单位）。spring.jta.atomikos.datasource.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.atomikos.datasource.max-lifetime &#x3D; 0 #在被破坏之前可以将连接合并的时间（以秒为单位）。 0表示无限制。spring.jta.atomikos.datasource.max-pool-size &#x3D; 1 #池的最大大小。spring.jta.atomikos.datasource.min-pool-size &#x3D; 1 #池的最小大小。spring.jta.atomikos.datasource.reap-timeout &#x3D; 0 #借用连接的收获超时（以秒为单位）。 0表示无限制。spring.jta.atomikos.datasource.test-query &#x3D; #用于在返回连接之前验证连接的SQL查询或语句。spring.jta.atomikos.datasource.unique-resource-name &#x3D; dataSource #用于在恢复期间识别资源的唯一名称。# BITRONIXspring.jta.bitronix.connectionfactory.acquire-increment &#x3D; 1 #生成池时要创建的连接数。spring.jta.bitronix.connectionfactory.acquisition-interval &#x3D; 1 #在获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。spring.jta.bitronix.connectionfactory.acquisition-timeout &#x3D; 30 #从池中获取连接的超时（以秒为单位）。spring.jta.bitronix.connectionfactory.allow-local-transactions &#x3D; true #事务管理器是否允许混合XA和非XA事务。spring.jta.bitronix.connectionfactory.apply-transaction-timeout &#x3D; false #当XAResource被登记时，是否应该设置事务超时。spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled &#x3D; true #资源是否应该被自动登记和删除。spring.jta.bitronix.connectionfactory.cache-producer-consumer &#x3D; true #是否生产和消费者应该被缓存。spring.jta.bitronix.connectionfactory.defer-connection-release &#x3D; true #提供程序是否可以在同一连接上运行许多事务，并支持事务交织。spring.jta.bitronix.connectionfactory.ignore-recovery-failures &#x3D; false #是否应忽略恢复失败。spring.jta.bitronix.connectionfactory.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.bitronix.connectionfactory.max-pool-size &#x3D; 10 #池的最大大小。 0表示无限制。spring.jta.bitronix.connectionfactory.min-pool-size &#x3D; 0 #池的最小大小。spring.jta.bitronix.connectionfactory.password &#x3D; #用于连接到JMS提供程序的密码。spring.jta.bitronix.connectionfactory.share-transaction-connections &#x3D; false #ACCESSIBLE状态中的连接是否可以在事务的上下文中共享。spring.jta.bitronix.connectionfactory.test-connections &#x3D; true #从池中获取连接是否应该进行测试。spring.jta.bitronix.connectionfactory.two-pc-ordering-position &#x3D; 1 #在两阶段提交期间该资源应该采取的位置（始终为Integer.MIN_VALUE，始终为Integer.MAX_VALUE）。spring.jta.bitronix.connectionfactory.unique-name &#x3D; jmsConnectionFactory #用于在恢复期间标识资源的唯一名称。spring.jta.bitronix.connectionfactory.use-tm-join &#x3D; true启动XAResource时是否应使用TMJOIN。spring.jta.bitronix.connectionfactory.user &#x3D; #用于连接到JMS提供者的用户。spring.jta.bitronix.datasource.acquire-increment &#x3D; 1 #生成池时要创建的连接数。spring.jta.bitronix.datasource.acquisition-interval &#x3D; 1 #在获取无效连接后再尝试获取连接之前等待的时间（以秒为单位）。spring.jta.bitronix.datasource.acquisition-timeout &#x3D; 30 #从池中获取连接的超时（以秒为单位）。spring.jta.bitronix.datasource.allow-local-transactions &#x3D; true #事务管理器是否允许混合XA和非XA事务。spring.jta.bitronix.datasource.apply-transaction-timeout &#x3D; false #当XAResource被登记时，是否应该设置事务超时。spring.jta.bitronix.datasource.automatic-enlisting-enabled &#x3D; true #资源是否应该被登记和自动删除。spring.jta.bitronix.datasource.cursor-holdability &#x3D; #连接的默认游标保持性。spring.jta.bitronix.datasource.defer-connection-release &#x3D; true #数据库是否可以在同一连接上运行许多事务，并支持事务交织。spring.jta.bitronix.datasource.enable-jdbc4-connection-test &#x3D; #从池中获取连接时是否调用Connection.isValid（）。spring.jta.bitronix.datasource.ignore-recovery-failures &#x3D; false #是否应忽略恢复失败。spring.jta.bitronix.datasource.isolation-level &#x3D; #连接的默认隔离级别。spring.jta.bitronix.datasource.local-auto-commit &#x3D; #本地事务的默认自动提交模式。spring.jta.bitronix.datasource.login-timeout &#x3D; #用于建立数据库连接的超时（以秒为单位）。spring.jta.bitronix.datasource.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.bitronix.datasource.max-pool-size &#x3D; 10 #池的最大大小。 0表示无限制。spring.jta.bitronix.datasource.min-pool-size &#x3D; 0 #池的最小大小。spring.jta.bitronix.datasource.prepared-statement-cache-size &#x3D; 0 #准备好的语句高速缓存的目标大小。 0禁用缓存。spring.jta.bitronix.datasource.share-transaction-connections &#x3D; false #ACCESSIBLE状态下的连接是否可以在事务的上下文中共享。spring.jta.bitronix.datasource.test-query &#x3D; #用于在返回连接之前验证连接的SQL查询或语句。spring.jta.bitronix.datasource.two-pc-ordering-position &#x3D; 1 #在两阶段提交期间该资源应该采取的位置（始终为Integer.MIN_VALUE，始终为Integer.MAX_VALUE）。spring.jta.bitronix.datasource.unique-name &#x3D; dataSource #用于在恢复期间标识资源的唯一名称。spring.jta.bitronix.datasource.use-tm-join &#x3D; true启动XAResource时是否应使用TMJOIN。# EMBEDDED MONGODB (EmbeddedMongoProperties)spring.mongodb.embedded.features &#x3D; SYNC_DELAY #启用功能的逗号分隔列表。spring.mongodb.embedded.version &#x3D; 2.6.10 #Mongo使用版本。# ----------------------------------------# 整合属性# ---------------------------------------- #ACTIVEMQ（ActiveMQProperties）spring.activemq.broker-url &#x3D; #ActiveMQ代理的URL。 默认自动生成。 例如&#96;tcp：&#x2F;&#x2F; localhost：61616&#96;spring.activemq.in-memory &#x3D; true #指定默认代理URL是否应在内存中。 如果指定了一个显式代理，则被忽略。spring.activemq.password &#x3D; #登录密码的代理。spring.activemq.pooled &#x3D; false #指定是否创建PooledConnectionFactory而不是常规的ConnectionFactory。spring.activemq.user &#x3D; #代理登录用户。# ARTEMIS (ArtemisProperties)spring.artemis.embedded.cluster-password &#x3D; #群集密码。 默认情况下随机生成。spring.artemis.embedded.data-directory &#x3D; #日志文件目录。 如果持久性被关闭，则不需要。spring.artemis.embedded.enabled &#x3D; true #如果Artemis服务器API可用，启用嵌入式模式。spring.artemis.embedded.persistent &#x3D; false #启用持久存储。spring.artemis.embedded.queues &#x3D; #启动时要创建的队列的逗号分隔列表。spring.artemis.embedded.server-id &#x3D; #服务器ID。 默认情况下，使用自动递增的计数器。spring.artemis.embedded.topics &#x3D; #启动时要创建的主题的逗号分隔列表。spring.artemis.host &#x3D; localhost #Artemis代理主机。spring.artemis.mode &#x3D; #Artemis部署模式，默认情况下自动检测。 可以显式设置为“native”或“embedded”。spring.artemis.port &#x3D; 61616 #Artemis 中间件端口。# SPRING BATCH(Batch 配置)spring.batch.initializer.enabled &#x3D; true #如果需要，在启动时创建所需的批处理表。spring.batch.job.enabled &#x3D; true #在启动时执行上下文中的所有Spring批处理作业。spring.batch.job.names &#x3D; #在启动时执行的作业名称的逗号分隔列表（例如&#96;job1，job2&#96;）。 默认情况下，执行在上下文中找到的所有作业。spring.batch.schema &#x3D; classpath：org &#x2F; springframework &#x2F; batch &#x2F; core &#x2F; schema - @@ platform @@。sql #用于初始化数据库模式的SQL文件的路径。spring.batch.table-prefix &#x3D; #所有批次元数据表的表前缀。# HORNETQ (HornetQ 配置)spring.hornetq.embedded.cluster-password &#x3D; #集群密码。 默认情况下随机生成。spring.hornetq.embedded.data-directory &#x3D; #日志文件目录。 如果持久性被关闭，则不需要。spring.hornetq.embedded.enabled &#x3D; true #如果HornetQ服务器API可用，启用嵌入式模式。spring.hornetq.embedded.persistent &#x3D; false #启用持久存储。spring.hornetq.embedded.queues &#x3D; #启动时要创建的队列的逗号分隔列表。spring.hornetq.embedded.server-id &#x3D; #服务器ID。 默认情况下，使用自动递增的计数器。spring.hornetq.embedded.topics &#x3D; #在启动时创建的主题的逗号分隔列表。spring.hornetq.host &#x3D; localhost #HornetQ代理主机。spring.hornetq.mode &#x3D; #HornetQ部署模式，默认情况下自动检测。 可以显式设置为“native”或“embedded”。spring.hornetq.port &#x3D; 5445 #HornetQ代理端口。# JMS (Jms 配置)# 连接工厂JNDI名称。 设置时，优先于其他连接工厂自动配置。spring.jms.jndi-name&#x3D; # 容器的确认模式。 默认情况下，监听器被自动确认处理。spring.jms.listener.acknowledge-mode&#x3D; # 启动时自动启动容器。spring.jms.listener.auto-startup&#x3D; true# 最小并发消费者数。spring.jms.listener.concurrency&#x3D; # 最大并发消费者数。spring.jms.listener.max-concurrency&#x3D; # 指定默认的目的地类型是否为主题。spring.jms.pub-sub-domain&#x3D; false# RABBIT (Rabbit 配置)# 客户端应连接到的逗号分隔的地址列表。spring.rabbitmq.addresses &#x3D; spring.rabbitmq.dynamic &#x3D; true # 创建一个AmqpAdmin bean。spring.rabbitmq.host &#x3D; localhost# RabbitMQ主机。spring.rabbitmq.listener.acknowledge-mode &#x3D; # 容器的确认模式。spring.rabbitmq.listener.auto-startup &#x3D; true# 启动时自动启动容器。spring.rabbitmq.listener.concurrency &#x3D; # 最少消费者数。spring.rabbitmq.listener.max-concurrency &#x3D; # 最大消费者数。spring.rabbitmq.listener.prefetch &#x3D; # 在单个请求中要处理的消息数。它应该大于或等于事务大小（如果使用）。spring.rabbitmq.listener.transaction-size &#x3D; # 在事务中要处理的消息数。为了获得最佳结果，它应该小于或等于预取计数。spring.rabbitmq.password &#x3D; # 登录以对代理进行身份验证。spring.rabbitmq.port &#x3D; 5672# RabbitMQ端口。spring.rabbitmq.requested-heartbeat &#x3D; # 请求的心跳超时，以秒为单位;零为无。spring.rabbitmq.ssl.enabled &#x3D; false# 启用SSL支持。spring.rabbitmq.ssl.key-store &#x3D; # 保存SSL证书的密钥存储区的路径。spring.rabbitmq.ssl.key-store-password &#x3D; # 用于访问密钥库的密码。spring.rabbitmq.ssl.trust-store &#x3D; # 保存SSL证书的Trust存储。spring.rabbitmq.ssl.trust-store-password &#x3D; # 用于访问信任存储的密码。spring.rabbitmq.username &#x3D; # 登录用户对代理进行身份验证。spring.rabbitmq.virtual-host &#x3D; # 连接到代理时使用的虚拟主机。# 端点配置（EndpointCorsProperties）# 设置是否支持凭据。 未设置时，不支持凭据。endpoints.cors.allow-credentials&#x3D; # 在请求中允许的头文件逗号分隔列表。 &#39;*&#39;允许所有标题。endpoints.cors.allowed-headers&#x3D; # 逗号分隔的允许的方法列表。 &#39;*&#39;允许所有方法。endpoints.cors.allowed-methods&#x3D; GET# 逗号分隔的起始列表允许。 &#39;*&#39;允许所有来源。 未设置时，禁用CORS支持。endpoints.cors.allowed-origins&#x3D; # 包含在响应中的标题的逗号分隔列表。endpoints.cors.exposed-headers&#x3D; # 客户端可以缓存飞行前请求的响应时间（秒）。endpoints.cors.max-age&#x3D; 1800# JMX ENDPOINT (EndpointMBeanExportProperties) （端点MBean导出属性）# JMX域名。 如果设置为&#39;spring.jmx.default-domain&#39;的值初始化。endpoints.jmx.domain&#x3D; # 启用所有端点的JMX导出。endpoints.jmx.enabled&#x3D; true# 附加静态属性以附加到表示端点的MBean的所有对象名称。endpoints.jmx.static-names&#x3D; # 确保在发生冲突时修改ObjectNames。endpoints.jmx.unique-names&#x3D; false# JOLOKIA JOLOKIA 配置# 见Jolokia手册jolokia.config.*&#x3D; # 管理HTTP服务器（管理服务器属性）# 在每个响应中添加“X-Application-Context”HTTP头。management.add-application-context-header&#x3D; true# 管理端点应绑定到的网络地址。management.address&#x3D; # 管理端点上下文路径。 例如&#96;&#x2F; actuator&#96;management.context-path&#x3D; # 管理端点HTTP端口。 默认使用与应用程序相同的端口。management.port&#x3D; # 启用安全性management.security.enabled&#x3D; true# 访问管理端点所需的角色。management.security.role&#x3D; ADMIN# 会话创建策略使用（always，never，if_required，stateless）（总是，永远，if_required，无状态）。management.security.sessions&#x3D; stateless# HEALTH INDICATORS (previously health.*)# 启用数据库运行状况检查management.health.db.enabled&#x3D; true# 启用默认的健康指标。management.health.defaults.enabled&#x3D; true# 启用磁盘空间运行状况检查。management.health.diskspace.enabled&#x3D; true# 用于计算可用磁盘空间的路径。management.health.diskspace.path&#x3D; # 应该可用的最小磁盘空间（以字节为单位）。management.health.diskspace.threshold&#x3D; 0# 启用弹性搜索健康检查。management.health.elasticsearch.enabled&#x3D; true# 逗号分隔的索引名称。management.health.elasticsearch.indices&#x3D; # 等待群集响应的时间（以毫秒为单位）。management.health.elasticsearch.response-timeout&#x3D; 100# 启用JMS健康检查。management.health.jms.enabled&#x3D; true# 启用邮件运行状况检查。management.health.mail.enabled&#x3D; true# 启用MongoDB健康检查。management.health.mongo.enabled&#x3D; true# 启用RabbitMQ运行状况检查。management.health.rabbit.enabled&#x3D; true# 启用Redis健康检查。management.health.redis.enabled&#x3D; true# 启用Solr运行状况检查。management.health.solr.enabled&#x3D; true# 按照严重性的顺序，以逗号分隔的健康状态列表。management.health.status.order&#x3D; DOWN, OUT_OF_SERVICE, UNKNOWN, UP# TRACING ((TraceProperties) 跟踪性能# 跟踪中包含的项目。management.trace.include&#x3D; request-headers,response-headers,errors# 远程 shell配置# 验证类型。 根据环境自动检测。shell.auth&#x3D; simple# JAAS域。shell.auth.jaas.domain&#x3D; my-domain# 验证密钥的路径。 这应该指向一个有效的“.pem”文件。shell.auth.key.path&#x3D; # 登录用户。shell.auth.simple.user.name&#x3D; user# 登录用户的密码。shell.auth.simple.user.password&#x3D; # 登录到CRaSH控制台的所需的角色，以逗号分隔列表。shell.auth.spring.roles&#x3D; ADMIN# 用于查找命令的模式。shell.command-path-patterns&#x3D; classpath*:&#x2F;commands&#x2F;**,classpath*:&#x2F;crash&#x2F;commands&#x2F;**# 扫描更改并在必要时更新命令（以秒为单位）。shell.command-refresh-interval&#x3D; -1# 用于查找配置的模式。shell.config-path-patterns&#x3D; classpath*:&#x2F;crash&#x2F;*# 逗号分隔的要禁用的命令列表。shell.disabled-commands&#x3D; jpa*,jdbc*,jndi*# 禁用逗号分隔的插件列表。 默认情况下，根据环境禁用某些插件。shell.disabled-plugins&#x3D; # 用户被提示再次登录后的毫秒数。shell.ssh.auth-timeout &#x3D; # 启用CRaSH SSH支持。shell.ssh.enabled&#x3D; true# 未使用的连接关闭之后的毫秒数。shell.ssh.idle-timeout &#x3D; # SSH服务器密钥路径。shell.ssh.key-path&#x3D; # SSH端口。shell.ssh.port&#x3D; 2000# 启用CRaSH telnet支持。 如果TelnetPlugin可用，默认情况下启用。shell.telnet.enabled&#x3D; false# Telnet端口。shell.telnet.port&#x3D; 5000# GIT 信息配置# 生成的git信息属性文件的资源引用。spring.git.properties&#x3D; # 标准出口# 模式，告诉聚合器如何从源存储库中的键。spring.metrics.export.aggregate.key-pattern&#x3D; # 全局存储库的前缀如果处于活动状态。spring.metrics.export.aggregate.prefix&#x3D; # 导出刻度之间以毫秒为单位的延迟。 按照这种延迟，指标将按计划导出到外部来源。spring.metrics.export.delay-millis&#x3D; 5000# 标志以启用度量标准导出（假设MetricWriter可用）。spring.metrics.export.enabled&#x3D; true# 要排除的度量名称列表。 应用后包括。spring.metrics.export.excludes&#x3D; # 要包含的度量名称的模式列表。spring.metrics.export.includes&#x3D; # redis存储库导出的密钥（如果活动）。spring.metrics.export.redis.key&#x3D; keys.spring.metrics# redis存储库的前缀 如果处于活动状态。spring.metrics.export.redis.prefix&#x3D; spring.metrics# 标志基于不导出不变的度量值来关闭任何可用的优化。spring.metrics.export.send-latest&#x3D; # 主机的statsd服务器接收导出的指标。spring.metrics.export.statsd.host&#x3D; # 接收导出指标的statsd服务器端口。spring.metrics.export.statsd.port&#x3D; 8125# statsd导出指标的前缀。spring.metrics.export.statsd.prefix&#x3D; # 每个MetricWriter bean名称具有特定的触发器属性。spring.metrics.export.triggers.*&#x3D; # ----------------------------------------# DEVTOOLS属性# ----------------------------------------# DEVTOOLS（开发工具属性）# 启用一个livereload.com兼容的服务器。spring.devtools.livereload.enabled&#x3D; true# # Server port.spring.devtools.livereload.port&#x3D; 35729# 应该排除的触发完全重新启动的其他模式。spring.devtools.restart.additional-exclude&#x3D; # 观看更改的附加路径。spring.devtools.restart.additional-paths&#x3D; # 启用自动重启功能。spring.devtools.restart.enabled&#x3D; true# 应该排除的模式触发完全重新启动。spring.devtools.restart.exclude&#x3D; META-INF&#x2F;maven&#x2F;**,META-INF&#x2F;resources&#x2F;**,resources&#x2F;**,static&#x2F;**,public&#x2F;**,templates&#x2F;**,**&#x2F;*Test.class,**&#x2F;*Tests.class,git.properties# 轮询类路径更改之间等待的时间量（以毫秒为单位）。spring.devtools.restart.poll-interval&#x3D; 1000# 触发重新启动之前没有任何类路径更改所需的安静时间量（以毫秒为单位）。spring.devtools.restart.quiet-period&#x3D; 400# 更改后的特定文件的名称将触发重新启动检查。 如果未指定任何类路径文件更改将触发重新启动。spring.devtools.restart.trigger-file&#x3D; # 远程开发工具属性# 用于处理远程连接的上下文路径。spring.devtools.remote.context-path&#x3D; &#x2F;.~~spring-boot!~# 启用远程调试支持。spring.devtools.remote.debug.enabled&#x3D; true# 本地远程调试服务器端口。spring.devtools.remote.debug.local-port&#x3D; 8000# 用于连接到远程应用程序的代理主机。spring.devtools.remote.proxy.host&#x3D; # 用于连接到远程应用程序的代理端口。spring.devtools.remote.proxy.port&#x3D; # 启用远程重启。spring.devtools.remote.restart.enabled&#x3D; true# 建立连接所需的共享密钥（需要启用远程支持）。spring.devtools.remote.secret&#x3D; # HTTP头用于传输共享密钥。&lt;&#x2F; span&gt;spring.devtools.remote.secret-header-name&#x3D; X-AUTH-TOKEN＃----------------------------------------#TESTING PROPERTIES＃----------------------------------------spring.test.database.replace &#x3D; any＃要替换的现有DataSource的类型。spring.test.mockmvc.print &#x3D;默认#MVC打印选项。","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://kanchai.club/tags/SpringBoot/"}]},{"title":"PC列表通用排序功能","slug":"通用列表排序实现","date":"2020-03-17T15:18:40.963Z","updated":"2020-03-17T14:39:16.000Z","comments":true,"path":"2020/03/17/通用列表排序实现/","link":"","permalink":"https://kanchai.club/2020/03/17/%E9%80%9A%E7%94%A8%E5%88%97%E8%A1%A8%E6%8E%92%E5%BA%8F%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"之前做过好多外包都没写过排序的实现，这次发现同事写的有问题，所以手动实现一个。不知是否有用。直接上代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168/** * 给表的排序字段排序 * * @author: 李涛 * @version: 2019年07月17日 16:51 */@Api(tags = \"给列表排序\")@RestController@RequestMapping(\"/common/sort\")@Validatedpublic class SortTableController &#123; @Autowired private ICommonSV commonSV; /** * 拖拽标志对应的表和字段 */ private static final Map&lt;String, String&gt; tables = new HashMap&lt;&gt;(); /** * 拖拽标志对应的表和字段 */ private static final Map&lt;String, String&gt; tablesWhere = new HashMap&lt;&gt;(); static &#123; // 表名 tables.put(\"app_banner\", \"sort_num\"); tables.put(\"app_health_plate\", \"sort_num\"); tables.put(\"app_start_page\", \"sort_num\"); tables.put(\"clinic_manual\", \"sort\"); tables.put(\"sys_menu\", \"menu_order\"); tables.put(\"nav_dept_adv\", \"sort_num\"); // 排序条件 tablesWhere.put(\"sys_menu\", \"and parent_id = #&#123;params.p0&#125;\"); tablesWhere.put(\"clinic_manual\", \"and deleted !='01' \"); &#125; @Log @ApiOperation(\"排序\") @ApiImplicitParams(&#123; @ApiImplicitParam(value = \"拖拽标志(nav_doctor_infor,nav_popu_dept_infor,nav_quick_entry_infor)\", name = \"tableName\", paramType = \"form\"), @ApiImplicitParam(value = \"上\", name = \"top\", paramType = \"form\"), @ApiImplicitParam(value = \"中\", name = \"mid\", paramType = \"form\"), @ApiImplicitParam(value = \"下\", name = \"bottom\", paramType = \"form\"), @ApiImplicitParam(value = \"条件\", name = \"whereCase\", paramType = \"form\"), &#125;) @Transactional @PostMapping(\"/sortTable\") public APIResponse sortTable( @NotNull String tableName, Long top, @NotNull Long mid, Long bottom, String[] whereCase ) &#123; String sort = tables.get(tableName); if (StringUtils.isBlank(sort)) &#123; throw new UnsupportedOperationException(); &#125; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); //根据上下判定是上移还是下移 Boolean down = null; Long midSort = null; Long topSort = null; Long bottomSort = null; if (top == null) &#123; down = false; &#125; else if (bottom == null) &#123; down = true; &#125; else &#123; midSort = findSort(mid, tableName); topSort = findSort(top, tableName); bottomSort = findSort(bottom, tableName); down = midSort &gt; topSort &amp;&amp; midSort &gt; bottomSort; &#125; // 执行更新操作 String updateSql = null; if (down) &#123; if (topSort == null) &#123; topSort = findSort(top, tableName); &#125; List&lt;Long&gt; ids = findIds(top, mid, tableName, whereCase, \"first\"); if (ids.isEmpty()) &#123; return APIResponseBuilder.successNoData(); &#125; updateSql = \"update \" + tableName + \" set \" + sort + \" = \" + sort + \" + 1 where id in ( \" + StringUtils.join(ids, \",\") + \" )\"; commonSV.updateByParams(updateSql, params); params.put(\"newSort\", topSort); params.put(\"id\", mid); updateSql = \"update \" + tableName + \" set \" + sort + \" = #&#123;params.newSort&#125; where id = #&#123;params.id&#125; \"; commonSV.updateByParams(updateSql, params); &#125; else if (!down) &#123; if (bottomSort == null) &#123; bottomSort = findSort(bottom, tableName); &#125; List&lt;Long&gt; ids = findIds(mid, bottom, tableName, whereCase, \"last\"); if (ids.isEmpty()) &#123; return APIResponseBuilder.successNoData(); &#125; updateSql = \"update \" + tableName + \" set \" + sort + \" = \" + sort + \" - 1 where id in ( \" + StringUtils.join(ids, \",\") + \" )\"; commonSV.updateByParams(updateSql, params); params.put(\"newSort\", bottomSort); params.put(\"id\", mid); updateSql = \"update \" + tableName + \" set \" + sort + \" = #&#123;params.newSort&#125; where id = #&#123;params.id&#125; \"; commonSV.updateByParams(updateSql, params); &#125; return APIResponseBuilder.successNoDataWithMsg(\"排序成功!\"); &#125; /** * 查询两个ID之间的ID有哪些 * * @param startId * @param endId * @param tableName * @param whereCase * @param removeTag * @return */ private List&lt;Long&gt; findIds(Long startId, Long endId, String tableName, String[] whereCase, String removeTag) &#123; String sort = tables.get(tableName); String sql = \" select id \" + \" from \" + tableName + \" \" + \" where \" + sort + \" &gt;= (select \" + sort + \" from \" + tableName + \" where id = #&#123;params.startId&#125;) \" + \" and \" + sort + \" &lt;= (select \" + sort + \" from \" + tableName + \" where id = #&#123;params.endId&#125;) \"; String whereCaseStr = tablesWhere.get(tableName); if (whereCaseStr != null) &#123; sql += whereCaseStr; &#125; sql += \" order by \" + sort + \" desc \"; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"startId\", startId); params.put(\"endId\", endId); if (whereCase != null &amp;&amp; whereCase.length &gt; 0) &#123; for (int i = 0; i &lt; whereCase.length; i++) &#123; params.put(\"p\" + i, whereCase[i]); &#125; &#125; List&lt;JSONObject&gt; longs = commonSV.queryListJSONObject(sql, params); if (StringUtils.isNotBlank(removeTag) &amp;&amp; !longs.isEmpty()) &#123; if (\"last\".equals(removeTag)) &#123; longs.remove(longs.size() - 1); &#125; else if (\"first\".equals(removeTag)) &#123; longs.remove(0); &#125; &#125; return longs.stream().map(n -&gt; n.getLong(\"id\")).collect(Collectors.toList()); &#125; /** * 根据ID查询序号 * * @param id * @param tableName * @return */ private Long findSort(Long id, String tableName) &#123; if (id == null) &#123; return null; &#125; String sql = \" select \" + tables.get(tableName) + \" from \" + tableName + \" where id = #&#123;params.id&#125;\"; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"id\", id); Number sortNum = commonSV.selectField(sql, params, Number.class); return sortNum.longValue(); &#125;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"}]},{"title":"SpringBoot中Mybatis枚举翻译插件实现","slug":"Mybatis插件实现,实现数据库枚举字段翻译为中文插件","date":"2020-03-17T15:18:40.843Z","updated":"2020-03-17T15:17:29.000Z","comments":true,"path":"2020/03/17/Mybatis插件实现,实现数据库枚举字段翻译为中文插件/","link":"","permalink":"https://kanchai.club/2020/03/17/Mybatis%E6%8F%92%E4%BB%B6%E5%AE%9E%E7%8E%B0,%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%9A%E4%B8%BE%E5%AD%97%E6%AE%B5%E7%BF%BB%E8%AF%91%E4%B8%BA%E4%B8%AD%E6%96%87%E6%8F%92%E4%BB%B6/","excerpt":"开发目的新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值…","text":"开发目的新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值… 开发目的 新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值.或者是给前端提供枚举查询接口,然后前端遍历.非常麻烦.所以使用Mybatis插件替代这个重复性工作.开发完毕后,发现Mybatis有类型转换器,但是和项目现在的现象出入挺大.以下介绍以下插件的开发.之后还发现和PageHepler冲突,修复了一番. 插件配置到spring容器中 此处有点坑,起初按照容器初始化加入到容器的方式.但是与Springboot的Mybatis的PagerHepler的starter顺序不好控制.导致插件的加载顺序不一致.由于分页插件的拦截顺序严格控制.如果拦截相同的地方就会导致分页插件总计失效.所以采用以下方式,采用容器启动后,加入到Mybatis拦截中的最后一个位置: 123456789101112131415161718192021/** * 配置枚举翻译插件 * * @author: 李涛 * @version: 2019年04月28日 15:23 */@Componentpublic class MybatisPluginConfig implements ApplicationRunner &#123; @Autowired private List&lt;SqlSessionFactory&gt; sqlSessionFactoryList; @Override public void run(ApplicationArguments args) throws Exception &#123; Iterator var3 = this.sqlSessionFactoryList.iterator(); while (var3.hasNext()) &#123; SqlSessionFactory sqlSessionFactory = (SqlSessionFactory) var3.next(); sqlSessionFactory.getConfiguration().addInterceptor(new MyBatisEnumHandlePlugin()); &#125; &#125;&#125; 插件开发代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * 处理枚举字段 * * @author: 李涛 * @version: 2019年04月28日 14:57 */@Intercepts(&#123; @Signature(type = ResultSetHandler.class, method = \"handleResultSets\", args = Statement.class)&#125;)public class MyBatisEnumHandlePlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; DefaultResultSetHandler statementHandler = (DefaultResultSetHandler) invocation.getTarget(); Object proceed = invocation.proceed(); if (proceed instanceof List) &#123; List data = (List) proceed; if (data == null || data.isEmpty()) &#123; return proceed; &#125; // 对第一个对象进行分析 List&lt;Map&lt;String, Object&gt;&gt; translationInformation = getTranslationInformation(data.get(0).getClass()); // 如果没有字典标识,直接返回 if (translationInformation.isEmpty()) &#123; return proceed; &#125; // 遍历结果进行设置翻译值 for (Object datum : data) &#123; for (Map&lt;String, Object&gt; info : translationInformation) &#123; Field readField = (Field) info.get(\"read\"); Field writeField = (Field) info.get(\"write\"); Map dictValues = (Map) info.get(\"value\"); FieldUtils.writeField(writeField, datum, dictValues.get(readField.get(datum)), true); &#125; &#125; return data; &#125; return proceed; &#125; @Override public Object plugin(Object o) &#123; return Plugin.wrap(o, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125; /** * 通过类,获取需要翻译的字段信息 * * @param cls * @return */ private List&lt;Map&lt;String, Object&gt;&gt; getTranslationInformation(Class&lt;?&gt; cls) &#123; // 查询字典值service ISysDictSV sysDictSV = SpringUtil.getObject(ISysDictSV.class); List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;(); List&lt;DictField&gt; dicts = new ArrayList&lt;&gt;(); getAllDictAnnotation(cls, dicts); if (dicts.isEmpty()) &#123; return list; &#125; // 开始填充Field for (DictField dictField : dicts) &#123; if (dictField.enumClass().equals(DictEnum.class)) &#123; // 如果是父类枚举直接返回 continue; &#125; // 字典读写翻译信息存储 Map&lt;String, Object&gt; fieldInfo = new HashMap&lt;&gt;(); String toField = dictField.to(); if (\"\".equals(toField)) &#123; //如果没有设置，默认为From()+Name toField = dictField.from() + \"Name\"; &#125; Field readField = FieldUtils.getField(cls, dictField.from(), true); Field writeField = FieldUtils.getField(cls, toField, true); Map dictValues = sysDictSV.getDictValues(dictField.enumClass(), dictField.codeType()); if (readField == null || writeField == null || dictValues == null) &#123; continue; &#125; fieldInfo.put(\"read\", readField); fieldInfo.put(\"write\", writeField); fieldInfo.put(\"value\", dictValues); list.add(fieldInfo); &#125; return list; &#125; /** * 获取所有的字典注解 * * @param cls 类信息 * @param fields 存放值 */ private void getAllDictAnnotation(Class&lt;?&gt; cls, List&lt;DictField&gt; fields) &#123; DictEntity annotation = cls.getAnnotation(DictEntity.class); // 加入注解 if (annotation != null) &#123; DictField[] value = annotation.value(); fields.addAll(Arrays.asList(value)); &#125; // 继续往上找 if (cls.getSuperclass() != null &amp;&amp; cls.getSuperclass() != BaseSearchModel.class &amp;&amp; cls.getSuperclass() != Object.class) &#123; getAllDictAnnotation(cls.getSuperclass(), fields); &#125; &#125;&#125; 枚举翻译注解1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 标识是一个含有数据字典的实体 * * @author: 李涛 * @version: 2019年04月28日 12:30 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface DictEntity &#123; DictField[] value();&#125;/** * 标识是一个含有数据字典的实体 * * @author: 李涛 * @version: 2019年04月28日 12:30 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Repeatable(value = DictEntity.class)public @interface DictField &#123; /** * 要翻译的字段名称 */ String from(); /** * 翻译到哪个字段.默认为from()+Name,可以自定义 */ String to() default \"\"; /** * 枚举类 */ Class&lt;? extends DictEnum&gt; enumClass(); /** * code类型 */ Class codeType() default String.class;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://kanchai.club/tags/Mybatis/"},{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-16T03:15:41.997Z","updated":"2020-03-16T03:15:41.997Z","comments":true,"path":"2020/03/16/hello-world/","link":"","permalink":"https://kanchai.club/2020/03/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}