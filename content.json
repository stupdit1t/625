{"meta":{"title":"每天拾柴火","subtitle":"砍柴","description":"纪录一些看到的好文，收藏起来","author":625,"url":"https://kanchai.club","root":"/"},"pages":[{"title":"关于","date":"2014-12-22T04:39:04.000Z","updated":"2020-03-24T12:48:21.267Z","comments":true,"path":"about/index.html","permalink":"https://kanchai.club/about/index.html","excerpt":"","text":"一名菜鸟程序员，渴望力量！坚持从外边砍点柴火！"},{"title":"分类","date":"2020-03-17T15:24:33.000Z","updated":"2020-03-24T12:49:06.102Z","comments":true,"path":"categories/index.html","permalink":"https://kanchai.club/categories/index.html","excerpt":"","text":""},{"title":"搜索","date":"2016-05-24T05:45:13.000Z","updated":"2020-03-24T12:50:39.545Z","comments":true,"path":"search/index.html","permalink":"https://kanchai.club/search/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-03-17T15:25:26.000Z","updated":"2020-03-24T12:49:48.064Z","comments":true,"path":"tags/index.html","permalink":"https://kanchai.club/tags/index.html","excerpt":"","text":""},{"title":"文章","date":"2014-12-22T04:39:04.000Z","updated":"2020-03-25T01:28:04.400Z","comments":true,"path":"archives/index.html","permalink":"https://kanchai.club/archives/index.html","excerpt":"","text":""}],"posts":[{"title":"浅谈微服务","slug":"浅谈微服务","date":"2020-05-12T00:59:59.760Z","updated":"2020-05-12T00:59:06.000Z","comments":true,"path":"2020/05/12/浅谈微服务/","link":"","permalink":"https://kanchai.club/2020/05/12/%E6%B5%85%E8%B0%88%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"来源：后端技术杂谈 www.rowkey.me/blog/2019/05/30/msa/ 这几年在Java工程师招聘时，会看到很多人的简历都写着使用了Spring Cloud做微服务实现，使用Docker做自动化部署，并且也会把这些做为自己的亮点。而比较有趣的这其中以小公司出来的人为绝大多数，大的公司出来的人简历上倒是很少提这些东西。 对于我自己来说，从15年就开始关注这一块，看过马丁.福勒最开始的关于微服务的论文、也看过不少对微服务的论证的英文文章和书，也研究过Spring Cloud、Sofa等开源实现以及Service mesh。考虑到我们公司研发团队人力不足、基础设施不完善，当初是没有推行微服务的。但随着看到上述的那种简历越来越多，有时候我也会疑问：难道真的不用微服务就落后了吗？公司的同事如果不掌握这些就真的没有竞争力了吗。而随着最近公司业务的逐步提升，研发人员越来越多，借着在梳理公司的微服务落地计划时，也梳理了一下微服务的相关知识点，也是本文的主要内容。 开篇之前先声明我对微服务的几点态度: ★ 架构模式有很多，微服务不是唯一的选择也不是什么银弹。国内绝大多数中小公司引入微服务都是在盲目追新，也能看出做此种技术选型的工程师基础架构素质的不足。 “你必须长的足够高才能使用微服务”。微服务基础设施，尤其是容器技术、自动化部署、自动化测试这些不完备，微服务形同虚设，不会带来什么质的提升。 微服务架构的关键不在于具体的实现，而在于如何合理地划分服务边界以及组织架构是否相匹配。不考虑研发团队的规模和组成就盲目上微服务是不良的技术选型。 Spring Boot是Spring全家桶的上层封装，并不是什么崭新的技术，也不是什么值得觉得成为自己杀手锏的技术。 Spring Cloud中Spring Cloud Netflix的组件是经过生产环境验证的，其他的则建议慎重选择。 ” 微服务是什么微服务起源于2005年Peter Rodgers博士在云端运算博览会提出的微Web服务(Micro-Web-Service)，根本思想类似于Unix的管道设计理念。2014年，由Martin Fowler 与 James Lewis共同提出了微服务的概念，定义了微服务架构风格是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯（HTTP API）。关键的三点是small、automated以及lightweight。 对比SOA，微服务可以看做是SOA的子集，是轻量级的SOA，粒度更细的服务，独立进程、数据分离，更注重敏捷、持续交付、DevOps以及去中心化实践。其共同的架构原理： 单一职责 关注分离：控制与逻辑相分离 模块化和分而治之 特点： 用服务进行组件化 围绕业务能力进行组织 是产品而非项目 端点智能化和哑管道: 控制逻辑都在端点，管道仅仅是传输 全自动化部署 语言和数据的去中心化控制 面向失败设计 渐进式设计 综合来看，其优缺点如下： 优点： 模块的强边界 独立部署 技术选型的多样性 缺点： 分布式带来编程复杂度，远程调用的消耗 舍弃强一致性，实现最终一致性 操作复杂性要求有一个成熟的运维团队或者运维基础设施 为什么要采用微服务是否选择微服务取决于你要设计的系统的复杂度。微服务是用来把控复杂系统的，但是随之而来的就是引入了微服务本身的复杂度。需要解决包括自动化部署、监控、容错处理、最终一致性等其他分布式系统面临的问题。即使已经有一些普遍使用的解决方案，但是仍然是有不小的成本的。 生产力和复杂度的关系如图所示，可见系统越复杂，微服务带来的收益越大。此外，无论是单体应用还是微服务，团队的技能都需要能够把控住。 马丁.福勒的一个观点是：除非管理单体应用的成本已经太复杂了（太大导致很难修改和部署），否则都不要考虑微服务。大部分应用都应该选择单体架构，做好单体应用的模块化而不是拆分成服务。 因此，系统一开始采用单体架构，做好模块化，之后随着系统变得越来越复杂、模块/服务间的边界越来越清晰，再重构为微服务架构是一个合理的架构演化路径。 四个可以考虑上微服务的情况： 多人开发一个模块/项目，提交代码频繁出现大量冲突。 模块间严重耦合，互相依赖，每次变动需要牵扯多个团队，单次上线需求太多，风险大。 主要业务和次要业务耦合，横向扩展流程复杂。 熔断降级全靠if-else。 微服务的三个阶段： 微服务1.0：仅使用注册发现，基于SpringCloud或者Dubbo进行开发。 微服务2.0：使用了熔断、限流、降级等服务治理策略，并配备完整服务工具和平台。 微服务3.0：Service Mesh将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现AIOps和智能调度。 微服务架构先决条件 快速的环境提供能力：依赖于云计算、容器技术，快速交付环境。 基本的监控能力：包括基础的技术监控和业务监控。 快速的应用部署能力：需要部署管道提供快速的部署能力。 Devops文化：需要具有良好的持续交付能力，包括全链路追踪、快速环境提供和部署等，还需要快速的反应能力（对问题、故障的快速响应），开发和运维的协同工作。 此外，根据康威定律和逆康威定律（技术架构倒逼组织架构改进），组织架构也是一个很关键的因素。对应于微服务架构，组织架构需要遵循以下原则： 一个微服务由一个团队维护，团队成员以三人为宜。 单个团队的任务和发展是独立的，不受其他因素影响。 团队是功能齐全、全栈、自治的，扁平、自我管理。 基础设施微服务的推行需要依赖于很多底层基础设施，包括提供微服务的编译、集成、打包、部署、配置等工作，采用PaaS平台解决微服务从开发到运行的全生命周期管理，同时提供异构环境管理、容器资源隔离与互通、服务伸缩漂移、服务升级与回退、服务熔断与降级、服务注册与发现。 最基本的基础设施 进程间通讯机制：微服务是独立进程的，需要确定之间的通讯方式。 服务发现+服务路由: 提供服务注册中心，服务提供者和消费者通过服务发现获取服务的信息从而调用服务，实现服务的负载均衡等。 服务容错：微服务架构中，由于服务非常多，往往是一个服务挂了，整个请求链路的服务都受到影响，因此需要服务容错，在服务调用失败的时候能够处理错误或者快速失败，包括熔断、fallback、重试、流控和服务隔离等。 分布式事务支持：随着业务拆分为服务，那么有时候不可避免的就是跨服务的事务，即分布式事务的问题。原则是尽量避免分布式事务，如果无法避免那么可以使用消息系统或者CQRS和Event Sourcing方案来实现最终一致性。如果需要强一致性，则有两阶段提交、三阶段提交、TCC等分布式事务解决方案。 提升外部服务对接效率和内部开发效率 API网关: 负责外部系统的访问，负责跨横切面的公共层面的工作，包括安全、日志、权限控制、传输加密、请求转发、流量控制等。典型的网关功能即对外暴露一个域名xx.com，根据第一级目录做反向路由xx.com/user，xx.com/trade。每一级目录，如user、trade对应一个服务的域名。此外，API网关也可以有服务编排的功能（不推荐）。 接口框架: 规范服务之间通讯使用的数据格式、解析包、自解释文档，便于服务使用方快速上手等。 提升测试和运维效率 持续集成：这一部分并非是微服务特定的，对于之前的单体应用，此部分一般来说也是必要的。主要是指通过自动化手段，持续地对代码进程编译构建、自动化测试，以得到快速有效的质量反馈，从而保证代码的顺利交付。自动化测试包括代码级别的单元测试、单个系统的集成测试、系统间的接口测试。 自动化部署：微服务架构，节点数动辄上百上千，自动化部署能够提高部署速度和部署频率，从而保证持续交付。包括版本管理、资源管理、部署操作、回滚操作等功能。而对于微服务的部署方式，包括蓝绿部署、滚动部署以及金丝雀部署。 配置中心: 运行时配置管理能够解决动态修改配置并批量生效的问题。包括配置版本管理、配置项管理、节点管理、配置同步等。 持续交付：包括持续集成、自动化部署等流程。目的就是小步迭代，快速交付。 进一步提升运维效率 服务监控: 微服务架构下节点数目众多，需要监控的机器、网络、进程、接口等的数量大大增加，需要一个强大的监控系统，能够提供实时搜集信息进行分析以及实时分析之上的预警。包括监控服务的请求次数、响应时间分布、最大/最小响应值、错误码分布等 服务跟踪：跟踪一个请求的完整路径，包括请求发起时间、响应时间、响应码、请求参数、返回结果等信息，也叫做全链路跟踪。通常的服务监控可以和服务监控做在一起，宏观信息由服务跟踪呈现，微观单个服务/节点的信息由服务监控呈现。服务跟踪目前的实现理论基本都是Google的Dapper论文。 服务安全：内网之间的微服务调用原则上讲应该是都可以互相访问写，一般并不需要权限控制，但有时候限于业务要求，会对接口、数据等方面有安全控制的要求。此部分可以以配置的方式存在于服务注册中心中，和服务绑定，在请求时由做为服务提供者的服务节点进行安全策略控制。配置则可以存储在配置中心以方便动态修改。 在微服务数量很少的情况下，以上基础设施的优先级自上而下降低。否则，仅仅依赖人工操作，则投入产出比会很低。 还需要提到的是Docker容器技术。虽然这个对于微服务并不是必须的，但是容器技术轻量级、灵活、与应用依存、屏蔽环境差异的特性对于持续交付的实现是至关重要的，即使对于传统的单体应用也能够给其带来交付效率的大幅提升。 架构设计模式在引入微服务之后，传统的单体应用变为了一个一个服务，之前一个应用直接提供接口给客户端访问的架构不再适用。微服务架构下，针对不同设备的接口做为BFF层（Backend For Frontend），也叫做用户体验适配层，负责聚合、编排微服务的数据转换成前端需要的数据。服务之间的调用则在允许的情况下（允许延迟）尽可能使用异步消息传递方式，如此形成面向用户体验的微服务架构设计模式。如下图所示： Client -&gt; API Gateway -&gt; BFF（Backend For Frontend） -&gt; Downstream Microservices 后台采用微服务架构，微服务可以采用不同的编程语言和不同的存储机制。 前台采用BFF模式对不同的用户体验（如桌面浏览器，Native App，平板响应式Web）进行适配。 BFF、API Orchestration Layer，Edge Service Layer，Device Wrapper Layer是相同的概念。 BFF不能过多，过多会造成代码逻辑重复冗余。 可以将网关承担的功能，如Geoip、限流、安全认证等跨横切面功能和BFF做在同一层，虽然增加了BFF层的复杂性，但能够得到性能优势。 服务拆分微服务架构最核心的环节，主要是对服务的横向拆分。服务拆分就是讲一个完整的业务系统解耦为服务，服务需要职责单一，之间没有耦合关系，能够独立开发和维护。 服务拆分不是一蹴而就的，需要在开发过程中不断地理清边界。在完全理清服务之前，尽量推迟对服务的拆分，尤其是对数据库的拆分。 拆分方法如下： 基于业务逻辑拆分 基于可扩展拆分 基于可靠性拆分 基于性能拆分 其中，对于无法修改的遗留系统，采用绞杀者模式：在遗留系统外面增加新的功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。 拆分过程需要遵守的规范如下： 先少后多、先粗后细（粒度） 服务纵向拆分最多三层，两次调用：Controller、组合服务、基础服务 仅仅单向调用，禁止循环调用 串行调用改为并行调用或者异步化 接口应该幂等 接口数据定义严禁内嵌，透传 规范化工程名 先拆分服务，等服务粒度确定后再拆分数据库。 微服务框架上面讲述了微服务架构的众多基础设施，如果每一个基础设施都需要自己开发的话是非常巨大的开发工作。目前市面上已经有不少开源的微服务框架可以选择。 Spring Boot Spring Boot是用来简化新Spring应用的初始搭建以及开发过程的。其虽然不是微服务框架，但其设计的初衷本质就是微应用的底层框架，因此非常适合用于微服务基础设施的开发以及微服务的应用开发。尤其对于Spring技术栈的团队来说，基于Spring Boot开发微服务框架和应用是自然而然的一个选择。 Dubbo&amp;&amp;Motan Dubbo阿里开源的服务治理框架。其出现在微服务理念兴起之前，可以看做是SOA框架的集大成之作。但其仅仅包含了微服务基础设施的部分功能，诸如熔断、服务跟踪、网关等都没有实现。 Motan则是微博开源的类似Dubbo的RPC框架，与Dubbo相比更轻量级。 服务发现 ：服务发布、订阅、通知 高可用策略 ：失败重试（Failover）、快速失败（Failfast）、资源隔离 - 负载均衡 ：最少活跃连接、一致性 Hash、随机请求、轮询等 扩展性 ：支持 SPI 扩展（service provider interface） 其他 ：调用统计、访问日志等 Spring Cloud Spring Cloud是基于Spring Boot实现的微服务框架，也可以看做一套微服务实现规范。基本涵盖了微服务基础设施的方方面面，包括配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等。其基于Spring生态，社区支持非常好。但其很多组件都没有经过生产环境验证，需要慎重选择。 Spring Cloud Netflix是Spring Cloud的一个子项目，是Spring对Netflix OSS的集成实现。基于Netflix的大规模使用，其中的已经被广泛使用的组件包括： 此外，另一个子项目Spring Cloud Alibaba则是Alibaba开源的基于Spring Boot的微服务框架，主要是对阿里云服务的支持。 Eureka：服务注册和服务发现 Ribbon：弹性而智能的进程间和服务通讯机制，客户端负载均衡 Hystrix：熔断器，在运行时提供延迟和容错的隔离 Zuul: 服务网关 Service Mesh 上述的微服务框架都是侵入式的，服务化的过程都需要进行代码改造。Service Mesh则是下一代微服务架构，最明显的特征就是无入侵。采用sidecar模式来解决系统架构微服务化后的服务间通信和治理问题。 如上图所示，目前主流的开源实现包括： Linkerd和Envoy：以 sidecar 为核心，关注如何做好proxy，并完成一些通用控制平面的功能。缺乏对这些sidecar的管理和控制。 Istio和Conduit：目前最为流行的Service Mesh实现方案，集中在更加强大的控制平面(sidecar被称为数据平面)功能。前者由Google和IBM合作，并使用了Envoy作为sidecar部分的实现；后者则是Linkerd作者的作品。相比起来，Istio有巨头背景，功能强大，但可用性和易用性一直不高，Conduit则相对简单、功能聚焦。 限于Service Mesh带来的性能延迟的开销以及sidecar对分布复杂性的增加，其对大规模部署(微服务数目多)、异构复杂(交互协议/开发语言类型多)的微服务架构带来的收益会更大。 6. Sofastack 蚂蚁金服开源的构建金融级分布式架构的一套中间件。包 括微服务开发框架、RPC框架、服务注册中心、全链路追 踪、服务监控、Service Mesh等一整套分布式应用开发 工具。 特别值得一提的是SOFAMesh。其是对下一代微服务架 构Service Mesh的大规模落地方案实践，基于 Istio改 进和扩展而来，应该是国内最为成熟的开源Service Mesh方案。 此外，需要提到Kubernetes(K8s)，其本身提供了部分的微服务特性支持（通过域名做服务发现），对代码无侵入。但服务调用、熔断这些都需要自己实现。 综上，目前公司技术团队技术栈是Spring，并且已有服务的实现都是基于Dubbo，因此选择Spring Cloud Netflix做为基础的微服务框架，对其中不成熟或者缺乏的组件，选择业界更为成熟的组件替代即可。 API网关：Zuul 服务注册中心：Dubbo 配置中心：disconf 服务监控&amp;&amp;全链路追踪：CAT 服务开发框架：Spring Boot 日志监控、告警：ELK + Elasalert 流量控制：Sentinel 消息队列：Kafka 参考资料 What’s so bad about monoliths anyway…?! Microservice MicroservicePremium Microservice Trade-Offs MicroservicePrerequisites MonolithFirst 服务怎么拆？ BFF@SoundCloud Service Mesh 及其主流开源实现解析","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://kanchai.club/tags/JAVA/"},{"name":"spring","slug":"spring","permalink":"https://kanchai.club/tags/spring/"},{"name":"微服务","slug":"微服务","permalink":"https://kanchai.club/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"springmvc实现参数处理，rsa解密数据","slug":"springmvc实现参数处理，rsa解密数据","date":"2020-05-09T07:28:21.503Z","updated":"2020-05-09T07:28:09.000Z","comments":true,"path":"2020/05/09/springmvc实现参数处理，rsa解密数据/","link":"","permalink":"https://kanchai.club/2020/05/09/springmvc%E5%AE%9E%E7%8E%B0%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86%EF%BC%8Crsa%E8%A7%A3%E5%AF%86%E6%95%B0%E6%8D%AE/","excerpt":"","text":"用于实现类似@RequestBody的作用，前后端在没有https的情况下，利用rsa非对称加密，实现数据安全性 首先创建注解 1234567891011/** * RSA加密数据解密 * * @author: 李涛 * @version: 2019年06月19日 10:44 */@Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface RequestEncrypt &#123;&#125; 利用spring参数处理器，实现接口，拦截该注解的参数，处理并返回 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 处理加密数据,参数 * * @author: 李涛 * @version: 2019年06月19日 10:40 */@Componentpublic class HandlerMethodArgumentCustomer implements HandlerMethodArgumentResolver &#123; private static final Logger LOG = LoggerFactory.getLogger(HandlerMethodArgumentCustomer.class); @Autowired private ISysSignSV sysSignSV; @Override public boolean supportsParameter(MethodParameter parameter) &#123; if (parameter.hasParameterAnnotation(RequestEncrypt.class)) &#123; return true; &#125; return false; &#125; @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; HttpServletRequest nativeRequest = webRequest.getNativeRequest(HttpServletRequest.class); String contentType = nativeRequest.getContentType(); if (!contentType.equals(MediaType.APPLICATION_JSON_VALUE) &amp;&amp; !contentType.equals(MediaType.APPLICATION_JSON_UTF8_VALUE) ) &#123; throw new MediaTypeNotSupportedStatusException(\"期望请求为application/json\"); &#125; // 加密数据 byte[] body = ServletUtils.getRequestBody(); String jsonData = IOUtils.toString(body); if (body.length == 0 || StringUtils.isBlank(jsonData) || jsonData.length() == 0) &#123; return null; &#125; // 获取当前登录用户的公私钥。如果没空，在header里取 Object appKeyObj = ShiroUtil.getSession().getAttribute(Global.APP_KEY); Object appSercetObj = ShiroUtil.getSession().getAttribute(Global.APP_SERCET); String appKey = appKeyObj == null ? null : String.valueOf(appKeyObj); String appSercet = appSercetObj == null ? null : String.valueOf(appSercetObj); if (StringUtils.isBlank(appKey) || StringUtils.isBlank(appSercet)) &#123; appKey = ServletUtils.getHeader(\"appKey\"); if (StringUtils.isBlank(appKey)) &#123; return null; &#125; else &#123; // 获取私钥 SysSign sysSign = sysSignSV.findByModel(SysSignModel.builder().appKey(appKey).includeColumns(\"app_secret\").build()); appSercet = sysSign.getAppSecret(); &#125; &#125; try &#123; RSA rs = new RSA(appSercet, appKey); byte[] decrypt = rs.decrypt(jsonData, KeyType.PrivateKey); jsonData = IOUtils.toString(decrypt); &#125; catch (Exception e) &#123; LOG.error(\"Rsa加密数据解密异常\"); &#125; return JSONObject.parseObject(jsonData, parameter.getParameterType()); &#125;&#125; 将参数处理器，加入到spring的拦截器调用链 123456789101112131415/** * 向MVC中添加自定义组件 */@Componentpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Autowired private HandlerMethodArgumentCustomer handlerMethodArgumentCustomer; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; resolvers) &#123; resolvers.add(handlerMethodArgumentCustomer); &#125;&#125; ok","categories":[],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"},{"name":"JAVA","slug":"JAVA","permalink":"https://kanchai.club/tags/JAVA/"},{"name":"spring","slug":"spring","permalink":"https://kanchai.club/tags/spring/"}]},{"title":"解决PropertySource不能读取yml的问题","slug":"解决PropertySource不能读取yml的问题","date":"2020-05-09T07:19:57.986Z","updated":"2020-05-09T07:19:22.000Z","comments":true,"path":"2020/05/09/解决PropertySource不能读取yml的问题/","link":"","permalink":"https://kanchai.club/2020/05/09/%E8%A7%A3%E5%86%B3PropertySource%E4%B8%8D%E8%83%BD%E8%AF%BB%E5%8F%96yml%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"12345678910111213141516171819202122232425262728/** * 解决PropertySource不能读取yml的问题 * * @author: 李涛 * @version: 2020年03月26日 17:12 */public class YamlConfigFactory extends DefaultPropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException &#123; String sourceName = name != null ? name : resource.getResource().getFilename(); if (!resource.getResource().exists()) &#123; return new PropertiesPropertySource(sourceName, new Properties()); &#125; else if (sourceName.endsWith(\".yml\") || sourceName.endsWith(\".yaml\")) &#123; Properties propertiesFromYaml = loadYml(resource); return new PropertiesPropertySource(sourceName, propertiesFromYaml); &#125; else &#123; return super.createPropertySource(name, resource); &#125; &#125; private Properties loadYml(EncodedResource resource) throws IOException &#123; YamlPropertiesFactoryBean factory = new YamlPropertiesFactoryBean(); factory.setResources(resource.getResource()); factory.afterPropertiesSet(); return factory.getObject(); &#125;&#125; 使用方式 123456789101112131415161718192021222324/** * 用户自定义配置 * * @author: 李涛 * @version: 2019年07月05日 16:44 */@PropertySource(value=\"classpath:file-table-config.yml\",factory = YamlConfigFactory.class)@ConfigurationProperties(prefix = \"config\")@Component@Datapublic class FileTableConfig &#123; /*** * 表达式 */ private String corn; /*** * 表和资源字段 */ private List&lt;String&gt; tables;&#125;","categories":[],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"},{"name":"JAVA","slug":"JAVA","permalink":"https://kanchai.club/tags/JAVA/"}]},{"title":"超长JVM总结","slug":"超长JVM总结","date":"2020-05-08T08:08:34.062Z","updated":"2020-05-08T08:08:21.000Z","comments":true,"path":"2020/05/08/超长JVM总结/","link":"","permalink":"https://kanchai.club/2020/05/08/%E8%B6%85%E9%95%BFJVM%E6%80%BB%E7%BB%93/","excerpt":"","text":"什么是JVMJVM 是可运行 Java 代码的假想计算机 ，包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收，堆 和 一个存储方法域。JVM 是运行在操作系统之上的，它与硬件没有直接的交互。 在这里插入图片描述 我们都知道 Java 源文件，通过编译器，能够生产相应的.Class 文件，也就是字节码文件，而字节码文件又通过 Java 虚拟机中的解释器，编译成特定机器上的机器码 。 在这里插入图片描述 每一种平台的解释器是不同的，但是实现的虚拟机是相同的，这也就是 Java 为什么能够跨平台的原因了 ，当一个程序从开始运行，这时虚拟机就开始实例化了，多个程序启动就会存在多个虚拟机实例。程序退出或者关闭，则虚拟机实例消亡，多个虚拟机实例之间数据不能共享。 在这里插入图片描述 线程这里所说的线程指程序执行过程中的一个线程实体。JVM 允许一个应用并发执行多个线程 。Hotspot JVM 中的 Java 线程与原生操作系统线程有直接的映射关系。当线程本地存储、缓冲区分配、同步对象、栈、程序计数器等准备好以后，就会创建一个操作系统原生线程。Java 线程结束，原生线程随之被回收。操作系统负责调度所有线程，并把它们分配到任何可用的 CPU 上。当原生线程初始化完毕，就会调用 Java 线程的 run() 方法。当线程结束时，会释放原生线程和 Java 线程的所有资源。 Hotspot JVM 后台运行的系统线程主要有下面几个： 虚拟机线程:这个线程等待 JVM 到达安全点操作出现。这些操作必须要在独立的线程里执行，因为当堆修改无法进行时，线程都需要 JVM位于安全点。这些操作的类型有：stop-the-world 垃圾回收、线程栈dump、线程暂停、线程偏向锁（biased locking）解除。 周期性任务线程:这线程负责定时器事件（也就是中断），用来调度周期性操作的执行。 GC 线程 :这些线程支持 JVM 中不同的垃圾回收活动。 编译器线程:这些线程在运行时将字节码动态编译成本地平台相关的机器码。 信号分发线程:这个线程接收发送到 JVM 的信号并调用适当的 JVM 方法处理。 JVM内存区域在这里插入图片描述 JVM 内存区域主要分为线程私有区域【程序计数器、虚拟机栈、本地方法区】、线程共享区域【JAVA 堆、方法区】、直接内存。-线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁(在 HotspotVM 内, 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的生/死对应)。 线程共享区域随虚拟机的启动/关闭而创建/销毁。 在这里插入图片描述 程序计数器( 线程私有） 一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有”的内存。 正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如果还是 Native 方法，则为空。 这个内存区域是唯一一个在虚拟机中没有规定任OutOfMemoryError 情况的区域。 JAVA虚拟机栈( 线程私有) 是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接(Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。 在这里插入图片描述 本地方法区(线程私有） 本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个C 栈，但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一。 堆（Heap- 线程共享）运行时数据区 是被线程共享的一块内存区域，创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行垃圾收集的最重要的内存区域。由于现代 VM 采用分代收集算法, 因此 Java 堆从 GC 的角度还可以细分为: 新生代( Eden 区 、 From Survivor 区 和 To Survivor 区 )和老年代(jdk1.7)。 方法区/ 永久代 （线程共享） 即我们常说的永久代(Permanent Generation), 用于存储被 JVM 加载的类信息、常量、静态变量、即时编译器编译后的代码等数据. HotSpot VM把GC分代收集扩展至方法区, 即使用Java堆的永久代来实现方法区, 这样 HotSpot 的垃圾收集器就可以像管理 Java 堆一样管理这部分内存,而不必为方法区开发专门的内存管理器(永久带的内存回收的主要目标是针对常量池的回收和类型的卸载, 因此收益一般很小)。 运行时常量池 （Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。Java 虚拟机对 Class 文件的每一部分（自然也包括常量池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会被虚拟机认可、装载和执行。 直接内存 直接内存并不是 JVM 运行时数据区的一部分, 但也会被频繁的使用: 在 JDK 1.4 引入的 NIO 提供了基于 Channel 与 Buffer 的 IO 方式, 它可以使用 Native 函数库直接分配堆外内存, 然后使用DirectByteBuffer 对象作为这块内存的引用进行操作， 这样就避免了在 Java堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。 JVM运行时内存(jdk1.7) Java 堆从 GC 的角度还可以细分为: 新生代( Eden 区 、 From Survivor 区 和 To Survivor 区 )和老年代 在这里插入图片描述 新生代是用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁触发MinorGC 进行垃圾回收。新生代又分为 Eden 区、ServivorFrom、ServivorTo 三个区。 Eden区：Java新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老年代）。当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收。 ServivorFrom：上一次 GC 的幸存者，作为这一次 GC 的被扫描者。 ServivorTo：保留了一次 MinorGC 过程中的幸存者。 MinorGC 的过程：（复制-&gt;清空-&gt;互换）MinorGC 采用复制算法。 eden 、 servicorFrom 复制到 ServicorTo，年龄+1 首先，把 Eden和 ServivorFrom区域中存活的对象复制到 ServicorTo区域（如果有对象的年龄以及达到了老年的(默认15岁，可以通过-XXMaxTenuringThreshold设置)，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不够位置了就放到老年区）。 清空 eden 、 servicorFrom** 清空 Eden 和 ServicorFrom 中的对象； ServicorTo 和 ServicorFrom 互换 最后，ServicorTo 和 ServicorFrom 互换，原 ServicorTo 成为下一次 GC 时的 ServicorFrom区。 老年代 主要存放应用程序中生命周期长的内存对象。 老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。 MajorGC 采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC 的耗时比较长，因为要扫描再回收。MajorGC 会产生内存碎片，为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的时候，就会抛出 OOM（Out of Memory）异常。 永久代-指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被放入永久区域，它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的 Class 的增多而胀满，最终抛出 OOM 异常。 JAVA8 与元数据在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 nativememory, 字符串池和类的静态变量放入 java 堆中，这样可以加载多少类的元数据就不再由MaxPermSize 控制, 而由系统的实际可用空间来控制。 垃圾回收与算法在这里插入图片描述 如何确定垃圾引用计数法 在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。简单说，即一个对象如果没有任何与之关联的引用，即他们的引用计数都不为 0，则说明对象不太可能再被用到，那么这个对象就是可回收对象。 可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍然是可回收对象，则将面临回收。 标记清除算法（ Mark-Sweep ） 最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记出所有需要回收的对象，清除阶段回收被标记的对象所占用的空间。如图 在这里插入图片描述 从图中我们就可以发现，该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题。复制算法（copying ） 为了解决 Mark-Sweep 算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉，如图： 在这里插入图片描述 这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原本的一半。且存活对象增多的话，Copying 算法的效率会大大降低。 标记整理算法(Mark-Compact)结合了以上两个算法，为了避免缺陷而提出。标记阶段和 Mark-Sweep 算法相同，标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。如图： 在这里插入图片描述 分代收集算法 分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。 新生代与复制算法 目前大部分 JVM 的 GC 对于新生代都采取 Copying 算法，因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少，但通常并不是按照 1：1 来划分新生代。一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。 在这里插入图片描述 老年代与标记复制算法而老年代因为每次只回收少量对象，因而采用 Mark-Compact 算法。 JAVA 虚拟机提到过的处于方法区的永生代(Permanet Generation)，它用来存储 class 类，常量，方法描述等。对永生代的回收主要包括废弃常量和无用的类。 对象的内存分配主要在新生代的 Eden Space 和 Survivor Space 的 From Space(Survivor 目前存放对象的那一块)，少数情况会直接分配到老生代。 当新生代的 Eden Space 和 From Space 空间不足时就会发生一次 GC，进行 GC 后，EdenSpace 和 From Space 区的存活对象会被挪到 To Space，然后将 Eden Space 和 FromSpace 进行清理。 如果 To Space 无法足够存储某个对象，则将这个对象存储到老生代。 在进行 GC 后，使用的便是 Eden Space 和 To Space 了，如此反复循环。 当对象在 Survivor 区躲过一次 GC 后，其年龄就会+1。默认情况下年龄到达 15 的对象会被移到老生代中。 GC 分代收集算法 VS 分区收集算法分代收集算法当前主流 JVM 垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为几块, 如 JVM 中的 新生代、老年代、永久代，这样就可以根据各年代特点分别采用最适当的 GC 算法。 在新生代-复制算法每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量存活对象的复制成本就可以完成收集。 在老年代-标记整理算法因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存。 分区收集算法分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次 GC 所产生的停顿。 GC 垃圾收集器Java 堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收 算法 ,年老代主要使用标记-整理垃圾回收算法，因此 java 虚拟中针对新生代和年老代分别提供了多种不同的垃圾收集器，JDK1.6 中 Sun HotSpot 虚拟机的垃圾收集器如下： 在这里插入图片描述 Serial 垃圾收集器 （单线程、 复制算法 ） Serial（英文连续）是最基本垃圾收集器，使用复制算法，曾经是JDK1.3.1之前新生代唯一的垃圾收集器。Serial 是一个单线程的收集器，它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。Serial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。 ParNew 垃圾收集器 （Serial+ 多线程 ） ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。ParNew 收集器默认开启和 CPU 数目相同的线程数，可以通过-XX:ParallelGCThreads 参数来限制垃圾收集器的线程数。【Parallel：平行的】ParNew虽然是除了多线程外和Serial收集器几乎完全一样，但是ParNew垃圾收集器是很多java虚拟机运行在 Server 模式下新生代的默认垃圾收集器。 Parallel Scavenge 收集器 （多线程复制算法、高效） Parallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，它重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU 用于运行用户代码的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。 Serial Old 收集器 (单线程标记整理算法）Serial Old 是 Serial 垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法，这个收集器也主要是运行在 Client 默认的 java 虚拟机默认的年老代垃圾收集器。在 Server 模式下，主要有两个用途： 在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。 作为年老代中使用 CMS 收集器的后备垃圾收集方案。新生代 Serial 与年老代 Serial Old 搭配垃圾收集过程图： 在这里插入图片描述 新生代 Parallel Scavenge 收集器与 ParNew 收集器工作原理类似，都是多线程的收集器，都使用的是复制算法，在垃圾收集过程中都需要暂停所有的工作线程。新生代 ParallelScavenge/ParNew 与年老代 Serial Old 搭配垃圾收集过程图： 在这里插入图片描述 Parallel Old 收集器（多线程标记整理算法）Parallel Old收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.6才开始提供。在 JDK1.6 之前，新生代使用 ParallelScavenge 收集器只能搭配年老代的 Serial Old 收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old 正是为了在年老代同样提供吞吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代 Parallel Scavenge和年老代 Parallel Old 收集器的搭配策略。新生代 Parallel Scavenge 和年老代 Parallel Old 收集器搭配运行过程图： 在这里插入图片描述 CMS 收集器 （多线程标记清除算法）Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾回收停顿时间，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。CMS 工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下 4 个阶段： 1.初始标记：只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 2.并发标记： 进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。 3.重新标记： 为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 4.并发清除： 清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 在这里插入图片描述 G1 收集器Garbage first 垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与 CMS 收集器，G1 收集器两个最突出的改进是： 基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://kanchai.club/tags/JAVA/"},{"name":"JVM","slug":"JVM","permalink":"https://kanchai.club/tags/JVM/"}]},{"title":"秒杀系统设计的 5 个要点：前端三板斧＋后端两条路！","slug":"秒杀系统设计的_5_个要点：前端三板斧＋后端两条路！","date":"2020-05-08T07:54:28.590Z","updated":"2020-05-08T07:53:39.000Z","comments":true,"path":"2020/05/08/秒杀系统设计的_5_个要点：前端三板斧＋后端两条路！/","link":"","permalink":"https://kanchai.club/2020/05/08/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%9A%84_5_%E4%B8%AA%E8%A6%81%E7%82%B9%EF%BC%9A%E5%89%8D%E7%AB%AF%E4%B8%89%E6%9D%BF%E6%96%A7%EF%BC%8B%E5%90%8E%E7%AB%AF%E4%B8%A4%E6%9D%A1%E8%B7%AF%EF%BC%81/","excerpt":"","text":"作者：cfyme https://www.tuicool.com/articles/JzQvUb 秒杀系统涉及到的知识点： 高并发，cache，锁机制 基于缓存架构redis,Memcached的先进先出队列。 稍微大一点的秒杀，肯定是分布式的集群的，并发来自于多个节点的JVM，synchronized所有在JVM上加锁是不行了 数据库压力 秒杀超卖问题 如何防止用户来刷， 黑名单？IP限制？ 利用memcached的带原子性特性的操作做并发控制. 秒杀简单设计方案如：比如有10件商品要秒杀，可以放到缓存中，读写时不要加锁。当并发量大的时候，可能有25个人秒杀成功，这样后面的就可以直接抛秒杀结束的静态页面。进去的25个人中有15个人是不可能获得商品的。所以可以根据进入的先后顺序只能前10个人购买成功。后面15个人就抛商品已秒杀完。 假设我们的秒杀场景：比如某商品10件物品待秒. 假设有100台web服务器(假设web服务器是Nginx + Tomcat),n台app服务器,n个数据库 第一步 如果Java层做过滤, 可以在每台web服务器的业务处理模块里做个计数器AtomicInteger(10)=待秒商品总数,decreaseAndGet()&gt;＝0的继续做后续处理, &lt;0的直接返回秒杀结束页面.这样经过第一步的处理只剩下100台*10个=1000个请求. 第二步, memcached 里以商品id作为key的value放个10, 每个web服务器在接到每个请求的同时, 向memcached服务器发起请求, 利用memcached的decr(key,1)操作返回值&gt;=0的继续处理, 其余的返回秒杀失败页面.这样经过第二步的处理只剩下100台中最快速到达的10个请求. 第三步, 向App服务器发起下单操作事务. 第四步, App服务器向商品所在的数据库请求减库存操作, (操作数据库时可以 update table set count=count-1 where id=商品id and count&gt;0; update 成功记录数为1, 再向订单数据库添加订单记录, 都成功后提交整个事务, 否则的话提示秒杀失败. 用户进入支付流程. 在看看淘宝的秒杀：1、前端面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】 扩容 加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。 静态化 将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 限流 一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。 或者活动入口的时候增加游戏或者问题环节进行消峰操作。 有损服务 最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。 2、后端那么后端的数据库在高并发和超卖下会遇到什么问题呢 首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。 最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。 针对上述问题，如何解决呢？淘宝的高大上解决方案： 关闭死锁检测，提高并发处理性能。 修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度。 组提交，降低server和引擎的交互次数，降低IO消耗。 解决方案1：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。 优点：解决性能问题 缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。 解决方案2：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。 优点：解决超卖问题，略微提升性能。 缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。 解决方案3：将写操作前移到MC中，同时利用MC的轻量级的锁机制CAS来实现减库存操作。 优点：读写在内存中，操作性能快，引入轻量级锁之后可以保证同一时刻只有一个写入成功，解决减库存问题。 缺点：没有实测，基于CAS的特性不知道高并发下是否会出现大量更新失败？不过加锁之后肯定对并发性能会有影响。 解决方案4：将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作，同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。 优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。 缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。 三、总结1、前端三板斧【扩容】【限流】【静态化】 2、后端两条路【内存】+【排队】","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://kanchai.club/tags/%E6%9E%B6%E6%9E%84/"},{"name":"系统设计","slug":"系统设计","permalink":"https://kanchai.club/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"}]},{"title":"大白话带你梳理一下Dubbo的那些事儿","slug":"大白话带你梳理一下Dubbo的那些事儿","date":"2020-04-26T02:39:56.223Z","updated":"2020-04-26T02:20:26.000Z","comments":true,"path":"2020/04/26/大白话带你梳理一下Dubbo的那些事儿/","link":"","permalink":"https://kanchai.club/2020/04/26/%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%A6%E4%BD%A0%E6%A2%B3%E7%90%86%E4%B8%80%E4%B8%8BDubbo%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/","excerpt":"","text":"首先声明，本文并不是什么代码实战类型的文章，适合于想对dubbo有更加全面认识的读者阅读，文章不会过于深奥，只是将一系列的知识点串通起来，帮助读者温故而知新。 RPC服务的介绍相信有过一些分布式开发经历的读者都有用过一些RPC框架，通过框架包装好之后提供的API接口调用远程服务，体验感觉起来就和调用本地服务一样轻松。这么方便好用的技术框架，在实际的开发过程中是如何包装的呢? 很早的时候，国外的工程师设计了一种能够通过A计算机调用B计算机上边应用程序的技术，这种技术不需要开发人员对于网络通讯了解过多，并且调用其他机器上边程序的时候和调用本地的程序一样方便好用。 A机器发起请求去调用B机器程序的时候会被挂起，B机器接收到A机器发起的请求参数之后会做一定的参数转换，最后将对应的程序结果返回给A，这就是最原始的RPC服务调用了。 RPC调用的优势简单不需要开发者对于网络通信做过多的设置，例如我们在使用http协议进行远程接口调用的时候，总是会需要编写较多的http协议参数（header，context，Accept-Language,Accept-Encode等等），这些处理对于开发人员来说，实际上都并不是特别友好。但是RPC服务调用框架通常都将这类解析进行了对应的封装，大大降低了开发人员的使用难度。 高效在网络传输方面，RPC更多是处于应用层和传输层之间。这里我们需要先理清楚一个问题，网络分层。RPC是处于会话层的部分，相比处于应用层的HTTP而言，RPC要比Rest服务调用更加轻便。 常见的远程调用技术rmi利用java.rmi包实现，基于Java远程方法协议(Java Remote Method Protocol) 和java的原生序列化。 Hessian是一个轻量级的remoting onhttp工具，使用简单的方法提供了RMI的功能。基于HTTP协议，采用二进制编解码。 protobuf-rpc-pro是一个Java类库，提供了基于 Google 的 Protocol Buffers 协议的远程方法调用的框架。基于 Netty 底层的 NIO 技术。支持 TCP 重用/ keep-alive、SSL加密、RPC 调用取消操作、嵌入式日志等功能。 Thrift是一种可伸缩的跨语言服务的软件框架。它拥有功能强大的代码生成引擎，无缝地支持C + +，C#，Java，Python和PHP和Ruby。thrift允许你定义一个描述文件，描述数据类型和服务接口。依据该文件，编译器方便地生成RPC客户端和服务器通信代码。 最初由facebook开发用做系统内部语言之间的RPC通信，2007年由facebook贡献到apache基金 ，现在是apache下的opensource之一 。支持多种语言之间的RPC方式的通信：php语言client可以构造一个对象，调用相应的服务方法来调用java语言的服务，跨越语言的C/S RPC调用。底层通讯基于SOCKET。 Avro出自Hadoop之父Doug Cutting, 在Thrift已经相当流行的情况下推出Avro的目标不仅是提供一套类似Thrift的通讯中间件,更是要建立一个新的，标准性的云计算的数据交换和存储的Protocol。支持HTTP，TCP两种协议。 DubboDubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架**，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。** 上边我们说到了RPC的远程调用发展历史，那么下边我们一起来深入探讨一下RPC的服务。 首先我们来看看OSI的网络协议内容。 OSI的七层网络模型对于OSI的七层网络模型我绘制了下边的这么一张图： 下边是我个人对于这七层协议的理解： 应用层 主要是对于服务接口的格式多定义，例如提供一定的终端接口暴露给外部应用调用。 表示层 处理一些数据传输的格式转换，例如说编码的统一，加密和解密处理。 会话层 管理用户的会话和对话，建立不同机器之间的会话连接。 传输层 向网络层提供可靠有序的数据包信息。 网络层 真正发送数据包信息的层面，提供流和拥塞控制，从而降低网络的资源损耗。 数据链路层 封装对应的数据包，检测和纠正数据包传输信息。 物理层 通过网络通讯设备发送数据 HTTP &amp; RPCHTTP主要是位于TCP/IP协议栈的应用层部分，首先需要构建三次握手的链接，接着才能进行数据信息的请求发送，最后进行四次挥手断开链接。 RPC在请求的过程中跨越了传输层和应用层，这是因为它本身是依赖于Socket的原因。（再深入的原因我也不知道）。减少了上边几层的封装，RPC的请求效率自然是要比HTTP高效很多。 那么一个完整的RPC调用应该包含哪些部分呢？ 通常我们将一个完整的RPC架构分为了以下几个核心组件： Server Client Server Stub Client Stub 这四个模块中我稍微说下stub吧。这个单词翻译过来称之为存根。 *Client Stub *就是将客户端请求的参数，服务名称，服务地址进行打包，统一发送给server方。 *Server Stub *我用通俗易懂的语言来解释就是服务端接收到Client发送的数据之后进行消息解包，调用本地方法。（看过netty拆包机制应该会对这块比较了解）。 Dubbo的核心属性其实Dubbo配置里面的核心内容就是 _服务暴露，服务发现，服务治理_。 什么是服务暴露，服务发现，服务治理？下边我们用一段xml的配置来进行讲解： 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;dubbo:application name=\"dubbo-invoker-provider\"&gt; &lt;dubbo:parameter key=\"qos.port\" value=\"22222\"/&gt; &lt;/dubbo:application&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;bean id=\"userService\" class=\"com.sise.user.service.UserServiceImpl\" /&gt; &lt;dubbo:service interface=\"com.sise.user.service.UserService\" ref=\"userService\" /&gt;&lt;/beans&gt; 在dubbo的配置文件里面，通常我们所说的dubbo:service 可以理解为服务暴露，dubbo:refernce 为服务发现，mock是服务治理，timeout属于服务治理的一种（性能调优）. 假设dubbo里面希望将一些公共的配置抽取出来，我们可以通过properties文件进行配置，dubbo在加载配置文件的优先顺序如下： 优先会读取JVM -D启动参数后边的内容 读取xml配置文件 读取properties配置文件内容 dubbo默认会读取dubbo.properties配置文件的信息，例如下边这种配置： 12dubbo.application.name&#x3D;dubbo-user-servicedubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;127.0.0.1:2181 假设我们的dubbo配置文件不命名为dubbo.properties（假设命名为了my-dubbo.properties）的时候，可以在启动参数的后边加上这么一段指令： 1-Ddubbo.properties.file&#x3D;my-dubbo.properties 那么在应用程序启动之后，对应的工程就会读取指定的配置文件，这样就可以将一些共用的dubbo配置给抽取了出来。 XML和配置类的映射在工作中，我们通常都会通过配置xml的方式来设定一个服务端暴露的服务接口和消费端需要调用的服务信息，这些配置的xml实际上在dubbo的源码中都会被解析为对应的实体类对象。 例如说我们常用到的reference配置类，下边我贴出一段代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.sise.user.config;import com.sise.user.service.UserService;import com.sise.user.service.UserServiceImpl;import org.apache.dubbo.config.*;import java.io.IOException;import java.util.concurrent.CountDownLatch;/** * dubbo里面的自定义配置类 * * @author idea * @data 2019/12/29 */public class DubboSelfDefConfig &#123; /** * dubbo的服务暴露 */ public void server() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"dubbo-server-config\"); RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(\"zookeeper://127.0.0.1:2181\"); ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setName(\"dubbo\"); protocolConfig.setPort(20880); protocolConfig.setThreads(200); UserService userService = new UserServiceImpl(); ServiceConfig&lt;UserService&gt; serviceConfig = new ServiceConfig&lt;&gt;(); serviceConfig.setApplication(applicationConfig); serviceConfig.setRegistry(registryConfig); serviceConfig.setProtocol(protocolConfig); serviceConfig.setInterface(UserService.class); serviceConfig.setRef(userService); serviceConfig.export(); &#125; public void consumer() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"dubbo-client-config\"); RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(\"zookeeper://127.0.0.1:2181\"); ReferenceConfig&lt;UserService&gt; referenceConfig = new ReferenceConfig&lt;&gt;(); referenceConfig.setApplication(applicationConfig); referenceConfig.setRegistry(registryConfig); referenceConfig.setInterface(UserService.class); UserService localRef = referenceConfig.get(); localRef.echo(\"idea\"); &#125; public static void main(String[] args) throws InterruptedException, IOException &#123; DubboSelfDefConfig d = new DubboSelfDefConfig(); d.consumer(); CountDownLatch countDownLatch = new CountDownLatch(1); countDownLatch.await(); &#125;&#125; 在这段代码里面，通过案例可以发现有这些信息内容： 12UserService localRef = referenceConfig.get();localRef.echo(\"idea\"); 这两行语句是获取具体服务的核心之处，由于我在别处定义了一个叫做UserService 的公共服务接口，因此在服务引用的过程中可以进行转换。 Dubbo2.7的三大新特新Dubbo的github官方地址为 https://github.com/apache/dubbo 在这里插入图片描述 Dubbo 目前有如图所示的 5 个分支，其中 2.7.1-release 只是一个临时分支，忽略不计，对其他 4 个分支而言，我归纳了一下，分别有如下信息： 2.5.x 近期已经通过投票，Dubbo 社区即将停止对其的维护。 2.6.x 为长期支持的版本，也是 Dubbo 贡献给 Apache 之前的版本，其包名前缀为：com.alibaba，JDK 版本对应 1.6。 3.x-dev 是前瞻性的版本，对 Dubbo 进行一些高级特性的补充，如支持 rx 特性。 master 为长期支持的版本，版本号为 2.7.x，也是 Dubbo 贡献给 Apache 的开发版本，其包名前缀为：org.apache，JDK 版本对应 1.8。 Dubbo 2.7 新特性Dubbo 2.7.x 作为 Apache 的孵化版本，除了代码优化之外，还新增了许多重磅的新特性，本文将会介绍其中最典型的2个新特性： 异步化改造 三大中心改造 异步化改造1.异步化调用的方式，在Dubbo2.7版本里面提供了异步化调用的功能，相关案例代码如下所示： 1234567891011@RestController@RequestMapping(value = \"/test\")public class TestController &#123; @Reference(async = true) private UserService userService; @GetMapping(\"/testStr\") public String testStr(String param)&#123; return userService.testEcho(param); &#125;&#125; 但是通过这种异步发送的方式我们通常都是获取不到响应值的，所以这里的return为null。 如果在低于2.7版本的dubbo框架中希望获取到异步返回的响应值还是需要通过RPC上下文来提取信息。 代码案例如下所示： 12345678@GetMapping(\"/futureGet\") public String futureGet(String param) throws ExecutionException, InterruptedException &#123; userService.testEcho(param); Future&lt;String&gt; future= RpcContext.getContext().getFuture(); String result = future.get(); System.out.println(\"this is :\"+result); return result; &#125; 通过RPC上下文的方式可以取到对应的响应值,但是这种方式需要有所等待，因此此时的效率会有所降低。假设我们将dubbo的版本提升到了2.7.1之后，通过使用CompletableFuture来进行接口优化的话，这部分的代码实现就会有所变化： 1234567891011/** * @author idea * @date 2019/12/31 * @Version V1.0 */public interface DemoService &#123; String sayHello(String name) ; default CompletableFuture&lt;String&gt; sayAsyncHello(String name)&#123; return CompletableFuture.completedFuture(sayHello(name)); &#125;&#125; 调用方代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.sise.consumer.controller;import com.sise.dubbo.service.DemoService;import org.apache.dubbo.config.annotation.Reference;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.concurrent.CompletableFuture;import java.util.concurrent.atomic.AtomicReference;/** * @author idea * @date 2019/12/31 * @Version V1.0 */@RestController@RequestMapping(value = \"/demo\")public class DemoController &#123; @Reference private DemoService demoService; @RequestMapping(value = \"/testDemo\") public String testDemo(String name)&#123; System.out.println(\"【testDemo】 this is :\"+name); return demoService.sayHello(name); &#125;. @RequestMapping(value = \"/testAsyncDemo\") public String testAsyncDemo(String name)&#123; System.out.println(\"【testAsyncDemo】 this is :\"+name); CompletableFuture&lt;String&gt; future = demoService.sayAsyncHello(name); AtomicReference&lt;String&gt; result = null; //通过一条callback线程来处理响应的数据信息 future.whenComplete((retValue,exception)-&gt;&#123; if(exception==null)&#123; System.out.println(retValue); result.set(retValue); &#125; else &#123; exception.printStackTrace(); &#125; &#125;); return \"通过一条callback线程来处理响应的数据信息,所以这个时候获取不到信息响应\"; &#125;&#125; 这样的调用是借助了callback线程来帮我们处理原先的数据内容，关于dubbo里面的异步化调用，我借用了官方的一张图来进行展示： 我们上边讲解的众多方法都只是针对于dubbo的客户端异步化，并没有讲解关于服务端的异步化处理，这是因为结合dubbo的业务线程池模型来思考，服务端的异步化处理比较鸡肋（因为dubbo内部服务端的线程池本身就是异步化调用的了）。 当然dubbo 2.6 里面对于接口异步化调用的配置到了2.7版本依旧有效。 三大中心的改造注册中心 在dubbo2.7之前，dubbo主要还是由consumer，provider ，register组成，然而在2.7版本之后，dubbo的注册中心被拆解为了三个中心，分别是原先的注册中心和元数据中心以及配置中心。 元数据配置 在dubbo2.7版本中，将原先注册在zk上边的过多数据进行了注册拆分，这样能够保证减少对于zk端的压力。具体配置如下： 1&lt;dubbo:registry address=“zookeeper://127.0.0.1:2181” simplified=\"true\"/&gt; 简化了相应配置之后，dubbo也只会上传一些必要的服务治理数据了，简化版本的服务数据只剩下下边这些信息： 12345dubbo://30.5.120.185:20880/com.sise.TestService?application=test-provider&amp;dubbo=2.0.2&amp;release=2.7.0&amp;timestamp=1554982201973 对于其他的元数据信息将会被存储到一些元数据中心里面，例如说redis，nacos，zk等 元数据配置改造主要解决的问题是：推送量大 -&gt; 存储数据量大 -&gt; 网络传输量大 -&gt; 延迟严重 配置中心dubbo2.7开始支持多种分布式配置中心的组件。例如说：zk，Spring Cloud Config, Apollo, Nacos，关于这部分的配置网上的资料也比较多，我就不在这里细说了。 END","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://kanchai.club/tags/Dubbo/"}]},{"title":"Dubbo 面试18问","slug":"Dubbo_面试18问","date":"2020-04-26T02:39:56.093Z","updated":"2020-04-26T02:38:53.000Z","comments":true,"path":"2020/04/26/Dubbo_面试18问/","link":"","permalink":"https://kanchai.club/2020/04/26/Dubbo_%E9%9D%A2%E8%AF%9518%E9%97%AE/","excerpt":"","text":"dubbo是什么dubbo是一个分布式框架，远程服务调用的分布式框架，其核心部分包含： 集群容错：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 远程通讯：提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 自动发现：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 dubbo能做什么透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 1、默认使用的是什么通信框架，还有别的选择吗?答：默认也推荐使用 netty 框架，还有 mina。 2、服务调用是阻塞的吗？答：默认是阻塞的，可以异步调用，没有返回值的可以这么做。 3、一般使用什么注册中心？还有别的选择吗？答：推荐使用 zookeeper 注册中心，还有 Multicast注册中心, Redis注册中心, Simple注册中心. ZooKeeper的节点是通过像树一样的结构来进行维护的，并且每一个节点通过路径来标示以及访问。除此之外，每一个节点还拥有自身的一些信息，包括：数据、数据长度、创建时间、修改时间等等。 4、默认使用什么序列化框架，你知道的还有哪些？答：默认使用 Hessian 序列化，还有 Duddo、FastJson、Java 自带序列化。hessian是一个采用二进制格式传输的服务框架，相对传统soap web service，更轻量，更快速。 Hessian原理与协议简析： http的协议约定了数据传输的方式，hessian也无法改变太多： hessian中client与server的交互，基于http-post方式。 hessian将辅助信息，封装在http header中，比如“授权token”等，我们可以基于http-header来封装关于“安全校验”“meta数据”等。hessian提供了简单的”校验”机制。 对于hessian的交互核心数据，比如“调用的方法”和参数列表信息，将通过post请求的body体直接发送，格式为字节流。 对于hessian的server端响应数据，将在response中通过字节流的方式直接输出。 hessian的协议本身并不复杂，在此不再赘言；所谓协议(protocol)就是约束数据的格式，client按照协议将请求信息序列化成字节序列发送给server端，server端根据协议，将数据反序列化成“对象”，然后执行指定的方法，并将方法的返回值再次按照协议序列化成字节流，响应给client，client按照协议将字节流反序列化成”对象”。 5、服务提供者能实现失效踢出是什么原理？答：服务失效踢出基于 zookeeper 的临时节点原理。 6、服务上线怎么不影响旧版本？答：采用多版本开发，不影响旧版本。在配置中添加version来作为版本区分 7、如何解决服务调用链过长的问题？答：可以结合 zipkin 实现分布式服务追踪。 8、说说核心的配置有哪些？核心配置有 dubbo:service/ dubbo:reference/ dubbo:protocol/ dubbo:registry/ dubbo:application/ dubbo:provider/ dubbo:consumer/ dubbo:method/ 9、dubbo 推荐用什么协议？答：默认使用 dubbo 协议。 10、同一个服务多个注册的情况下可以直连某一个服务吗？答：可以直连，修改配置即可，也可以通过 telnet 直接某个服务。 11、dubbo 在安全机制方面如何解决的？dubbo 通过 token 令牌防止用户绕过注册中心直连，然后在注册中心管理授权，dubbo 提供了黑白名单，控制服务所允许的调用方。 12、集群容错怎么做？答：读操作建议使用 Failover 失败自动切换，默认重试两次其他服务器。写操作建议使用 Failfast 快速失败，发一次调用失败就立即报错。 13、在使用过程中都遇到了些什么问题？如何解决的？1.同时配置了 XML 和 properties 文件，则 properties 中的配置无效 只有 XML 没有配置时，properties 才生效。 2.dubbo 缺省会在启动时检查依赖是否可用，不可用就抛出异常，阻止 spring 初始化完成，check 属性默认为 true。 测试时有些服务不关心或者出现了循环依赖，将 check 设置为 false 3.为了方便开发测试，线下有一个所有服务可用的注册中心，这时，如果有一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。 解决：让服务提供者开发方，只订阅服务，而不注册正在开发的服务，通过直连测试正在开发的服务。设置 dubbo:registry 标签的 register 属性为 false。 4.spring 2.x 初始化死锁问题。 在 spring 解析到 dubbo:service 时，就已经向外暴露了服务，而 spring 还在接着初始化其他 bean，如果这时有请求进来，并且服务的实现类里有调用applicationContext.getBean() 的用法。getBean 线程和 spring 初始化线程的锁的顺序不一样，导致了线程死锁，不能提供服务，启动不了。 解决：不要在服务的实现类中使用 applicationContext.getBean(); 如果不想依赖配置顺序，可以将 dubbo:provider 的 deplay 属性设置为 - 1，使 dubbo 在容器初始化完成后再暴露服务。 5.服务注册不上 检查 dubbo 的 jar 包有没有在 classpath 中，以及有没有重复的 jar 包 检查暴露服务的 spring 配置有没有加载 在服务提供者机器上测试与注册中心的网络是否通 6.出现 RpcException: No provider available for remote service 异常，表示没有可用的服务提供者， 检查连接的注册中心是否正确 到注册中心查看相应的服务提供者是否存在 检查服务提供者是否正常运行 7.出现” 消息发送失败” 异常 通常是接口方法的传入传出参数未实现 Serializable 接口。 14、dubbo 和 dubbox 之间的区别？答：dubbox 是当当网基于 dubbo 上做了一些扩展，如加了服务可 restful 调用，更新了开源组件等。 15、你还了解别的分布式框架吗？答：别的还有 spring 的 spring cloud，facebook 的 thrift，twitter 的 finagle 等。 16、Dubbo 支持哪些协议，每种协议的应用场景，优缺点？dubbo：单一长连接和 NIO 异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议 TCP，异步，Hessian 序列化； rmi：采用 JDK 标准的 rmi 协议实现，传输参数和返回参数对象需要实现 Serializable 接口，使用 java 标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议 TCP。多个短连接，TCP 协议传输，同步传输，适用常规的远程服务调用和 rmi 互操作。在依赖低版本的 Common-Collections 包，java 序列化存在安全漏洞； webservice：基于 WebService 的远程调用协议，集成 CXF 实现，提供和原生 WebService 的互操作。多个短连接，基于 HTTP 传输，同步传输，适用系统集成和跨语言调用； http：基于 Http 表单提交的远程调用协议，使用 Spring 的 HttpInvoke 实现。多个短连接，传输协议 HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器 JS 调用； hessian：集成 Hessian 服务，基于 HTTP 通讯，采用 Servlet 暴露服务，Dubbo 内嵌 Jetty 作为服务器时默认实现，提供与 Hession 服务互操作。多个短连接，同步 HTTP 传输，Hessian 序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件； memcache：基于 memcached 实现的 RPC 协议 redis：基于 redis 实现的 RPC 协议 17、Dubbo 集群的负载均衡有哪些策略 Dubbo 提供了常见的集群策略实现，并预扩展点予以自行实现。 Random LoadBalance：随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀； RoundRobin LoadBalance：轮循选取提供者策略，平均分布，但是存在请求累积的问题； LeastActive LoadBalance:：最少活跃调用策略，解决慢提供者接收更少的请求； ConstantHash LoadBalance:：一致性 Hash 策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动； 18. 服务调用超时问题怎么解决dubbo在调用服务不成功时，默认是会重试两次的。这样在服务端的处理时间超过了设定的超时时间时，就会有重复请求，比如在发邮件时，可能就会发出多份重复邮件，执行注册请求时，就会插入多条重复的注册数据，那么怎么解决超时问题呢？如下 对于核心的服务中心，去除dubbo超时重试机制，并重新评估设置超时时间。业务处理代码必须放在服务端，客户端只做参数验证和服务调用，不涉及业务流程处理 全局配置实例 1&lt;dubbo:provider delay=\"-1\" timeout=\"6000\" retries=\"0\"/&gt; 当然Dubbo的重试机制其实是非常好的QOS保证，它的路由机制，是会帮你把超时的请求路由到其他机器上，而不是本机尝试，所以 dubbo的重试机器也能一定程度的保证服务的质量。但是请一定要综合线上的访问情况，给出综合的评估。","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://kanchai.club/tags/Dubbo/"}]},{"title":"Mysql去重sql","slug":"Mysql去重sql","date":"2020-04-21T05:37:24.474Z","updated":"2020-04-21T02:18:30.000Z","comments":true,"path":"2020/04/21/Mysql去重sql/","link":"","permalink":"https://kanchai.club/2020/04/21/Mysql%E5%8E%BB%E9%87%8Dsql/","excerpt":"","text":"替换变量table_name 和 group_by 1234567891011121314151617DELETEFROM $&#123;table_name&#125;WHERE ID NOT IN ( SELECT * FROM ( SELECT Max(ID) FROM $&#123;table_name&#125; GROUP BY $&#123;group_by&#125; bb ))","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://kanchai.club/tags/mysql/"}]},{"title":"OpenResty下载与安装(Linux&Windos)","slug":"OpenResty下载与安装(Linux&Windos)","date":"2020-04-21T01:13:42.651Z","updated":"2020-04-21T01:13:19.000Z","comments":true,"path":"2020/04/21/OpenResty下载与安装(Linux&Windos)/","link":"","permalink":"https://kanchai.club/2020/04/21/OpenResty%E4%B8%8B%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85(Linux&Windos)/","excerpt":"","text":"OpenResty下载与安装前言版本说明123OpenResty&#x3D;1.15.8.2 linux.centos&#x3D;7windows&#x3D;10 相关链接 OpenResty 官网:http://openresty.org/cn/ OpenResty 下载及安装说明地址：http://openresty.org/cn/download.html Win 10 安装解压即安装，双击 nginx.exe 即运行； 或者进入安装目录，执行 start nginx.exe 即运行； Linux Tar 安装官方源码安装指南：http://openresty.org/cn/installation.html 安装依赖环境1yum install pcre-devel openssl-devel gcc curl 配置123# .&#x2F;configure 默认 --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;openresty# .&#x2F;configure --help 查看更多的选项。.&#x2F;configure 编译与安装1234# 编译make # 安装make install 运行1234# 方式一：进入 openresty安装目录&#x2F;bin 目录，执行.&#x2F;openresty# 方式二：进入 openresty安装目录&#x2F;nginx&#x2F;sbin 目录，执行.&#x2F;nginx Linux Yum 安装添加 OpenResty 仓库12sudo yum install -y yum-utilssudo yum-config-manager --add-repo https:&#x2F;&#x2F;openresty.org&#x2F;package&#x2F;centos&#x2F;openresty.repo 下载与安装1234# 下载与安装sudo yum install -y openresty# 更新sudo yum check-update 注：默认安装目录：/usr/local/openresty 运行1234# 方式一：进入 openresty安装目录&#x2F;bin 目录，执行.&#x2F;openresty# 方式二：进入 openresty安装目录&#x2F;&#x2F;nginx&#x2F;sbin 目录，执行.&#x2F;nginx 安装 OpenResty 命令工具1sudo yum install -y openresty-resty 命令行工具 opm 在 openresty-opm 包里，而 restydoc 工具在 openresty-doc 包里头 附录-configure 选项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247root@localhost openresty-1.15.8.2]# .&#x2F;configure --help --help this message --prefix&#x3D;PATH set the installation prefix (default to &#x2F;usr&#x2F;local&#x2F;openresty) --with-debug enable debug logging --with-dtrace-probes enable dtrace USDT probes --with-dtrace&#x3D;PATH set dtrace utility pathname --with-no-pool-patch enable the no-pool patch for debugging memory issues -jN pass -jN option to make while building the bundled Lua 5.1 interpreter or LuaJIT 2.1 --without-http_echo_module disable ngx_http_echo_module --without-http_xss_module disable ngx_http_xss_module --without-http_coolkit_module disable ngx_http_coolkit_module --without-http_set_misc_module disable ngx_http_set_misc_module --without-http_form_input_module disable ngx_http_form_input_module --without-http_encrypted_session_module disable ngx_http_encrypted_session_module --without-http_srcache_module disable ngx_http_srcache_module --without-http_lua_module disable ngx_http_lua_module --without-http_lua_upstream_module disable ngx_http_lua_upstream_module --without-http_headers_more_module disable ngx_http_headers_more_module --without-http_array_var_module disable ngx_http_array_var_module --without-http_memc_module disable ngx_http_memc_module --without-http_redis2_module disable ngx_http_redis2_module --without-http_redis_module disable ngx_http_redis_module --without-http_rds_json_module disable ngx_http_rds_json_module --without-http_rds_csv_module disable ngx_http_rds_csv_module --without-stream_lua_module disable ngx_stream_lua_module --without-ngx_devel_kit_module disable ngx_devel_kit_module --without-http_ssl_module disable ngx_http_ssl_module --without-stream_ssl_module disable ngx_stream_ssl_module --with-http_iconv_module enable ngx_http_iconv_module --with-http_drizzle_module enable ngx_http_drizzle_module --with-http_postgres_module enable ngx_http_postgres_module --without-lua_cjson disable the lua-cjson library --without-lua_tablepool disable the lua-tablepool library (and by consequence, the lua-resty-shell library) --without-lua_redis_parser disable the lua-redis-parser library --without-lua_rds_parser disable the lua-rds-parser library --without-lua_resty_dns disable the lua-resty-dns library --without-lua_resty_memcached disable the lua-resty-memcached library --without-lua_resty_redis disable the lua-resty-redis library --without-lua_resty_mysql disable the lua-resty-mysql library --without-lua_resty_upload disable the lua-resty-upload library --without-lua_resty_upstream_healthcheck disable the lua-resty-upstream-healthcheck library --without-lua_resty_string disable the lua-resty-string library --without-lua_resty_websocket disable the lua-resty-websocket library --without-lua_resty_limit_traffic disable the lua-resty-limit-traffic library --without-lua_resty_lock disable the lua-resty-lock library --without-lua_resty_lrucache disable the lua-resty-lrucache library --without-lua_resty_signal disable the lua-resty-signal library (and by consequence, the lua-resty-shell library) --without-lua_resty_shell disable the lua-resty-shell library --without-lua_resty_core disable the lua-resty-core library --with-luajit enable and build the bundled LuaJIT 2.1 (the default) --with-luajit&#x3D;DIR use the external LuaJIT 2.1 installation specified by DIR --with-luajit-xcflags&#x3D;FLAGS Specify extra C compiler flags for LuaJIT 2.1 --without-luajit-lua52 Turns off the LuaJIT extensions from Lua 5.2 that may break backward compatibility. --without-luajit-gc64 Turns off the LuaJIT GC64 mode (which is enabled by default on x86_64) --with-libdrizzle&#x3D;DIR specify the libdrizzle 1.0 (or drizzle) installation prefix --with-libpq&#x3D;DIR specify the libpq (or postgresql) installation prefix --with-pg_config&#x3D;PATH specify the path of the pg_config utilityOptions directly inherited from nginx --sbin-path&#x3D;PATH set nginx binary pathname --modules-path&#x3D;PATH set modules path --conf-path&#x3D;PATH set nginx.conf pathname --error-log-path&#x3D;PATH set error log pathname --pid-path&#x3D;PATH set nginx.pid pathname --lock-path&#x3D;PATH set nginx.lock pathname --tapset-prefix&#x3D;PATH set systemtap tapset directory prefix --stap-nginx-path&#x3D;PATH set stap-nginx pathname --user&#x3D;USER set non-privileged user for worker processes --group&#x3D;GROUP set non-privileged group for worker processes --build&#x3D;NAME set build name --builddir&#x3D;DIR set the build directory --with-select_module enable select module --without-select_module disable select module --with-poll_module enable poll module --without-poll_module disable poll module --with-threads enable thread pool support --with-file-aio enable file AIO support --with-ipv6 enable IPv6 support --with-http_v2_module enable ngx_http_v2_module --with-http_realip_module enable ngx_http_realip_module --with-http_addition_module enable ngx_http_addition_module --with-http_xslt_module enable ngx_http_xslt_module --with-http_xslt_module&#x3D;dynamic enable dynamic ngx_http_xslt_module --with-http_image_filter_module enable ngx_http_image_filter_module --with-http_image_filter_module&#x3D;dynamic enable dynamic ngx_http_image_filter_module --with-http_geoip_module enable ngx_http_geoip_module --with-http_geoip_module&#x3D;dynamic enable dynamic ngx_http_geoip_module --with-http_sub_module enable ngx_http_sub_module --with-http_dav_module enable ngx_http_dav_module --with-http_flv_module enable ngx_http_flv_module --with-http_mp4_module enable ngx_http_mp4_module --with-http_gunzip_module enable ngx_http_gunzip_module --with-http_gzip_static_module enable ngx_http_gzip_static_module --with-http_auth_request_module enable ngx_http_auth_request_module --with-http_random_index_module enable ngx_http_random_index_module --with-http_secure_link_module enable ngx_http_secure_link_module --with-http_degradation_module enable ngx_http_degradation_module --with-http_slice_module enable ngx_http_slice_module --with-http_stub_status_module enable ngx_http_stub_status_module --without-http_charset_module disable ngx_http_charset_module --without-http_gzip_module disable ngx_http_gzip_module --without-http_ssi_module disable ngx_http_ssi_module --without-http_userid_module disable ngx_http_userid_module --without-http_access_module disable ngx_http_access_module --without-http_auth_basic_module disable ngx_http_auth_basic_module --without-http_autoindex_module disable ngx_http_autoindex_module --without-http_geo_module disable ngx_http_geo_module --without-http_map_module disable ngx_http_map_module --without-http_split_clients_module disable ngx_http_split_clients_module --without-http_referer_module disable ngx_http_referer_module --without-http_rewrite_module disable ngx_http_rewrite_module --without-http_proxy_module disable ngx_http_proxy_module --without-http_fastcgi_module disable ngx_http_fastcgi_module --without-http_uwsgi_module disable ngx_http_uwsgi_module --without-http_scgi_module disable ngx_http_scgi_module --without-http_memcached_module disable ngx_http_memcached_module --without-http_limit_conn_module disable ngx_http_limit_conn_module --without-http_limit_req_module disable ngx_http_limit_req_module --without-http_empty_gif_module disable ngx_http_empty_gif_module --without-http_browser_module disable ngx_http_browser_module --without-http_upstream_hash_module disable ngx_http_upstream_hash_module --without-http_upstream_ip_hash_module disable ngx_http_upstream_ip_hash_module --without-http_upstream_least_conn_module disable ngx_http_upstream_least_conn_module --without-http_upstream_keepalive_module disable ngx_http_upstream_keepalive_module --without-http_upstream_zone_module disable ngx_http_upstream_zone_module --with-http_perl_module enable ngx_http_perl_module --with-http_perl_module&#x3D;dynamic enable dynamic ngx_http_perl_module --with-perl_modules_path&#x3D;PATH set Perl modules path --with-perl&#x3D;PATH set perl binary pathname --http-log-path&#x3D;PATH set http access log pathname --http-client-body-temp-path&#x3D;PATH set path to store http client request body temporary files --http-proxy-temp-path&#x3D;PATH set path to store http proxy temporary files --http-fastcgi-temp-path&#x3D;PATH set path to store http fastcgi temporary files --http-uwsgi-temp-path&#x3D;PATH set path to store http uwsgi temporary files --http-scgi-temp-path&#x3D;PATH set path to store http scgi temporary files --without-http disable HTTP server --without-http-cache disable HTTP cache --with-mail enable POP3&#x2F;IMAP4&#x2F;SMTP proxy module --with-mail&#x3D;dynamic enable dynamic POP3&#x2F;IMAP4&#x2F;SMTP proxy module --with-mail_ssl_module enable ngx_mail_ssl_module --without-mail_pop3_module disable ngx_mail_pop3_module --without-mail_imap_module disable ngx_mail_imap_module --without-mail_smtp_module disable ngx_mail_smtp_module --without-stream disable TCP&#x2F;UDP proxy module --without-stream_ssl_module disable ngx_stream_ssl_module --with-stream enable TCP&#x2F;UDP proxy module (default on) --with-stream&#x3D;dynamic enable dynamic TCP&#x2F;UDP proxy module --with-stream_ssl_module enable ngx_stream_ssl_module (default on) --with-stream_realip_module enable ngx_stream_realip_module --with-stream_geoip_module enable ngx_stream_geoip_module --with-stream_geoip_module&#x3D;dynamic enable dynamic ngx_stream_geoip_module --with-stream_ssl_preread_module enable ngx_stream_ssl_preread_module --without-stream_limit_conn_module disable ngx_stream_limit_conn_module --without-stream_access_module disable ngx_stream_access_module --without-stream_geo_module disable ngx_stream_geo_module --without-stream_map_module disable ngx_stream_map_module --without-stream_split_clients_module disable ngx_stream_split_clients_module --without-stream_return_module disable ngx_stream_return_module --without-stream_upstream_hash_module disable ngx_stream_upstream_hash_module --without-stream_upstream_least_conn_module disable ngx_stream_upstream_least_conn_module --without-stream_upstream_zone_module disable ngx_stream_upstream_zone_module --with-google_perftools_module enable ngx_google_perftools_module --with-cpp_test_module enable ngx_cpp_test_module --add-module&#x3D;PATH enable external module --add-dynamic-module&#x3D;PATH enable dynamic external module --with-cc&#x3D;PATH set C compiler pathname --with-cpp&#x3D;PATH set C preprocessor pathname --with-cc-opt&#x3D;OPTIONS set additional C compiler options --with-ld-opt&#x3D;OPTIONS set additional linker options --with-cpu-opt&#x3D;CPU build for the specified CPU, valid values: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --without-pcre disable PCRE library usage --with-pcre force PCRE library usage --with-pcre&#x3D;DIR set path to PCRE library sources --with-pcre-opt&#x3D;OPTIONS set additional make options for PCRE --with-pcre-conf-opt&#x3D;OPTIONS set additional configure options for PCRE --with-pcre-jit build PCRE with JIT compilation support --with-zlib&#x3D;DIR set path to zlib library sources --with-zlib-opt&#x3D;OPTIONS set additional build options for zlib --with-zlib-asm&#x3D;CPU use zlib assembler sources optimized for the specified CPU, valid values: pentium, pentiumpro --with-libatomic force libatomic_ops library usage --with-libatomic&#x3D;DIR set path to libatomic_ops library sources --with-openssl&#x3D;DIR set path to OpenSSL library sources --with-openssl-opt&#x3D;OPTIONS set additional build options for OpenSSL --dry-run dry running the configure, for testing only --platform&#x3D;PLATFORM forcibly specify a platform name, for testing only————————————————版权声明：本文为CSDN博主「SIMBA1949」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;simba1949&#x2F;java&#x2F;article&#x2F;details&#x2F;103333599","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://kanchai.club/tags/nginx/"},{"name":"devops","slug":"devops","permalink":"https://kanchai.club/tags/devops/"}]},{"title":"synchronized与Lock的区别与使用？","slug":"synchronized与Lock的区别与使用","date":"2020-04-21T01:04:22.356Z","updated":"2020-04-21T01:03:42.000Z","comments":true,"path":"2020/04/21/synchronized与Lock的区别与使用/","link":"","permalink":"https://kanchai.club/2020/04/21/synchronized%E4%B8%8ELock%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E4%BD%BF%E7%94%A8/","excerpt":"","text":"引言：昨天在学习别人分享的面试经验时，看到Lock的使用。想起自己在上次面试也遇到了synchronized与Lock的区别与使用。 于是，我整理了两者的区别和使用情况，同时，对synchronized的使用过程一些常见问题的总结，最后是参照源码和说明文档，对Lock的使用写了几个简单的Demo。请大家批评指正。 技术点：1、线程与进程：在开始之前先把进程与线程进行区分一下，一个程序最少需要一个进程，而一个进程最少需要一个线程。关系是线程–&gt;进程–&gt;程序的大致组成结构。所以线程是程序执行流的最小单位，而进程是系统进行资源分配和调度的一个独立单位。以下我们所有讨论的都是建立在线程基础之上。 2、Thread的几个重要方法：我们先了解一下Thread的几个重要方法。 start()方法，调用该方法开始执行该线程； stop()方法，调用该方法强制结束该线程执行； join方法，调用该方法等待该线程结束。 sleep()方法，调用该方法该线程进入等待。 run()方法，调用该方法直接执行线程的run()方法，但是线程调用start()方法时也会运行run()方法，区别就是一个是由线程调度运行run()方法，一个是直接调用了线程中的run()方法！！ 看到这里，可能有些人就会问啦，那wait()和notify()呢？要注意，其实wait()与notify()方法是Object的方法，不是Thread的方法！！同时，wait()与notify()会配合使用，分别表示线程挂起和线程恢复。 这里还有一个很常见的问题，顺带提一下：wait()与sleep()的区别，简单来说wait()会释放对象锁而sleep()不会释放对象锁。这些问题有很多的资料，不再赘述。 3、线程状态： 线程总共有5大状态，通过上面第二个知识点的介绍，理解起来就简单了。 新建状态：新建线程对象，并没有调用start()方法之前 就绪状态：调用start()方法之后线程就进入就绪状态，但是并不是说只要调用start()方法线程就马上变为当前线程，在变为当前线程之前都是为就绪状态。值得一提的是，线程在睡眠和挂起中恢复的时候也会进入就绪状态哦。 运行状态：线程被设置为当前线程，开始执行run()方法。就是线程进入运行状态 阻塞状态：线程被暂停，比如说调用sleep()方法后线程就进入阻塞状态 死亡状态：线程执行结束 4、锁类型 可重入锁：在执行对象中所有同步方法不用再次获得锁 可中断锁：在等待获取锁过程中可中断 公平锁：按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利 读写锁：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写 synchronized与Lock的区别1、我把两者的区别分类到了一个表中，方便大家对比： 或许，看到这里还对LOCK所知甚少，那么接下来，我们进入LOCK的深入学习。 Lock详细介绍与Demo以下是Lock接口的源码，笔者修剪之后的结果： 123456789101112131415161718192021222324252627282930public interface Lock &#123; /** * Acquires the lock. */ void lock(); /** * Acquires the lock unless the current thread is * &#123;@linkplain Thread#interrupt interrupted&#125;. */ void lockInterruptibly() throws InterruptedException; /** * Acquires the lock only if it is free at the time of invocation. */ boolean tryLock(); /** * Acquires the lock if it is free within the given waiting time and the * current thread has not been &#123;@linkplain Thread#interrupt interrupted&#125;. */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; /** * Releases the lock. */ void unlock();&#125; 从Lock接口中我们可以看到主要有个方法，这些方法的功能从注释中可以看出： lock()：获取锁，如果锁被暂用则一直等待 unlock()：释放锁 tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间 lockInterruptibly()：用该锁的获得方式，如果线程在获取锁的阶段进入了等待，那么可以中断此线程，先去做别的事 通过 以上的解释，大致可以解释在上个部分中“锁类型(lockInterruptibly())”，“锁状态(tryLock())”等问题，还有就是前面子所获取的过程我所写的“大致就是可以尝试获得锁，线程可以不会一直等待”用了“可以”的原因。 下面是Lock一般使用的例子，注意ReentrantLock是Lock接口的实现。 lock()：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.brickworkers;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class LockTest &#123; private Lock lock = new ReentrantLock(); //需要参与同步的方法 private void method(Thread thread)&#123; lock.lock(); try &#123; System.out.println(\"线程名\"+thread.getName() + \"获得了锁\"); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"线程名\"+thread.getName() + \"释放了锁\"); lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; LockTest lockTest = new LockTest(); //线程1 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; lockTest.method(Thread.currentThread()); &#125; &#125;, \"t1\"); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; lockTest.method(Thread.currentThread()); &#125; &#125;, \"t2\"); t1.start(); t2.start(); &#125;&#125;//执行情况：线程名t1获得了锁// 线程名t1释放了锁// 线程名t2获得了锁// 线程名t2释放了锁 tryLock():123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.brickworkers;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class LockTest &#123; private Lock lock = new ReentrantLock(); //需要参与同步的方法 private void method(Thread thread)&#123;/* lock.lock(); try &#123; System.out.println(\"线程名\"+thread.getName() + \"获得了锁\"); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"线程名\"+thread.getName() + \"释放了锁\"); lock.unlock(); &#125;*/ if(lock.tryLock())&#123; try &#123; System.out.println(\"线程名\"+thread.getName() + \"获得了锁\"); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"线程名\"+thread.getName() + \"释放了锁\"); lock.unlock(); &#125; &#125;else&#123; System.out.println(\"我是\"+Thread.currentThread().getName()+\"有人占着锁，我就不要啦\"); &#125; &#125; public static void main(String[] args) &#123; LockTest lockTest = new LockTest(); //线程1 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; lockTest.method(Thread.currentThread()); &#125; &#125;, \"t1\"); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; lockTest.method(Thread.currentThread()); &#125; &#125;, \"t2\"); t1.start(); t2.start(); &#125;&#125;//执行结果： 线程名t2获得了锁// 我是t1有人占着锁，我就不要啦// 线程名t2释放了锁 看到这里相信大家也都会使用如何使用Lock了吧，关于tryLock(long time, TimeUnit unit)和lockInterruptibly()不再赘述。前者主要存在一个等待时间，在测试代码中写入一个等待时间，后者主要是等待中断，会抛出一个中断异常，常用度不高，喜欢探究可以自己深入研究。 前面比较重提到“公平锁”，在这里可以提一下ReentrantLock对于平衡锁的定义，在源码中有这么两段： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Sync object for non-fair locks */ static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; /** * Sync object for fair locks */ static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; &#125; 从以上源码可以看出在Lock中可以自己控制锁是否公平，而且，默认的是非公平锁，以下是ReentrantLock的构造函数： 123public ReentrantLock() &#123; sync = new NonfairSync();//默认非公平锁 &#125; 尾记录：笔者水平一般，不过此博客在引言中的目的已全部达到。这只是笔者在学习过程中的总结与概括，如存在不正确的，欢迎大家批评指出。 补充1、两种锁的底层实现方式：synchronized：我们知道java是用字节码指令来控制程序（这里不包括热点代码编译成机器码）。在字节指令中，存在有synchronized所包含的代码块，那么会形成2段流程的执行。 我们点击查看SyncDemo.java的源码SyncDemo.class，可以看到如下： 如上就是这段代码段字节码指令，没你想的那么难吧。言归正传，我们可以清晰段看到，其实synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当一条线程进行执行的遇到monitorenter指令的时候，它会去尝试获得锁，如果获得锁那么锁计数+1（为什么会加一呢，因为它是一个可重入锁，所以需要用这个锁计数判断锁的情况），如果没有获得锁，那么阻塞。当它遇到monitorexit的时候，锁计数器-1，当计数器为0，那么就释放锁。 那么有的朋友看到这里就疑惑了，那图上有2个monitorexit呀？马上回答这个问题：上面我以前写的文章也有表述过，synchronized锁释放有两种机制，一种就是执行完释放；另外一种就是发送异常，虚拟机释放。图中第二个monitorexit就是发生异常时执行的流程，这就是我开头说的“会有2个流程存在“。而且，从图中我们也可以看到在第13行，有一个goto指令，也就是说如果正常运行结束会跳转到19行执行。 这下，你对synchronized是不是了解的很清晰了呢。接下来我们再聊一聊Lock。 Lock：Lock实现和synchronized不一样，后者是一种悲观锁，它胆子很小，它很怕有人和它抢吃的，所以它每次吃东西前都把自己关起来。而Lock呢底层其实是CAS乐观锁的体现，它无所谓，别人抢了它吃的，它重新去拿吃的就好啦，所以它很乐观。具体底层怎么实现，博主不在细述，有机会的话，我会对concurrent包下面的机制好好和大家说说，如果面试问起，你就说底层主要靠volatile和CAS操作实现的。 现在，才是我真正想在这篇博文后面加的，我要说的是：尽可能去使用synchronized而不要去使用LOCK 什么概念呢？我和大家打个比方：你叫jdk，你生了一个孩子叫synchronized，后来呢，你领养了一个孩子叫LOCK。起初，LOCK刚来到新家的时候，它很乖，很懂事，各个方面都表现的比synchronized好。你很开心，但是你内心深处又有一点淡淡的忧伤，你不希望你自己亲生的孩子竟然还不如一个领养的孩子乖巧。这个时候，你对亲生的孩子教育更加深刻了，你想证明，你的亲生孩子synchronized并不会比领养的孩子LOCK差。（博主只是打个比方） 那如何教育呢？在jdk1.6~jdk1.7的时候，也就是synchronized16、7岁的时候，你作为爸爸，你给他优化了，具体优化在哪里呢： 1、线程自旋和适应性自旋我们知道，java’线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。 而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。 2、锁消除什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。 那么有的小伙伴又迷糊了，我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？ 并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除，我打一个比方： 在jdk1.5以前，我们的String字符串拼接操作其实底层是StringBuffer来实现的（这个大家可以用我前面介绍的方法，写一个简单的demo，然后查看class文件中的字节码指令就清楚了），而在jdk1.5之后，那么是用StringBuilder来拼接的。我们考虑前面的情况，比如如下代码： 123String str1=\"qwe\";String str2=\"asd\";String str3=str1+str2; 底层实现会变成这样： 123StringBuffer sb = new StringBuffer();sb.append(\"qwe\");sb.append(\"asd\"); 我们知道，StringBuffer是一个线程安全的类，也就是说两个append方法都会同步，通过指针逃逸分析（就是变量不会外泄），我们发现在这段代码并不存在线程安全问题，这个时候就会把这个同步锁消除。 3、锁粗化在用synchronized的时候，我们都讲究为了避免大开销，尽量同步代码块要小。那么为什么还要加粗呢？ 我们继续以上面的字符串拼接为例，我们知道在这一段代码中，每一个append都需要同步一次，那么我可以把锁粗化到第一个append和最后一个append（这里不要去纠结前面的锁消除，我只是打个比方） 4、轻量级锁5、偏向锁关于最后这两种，我希望留个有缘的读者自己去查找，我不希望我把一件事情描述的那么详细，自己动手得到才是你自己的，博主可以告诉你的是，最后两种并不难。。加油吧，各位。 来源：https://blog.csdn.net/u012403290/","categories":[],"tags":[{"name":"JAVA并发","slug":"JAVA并发","permalink":"https://kanchai.club/tags/JAVA%E5%B9%B6%E5%8F%91/"}]},{"title":"API接口设计该如何设计？如何保证安全？","slug":"API接口设计该如何设计？如何保证安全？","date":"2020-04-20T10:01:29.424Z","updated":"2020-04-20T10:00:52.000Z","comments":true,"path":"2020/04/20/API接口设计该如何设计？如何保证安全？/","link":"","permalink":"https://kanchai.club/2020/04/20/API%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E8%AF%A5%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%EF%BC%9F%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%AE%89%E5%85%A8%EF%BC%9F/","excerpt":"","text":"在实际的业务中，难免会跟第三方系统进行数据的交互与传递，那么如何保证数据在传输过程中的安全呢（防窃取）？除了https的协议之外，能不能加上通用的一套算法以及规范来保证传输的安全性呢？ 下面我们就来讨论下常用的一些API设计的安全方法，可能不一定是最好的，有更牛逼的实现方式，但是这篇是我自己的经验分享.一、token 简介Token：访问令牌access token, 用于接口中, 用于标识接口调用者的身份、凭证，减少用户名和密码的传输次数。一般情况下客户端(接口调用方)需要先向服务器端申请一个接口调用的账号，服务器会给出一个appId和一个key, key用于参数签名使用，注意key保存到客户端，需要做一些安全处理，防止泄露。Token的值一般是UUID，服务端生成Token后需要将token做为key，将一些和token关联的信息作为value保存到缓存服务器中(redis)，当一个请求过来后，服务器就去缓存服务器中查询这个Token是否存在，存在则调用接口，不存在返回接口错误，一般通过拦截器或者过滤器来实现，Token分为两种： API Token(接口令牌): 用于访问不需要用户登录的接口，如登录、注册、一些基本数据的获取等。获取接口令牌需要拿appId、timestamp和sign来换，sign=加密(timestamp+key) USER Token(用户令牌): 用于访问需要用户登录之后的接口，如：获取我的基本信息、保存、修改、删除等操作。获取用户令牌需要拿用户名和密码来换 关于Token的时效性：token可以是一次性的、也可以在一段时间范围内是有效的，具体使用哪种看业务需要。一般情况下接口最好使用https协议，如果使用http协议，Token机制只是一种减少被黑的可能性，其实只能防君子不能防小人。一般token、timestamp和sign 三个参数会在接口中会同时作为参数传递，每个参数都有各自的用途。 二、timestamp 简介timestamp: 时间戳，是客户端调用接口时对应的当前时间戳，时间戳用于防止DoS攻击。当黑客劫持了请求的url去DoS攻击，每次调用接口时接口都会判断服务器当前系统时间和接口中传的的timestamp的差值，如果这个差值超过某个设置的时间(假如5分钟)，那么这个请求将被拦截掉，如果在设置的超时时间范围内，是不能阻止DoS攻击的。timestamp机制只能减轻DoS攻击的时间，缩短攻击时间。如果黑客修改了时间戳的值可通过sign签名机制来处理。DoSDoS是Denial of Service的简称，即拒绝服务，造成DoS的攻击行为被称为DoS攻击，其目的是使计算机或网络无法提供正常的服务。最常见的DoS攻击有计算机网络带宽攻击和连通性攻击。DoS攻击是指故意的攻击网络协议实现的缺陷或直接通过野蛮手段残忍地耗尽被攻击对象的资源，目的是让目标计算机或网络无法提供正常的服务或资源访问，使目标系统服务系统停止响应甚至崩溃，而在此攻击中并不包括侵入目标服务器或目标网络设备。这些服务资源包括网络带宽，文件系统空间容量，开放的进程或者允许的连接。这种攻击会导致资源的匮乏，无论计算机的处理速度多快、内存容量多大、网络带宽的速度多快都无法避免这种攻击带来的后果。 Pingflood: 该攻击在短时间内向目的主机发送大量ping包，造成网络堵塞或主机资源耗尽。 Synflood: 该攻击以多个随机的源主机地址向目的主机发送SYN包，而在收到目的主机的SYN ACK后并不回应，这样，目的主机就为这些源主机建立了大量的连接队列，而且由于没有收到ACK一直维护着这些队列，造成了资源的大量消耗而不能向正常请求提供服务。 Smurf：该攻击向一个子网的广播地址发一个带有特定请求（如ICMP回应请求）的包，并且将源地址伪装成想要攻击的主机地址。子网上所有主机都回应广播包请求而向被攻击主机发包，使该主机受到攻击。 Land-based：攻击者将一个包的源地址和目的地址都设置为目标主机的地址，然后将该包通过IP欺骗的方式发送给被攻击主机，这种包可以造成被攻击主机因试图与自己建立连接而陷入死循环，从而很大程度地降低了系统性能。 Ping of Death：根据TCP/IP的规范，一个包的长度最大为65536字节。尽管一个包的长度不能超过65536字节，但是一个包分成的多个片段的叠加却能做到。当一个主机收到了长度大于65536字节的包时，就是受到了Ping of Death攻击，该攻击会造成主机的宕机。 Teardrop：IP数据包在网络传递时，数据包可以分成更小的片段。攻击者可以通过发送两段（或者更多）数据包来实现TearDrop攻击。第一个包的偏移量为0，长度为N，第二个包的偏移量小于N。为了合并这些数据段，TCP/IP堆栈会分配超乎寻常的巨大资源，从而造成系统资源的缺乏甚至机器的重新启动。 PingSweep：使用ICMP Echo轮询多个主机。 三、sign 简介nonce：随机值，是客户端随机生成的值，作为参数传递过来，随机值的目的是增加sign签名的多变性。随机值一般是数字和字母的组合，6位长度，随机值的组成和长度没有固定规则。sign: 一般用于参数签名，防止参数被非法篡改，最常见的是修改金额等重要敏感参数， sign的值一般是将所有非空参数按照升续排序然后+token+key+timestamp+nonce(随机数)拼接在一起，然后使用某种加密算法进行加密，作为接口中的一个参数sign来传递，也可以将sign放到请求头中。接口在网络传输过程中如果被黑客挟持，并修改其中的参数值，然后再继续调用接口，虽然参数的值被修改了，但是因为黑客不知道sign是如何计算出来的，不知道sign都有哪些值构成，不知道以怎样的顺序拼接在一起的，最重要的是不知道签名字符串中的key是什么，所以黑客可以篡改参数的值，但没法修改sign的值，当服务器调用接口前会按照sign的规则重新计算出sign的值然后和接口传递的sign参数的值做比较，如果相等表示参数值没有被篡改，如果不等，表示参数被非法篡改了，就不执行接口了。四、防止重复提交 对于一些重要的操作需要防止客户端重复提交的(如非幂等性重要操作)，具体办法是当请求第一次提交时将sign作为key保存到redis，并设置超时时间，超时时间和Timestamp中设置的差值相同。当同一个请求第二次访问时会先检测redis是否存在该sign，如果存在则证明重复提交了，接口就不再继续调用了。如果sign在缓存服务器中因过期时间到了，而被删除了，此时当这个url再次请求服务器时，因token的过期时间和sign的过期时间一直，sign过期也意味着token过期，那样同样的url再访问服务器会因token错误会被拦截掉，这就是为什么sign和token的过期时间要保持一致的原因。拒绝重复调用机制确保URL被别人截获了也无法使用（如抓取数据）。对于哪些接口需要防止重复提交可以自定义个注解来标记。注意：所有的安全措施都用上的话有时候难免太过复杂，在实际项目中需要根据自身情况作出裁剪，比如可以只使用签名机制就可以保证信息不会被篡改，或者定向提供服务的时候只用Token机制就可以了。如何裁剪，全看项目实际情况和对接口安全性的要求。五、使用流程1.接口调用方(客户端)向接口提供方(服务器)申请接口调用账号，申请成功后，接口提供方会给接口调用方一个appId和一个key参数2.客户端携带参数appId、timestamp、sign去调用服务器端的API token，其中sign=加密(appId + timestamp + key)3.客户端拿着api_token 去访问不需要登录就能访问的接口4.当访问用户需要登录的接口时，客户端跳转到登录页面，通过用户名和密码调用登录接口，登录接口会返回一个usertoken, 客户端拿着usertoken 去访问需要登录才能访问的接口sign的作用是防止参数被篡改，客户端调用服务端时需要传递sign参数，服务器响应客户端时也可以返回一个sign用于客户度校验返回的值是否被非法篡改了。客户端传的sign和服务器端响应的sign算法可能会不同。 六、示例代码1. dependency 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 2. RedisConfiguration 123456789101112131415161718192021222324252627282930@Configurationpublic class RedisConfiguration &#123; @Bean public JedisConnectionFactory jedisConnectionFactory()&#123; return new JedisConnectionFactory(); &#125; /** * 支持存储对象 * @return */ @Bean public RedisTemplate&lt;String, String&gt; redisTemplate()&#123; RedisTemplate&lt;String, String&gt; redisTemplate = new StringRedisTemplate(); redisTemplate.setConnectionFactory(jedisConnectionFactory()); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125;&#125; 3. TokenController 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111@Slf4j@RestController@RequestMapping(\"/api/token\")public class TokenController &#123; @Autowired private RedisTemplate redisTemplate; /** * API Token * * @param sign * @return */ @PostMapping(\"/api_token\") public ApiResponse&lt;AccessToken&gt; apiToken(String appId, @RequestHeader(\"timestamp\") String timestamp, @RequestHeader(\"sign\") String sign) &#123; Assert.isTrue(!StringUtils.isEmpty(appId) &amp;&amp; !StringUtils.isEmpty(timestamp) &amp;&amp; !StringUtils.isEmpty(sign), \"参数错误\"); long reqeustInterval = System.currentTimeMillis() - Long.valueOf(timestamp); Assert.isTrue(reqeustInterval &lt; 5 * 60 * 1000, \"请求过期，请重新请求\"); // 1. 根据appId查询数据库获取appSecret AppInfo appInfo = new AppInfo(\"1\", \"12345678954556\"); // 2. 校验签名 String signString = timestamp + appId + appInfo.getKey(); String signature = MD5Util.encode(signString); log.info(signature); Assert.isTrue(signature.equals(sign), \"签名错误\"); // 3. 如果正确生成一个token保存到redis中，如果错误返回错误信息 AccessToken accessToken = this.saveToken(0, appInfo, null); return ApiResponse.success(accessToken); &#125; @NotRepeatSubmit(5000) @PostMapping(\"user_token\") public ApiResponse&lt;UserInfo&gt; userToken(String username, String password) &#123; // 根据用户名查询密码, 并比较密码(密码可以RSA加密一下) UserInfo userInfo = new UserInfo(username, \"81255cb0dca1a5f304328a70ac85dcbd\", \"111111\"); String pwd = password + userInfo.getSalt(); String passwordMD5 = MD5Util.encode(pwd); Assert.isTrue(passwordMD5.equals(userInfo.getPassword()), \"密码错误\"); // 2. 保存Token AppInfo appInfo = new AppInfo(\"1\", \"12345678954556\"); AccessToken accessToken = this.saveToken(1, appInfo, userInfo); userInfo.setAccessToken(accessToken); return ApiResponse.success(userInfo); &#125; private AccessToken saveToken(int tokenType, AppInfo appInfo, UserInfo userInfo) &#123; String token = UUID.randomUUID().toString(); // token有效期为2小时 Calendar calendar = Calendar.getInstance(); calendar.setTime(new Date()); calendar.add(Calendar.SECOND, 7200); Date expireTime = calendar.getTime(); // 4. 保存token ValueOperations&lt;String, TokenInfo&gt; operations = redisTemplate.opsForValue(); TokenInfo tokenInfo = new TokenInfo(); tokenInfo.setTokenType(tokenType); tokenInfo.setAppInfo(appInfo); if (tokenType == 1) &#123; tokenInfo.setUserInfo(userInfo); &#125; operations.set(token, tokenInfo, 7200, TimeUnit.SECONDS); AccessToken accessToken = new AccessToken(token, expireTime); return accessToken; &#125; public static void main(String[] args) &#123; long timestamp = System.currentTimeMillis(); System.out.println(timestamp); String signString = timestamp + \"1\" + \"12345678954556\"; String sign = MD5Util.encode(signString); System.out.println(sign); System.out.println(\"-------------------\"); signString = \"password=123456&amp;username=1&amp;12345678954556\" + \"ff03e64b-427b-45a7-b78b-47d9e8597d3b1529815393153sdfsdfsfs\" + timestamp + \"A1scr6\"; sign = MD5Util.encode(signString); System.out.println(sign); &#125;&#125; 4. WebMvcConfiguration 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurationSupport &#123; private static final String[] excludePathPatterns = &#123;\"/api/token/api_token\"&#125;; @Autowired private TokenInterceptor tokenInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; super.addInterceptors(registry); registry.addInterceptor(tokenInterceptor) .addPathPatterns(\"/api/**\") .excludePathPatterns(excludePathPatterns); &#125;&#125;5. TokenInterceptor@Componentpublic class TokenInterceptor extends HandlerInterceptorAdapter &#123; @Autowired private RedisTemplate redisTemplate; /** * * @param request * @param response * @param handler 访问的目标方法 * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String token = request.getHeader(\"token\"); String timestamp = request.getHeader(\"timestamp\"); // 随机字符串 String nonce = request.getHeader(\"nonce\"); String sign = request.getHeader(\"sign\"); Assert.isTrue(!StringUtils.isEmpty(token) &amp;&amp; !StringUtils.isEmpty(timestamp) &amp;&amp; !StringUtils.isEmpty(sign), \"参数错误\"); // 获取超时时间 NotRepeatSubmit notRepeatSubmit = ApiUtil.getNotRepeatSubmit(handler); long expireTime = notRepeatSubmit == null ? 5 * 60 * 1000 : notRepeatSubmit.value(); // 2. 请求时间间隔 long reqeustInterval = System.currentTimeMillis() - Long.valueOf(timestamp); Assert.isTrue(reqeustInterval &lt; expireTime, \"请求超时，请重新请求\"); // 3. 校验Token是否存在 ValueOperations&lt;String, TokenInfo&gt; tokenRedis = redisTemplate.opsForValue(); TokenInfo tokenInfo = tokenRedis.get(token); Assert.notNull(tokenInfo, \"token错误\"); // 4. 校验签名(将所有的参数加进来，防止别人篡改参数) 所有参数看参数名升续排序拼接成url // 请求参数 + token + timestamp + nonce String signString = ApiUtil.concatSignString(request) + tokenInfo.getAppInfo().getKey() + token + timestamp + nonce; String signature = MD5Util.encode(signString); boolean flag = signature.equals(sign); Assert.isTrue(flag, \"签名错误\"); // 5. 拒绝重复调用(第一次访问时存储，过期时间和请求超时时间保持一致), 只有标注不允许重复提交注解的才会校验 if (notRepeatSubmit != null) &#123; ValueOperations&lt;String, Integer&gt; signRedis = redisTemplate.opsForValue(); boolean exists = redisTemplate.hasKey(sign); Assert.isTrue(!exists, \"请勿重复提交\"); signRedis.set(sign, 0, expireTime, TimeUnit.MILLISECONDS); &#125; return super.preHandle(request, response, handler); &#125;&#125; 6. MD5Util —-MD5工具类，加密生成数字签名 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class MD5Util &#123; private static final String hexDigits[] = &#123; \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\" &#125;; private static String byteArrayToHexString(byte b[]) &#123; StringBuffer resultSb = new StringBuffer(); for (int i = 0; i &lt; b.length; i++) resultSb.append(byteToHexString(b[i])); return resultSb.toString(); &#125; private static String byteToHexString(byte b) &#123; int n = b; if (n &lt; 0) n += 256; int d1 = n / 16; int d2 = n % 16; return hexDigits[d1] + hexDigits[d2]; &#125; public static String encode(String origin) &#123; return encode(origin, \"UTF-8\"); &#125; public static String encode(String origin, String charsetname) &#123; String resultString = null; try &#123; resultString = new String(origin); MessageDigest md = MessageDigest.getInstance(\"MD5\"); if (charsetname == null || \"\".equals(charsetname)) resultString = byteArrayToHexString(md.digest(resultString .getBytes())); else resultString = byteArrayToHexString(md.digest(resultString .getBytes(charsetname))); &#125; catch (Exception exception) &#123; &#125; return resultString; &#125;&#125; 7. @NotRepeatSubmit —–自定义注解，防止重复提交。 123456789/** * 禁止重复提交 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface NotRepeatSubmit &#123; /** 过期时间，单位毫秒 **/ long value() default 5000;&#125; 8. AccessToken 12345678910@Data@AllArgsConstructorpublic class AccessToken &#123; /** token */ private String token; /** 失效时间 */ private Date expireTime;&#125; 9. AppInfo 123456789@Data@NoArgsConstructor@AllArgsConstructorpublic class AppInfo &#123; /** App id */ private String appId; /** API 秘钥 */ private String key;&#125; 10. TokenInfo 12345678910111213@Datapublic class TokenInfo &#123; /** token类型: api:0 、user:1 */ private Integer tokenType; /** App 信息 */ private AppInfo appInfo; /** 用户其他数据 */ private UserInfo userInfo;&#125; 11. UserInfo 1234567891011121314151617181920212223@Datapublic class UserInfo &#123; /** 用户名 */ private String username; /** 手机号 */ private String mobile; /** 邮箱 */ private String email; /** 密码 */ private String password; /** 盐 */ private String salt; private AccessToken accessToken; public UserInfo(String username, String password, String salt) &#123; this.username = username; this.password = password; this.salt = salt; &#125;&#125; 12. ApiCodeEnum 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 错误码code可以使用纯数字,使用不同区间标识一类错误，也可以使用纯字符，也可以使用前缀+编号 * * 错误码：ERR + 编号 * * 可以使用日志级别的前缀作为错误类型区分 Info(I) Error(E) Warning(W) * * 或者以业务模块 + 错误号 * * TODO 错误码设计 * * Alipay 用了两个code，两个msg(https://docs.open.alipay.com/api_1/alipay.trade.pay) */public enum ApiCodeEnum &#123; SUCCESS(\"10000\", \"success\"), UNKNOW_ERROR(\"ERR0001\",\"未知错误\"), PARAMETER_ERROR(\"ERR0002\",\"参数错误\"), TOKEN_EXPIRE(\"ERR0003\",\"认证过期\"), REQUEST_TIMEOUT(\"ERR0004\",\"请求超时\"), SIGN_ERROR(\"ERR0005\",\"签名错误\"), REPEAT_SUBMIT(\"ERR0006\",\"请不要频繁操作\"), ; /** 代码 */ private String code; /** 结果 */ private String msg; ApiCodeEnum(String code, String msg) &#123; this.code = code; this.msg = msg; &#125; public String getCode() &#123; return code; &#125; public String getMsg() &#123; return msg; &#125;&#125; 13. ApiResult 12345678910111213@Data@NoArgsConstructor@AllArgsConstructorpublic class ApiResult &#123; /** 代码 */ private String code; /** 结果 */ private String msg;&#125; 14. ApiUtil ——-这个参考支付宝加密的算法写的.我直接Copy过来了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ApiUtil &#123; /** * 按参数名升续拼接参数 * @param request * @return */ public static String concatSignString(HttpServletRequest request) &#123; Map&lt;String, String&gt; paramterMap = new HashMap&lt;&gt;(); request.getParameterMap().forEach((key, value) -&gt; paramterMap.put(key, value[0])); // 按照key升续排序，然后拼接参数 Set&lt;String&gt; keySet = paramterMap.keySet(); String[] keyArray = keySet.toArray(new String[keySet.size()]); Arrays.sort(keyArray); StringBuilder sb = new StringBuilder(); for (String k : keyArray) &#123; // 或略掉的字段 if (k.equals(\"sign\")) &#123; continue; &#125; if (paramterMap.get(k).trim().length() &gt; 0) &#123; // 参数值为空，则不参与签名 sb.append(k).append(\"=\").append(paramterMap.get(k).trim()).append(\"&amp;\"); &#125; &#125; return sb.toString(); &#125; public static String concatSignString(Map&lt;String, String&gt; map) &#123; Map&lt;String, String&gt; paramterMap = new HashMap&lt;&gt;(); map.forEach((key, value) -&gt; paramterMap.put(key, value)); // 按照key升续排序，然后拼接参数 Set&lt;String&gt; keySet = paramterMap.keySet(); String[] keyArray = keySet.toArray(new String[keySet.size()]); Arrays.sort(keyArray); StringBuilder sb = new StringBuilder(); for (String k : keyArray) &#123; if (paramterMap.get(k).trim().length() &gt; 0) &#123; // 参数值为空，则不参与签名 sb.append(k).append(\"=\").append(paramterMap.get(k).trim()).append(\"&amp;\"); &#125; &#125; return sb.toString(); &#125; /** * 获取方法上的@NotRepeatSubmit注解 * @param handler * @return */ public static NotRepeatSubmit getNotRepeatSubmit(Object handler) &#123; if (handler instanceof HandlerMethod) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); NotRepeatSubmit annotation = method.getAnnotation(NotRepeatSubmit.class); return annotation; &#125; return null; &#125;&#125; 15. ApiResponse 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Data@Slf4jpublic class ApiResponse&lt;T&gt; &#123; /** 结果 */ private ApiResult result; /** 数据 */ private T data; /** 签名 */ private String sign; public static &lt;T&gt; ApiResponse success(T data) &#123; return response(ApiCodeEnum.SUCCESS.getCode(), ApiCodeEnum.SUCCESS.getMsg(), data); &#125; public static ApiResponse error(String code, String msg) &#123; return response(code, msg, null); &#125; public static &lt;T&gt; ApiResponse response(String code, String msg, T data) &#123; ApiResult result = new ApiResult(code, msg); ApiResponse response = new ApiResponse(); response.setResult(result); response.setData(data); String sign = signData(data); response.setSign(sign); return response; &#125; private static &lt;T&gt; String signData(T data) &#123; // TODO 查询key String key = \"12345678954556\"; Map&lt;String, String&gt; responseMap = null; try &#123; responseMap = getFields(data); &#125; catch (IllegalAccessException e) &#123; return null; &#125; String urlComponent = ApiUtil.concatSignString(responseMap); String signature = urlComponent + \"key=\" + key; String sign = MD5Util.encode(signature); return sign; &#125; /** * @param data 反射的对象,获取对象的字段名和值 * @throws IllegalArgumentException * @throws IllegalAccessException */ public static Map&lt;String, String&gt; getFields(Object data) throws IllegalAccessException, IllegalArgumentException &#123; if (data == null) return null; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); Field[] fields = data.getClass().getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; Field field = fields[i]; field.setAccessible(true); String name = field.getName(); Object value = field.get(data); if (field.get(data) != null) &#123; map.put(name, value.toString()); &#125; &#125; return map; &#125;&#125; 七、ThreadLocalThreadLocal是线程内的全局上下文。就是在单个线程中，方法之间共享的内存，每个方法都可以从该上下文中获取值和修改值。实际案例：在调用api时都会传一个token参数，通常会写一个拦截器来校验token是否合法，我们可以通过token找到对应的用户信息(User)，如果token合法，然后将用户信息存储到ThreadLocal中，这样无论是在controller、service、dao的哪一层都能访问到该用户的信息。作用类似于Web中的request作用域。传统方式我们要在方法中访问某个变量，可以通过传参的形式往方法中传参，如果多个方法都要使用那么每个方法都要传参；如果使用ThreadLocal所有方法就不需要传该参数了，每个方法都可以通过ThreadLocal来访问该值。 ThreadLocalUtil.set(“key”, value); 保存值 T value = ThreadLocalUtil.get(“key”); 获取值 ThreadLocalUtil 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class ThreadLocalUtil&lt;T&gt; &#123; private static final ThreadLocal&lt;Map&lt;String, Object&gt;&gt; threadLocal = new ThreadLocal() &#123; @Override protected Map&lt;String, Object&gt; initialValue() &#123; return new HashMap&lt;&gt;(4); &#125; &#125;; public static Map&lt;String, Object&gt; getThreadLocal()&#123; return threadLocal.get(); &#125; public static &lt;T&gt; T get(String key) &#123; Map map = (Map)threadLocal.get(); return (T)map.get(key); &#125; public static &lt;T&gt; T get(String key,T defaultValue) &#123; Map map = (Map)threadLocal.get(); return (T)map.get(key) == null ? defaultValue : (T)map.get(key); &#125; public static void set(String key, Object value) &#123; Map map = (Map)threadLocal.get(); map.put(key, value); &#125; public static void set(Map&lt;String, Object&gt; keyValueMap) &#123; Map map = (Map)threadLocal.get(); map.putAll(keyValueMap); &#125; public static void remove() &#123; threadLocal.remove(); &#125; public static &lt;T&gt; Map&lt;String,T&gt; fetchVarsByPrefix(String prefix) &#123; Map&lt;String,T&gt; vars = new HashMap&lt;&gt;(); if( prefix == null )&#123; return vars; &#125; Map map = (Map)threadLocal.get(); Set&lt;Map.Entry&gt; set = map.entrySet(); for( Map.Entry entry : set)&#123; Object key = entry.getKey(); if( key instanceof String )&#123; if( ((String) key).startsWith(prefix) )&#123; vars.put((String)key,(T)entry.getValue()); &#125; &#125; &#125; return vars; &#125; public static &lt;T&gt; T remove(String key) &#123; Map map = (Map)threadLocal.get(); return (T)map.remove(key); &#125; public static void clear(String prefix) &#123; if( prefix == null )&#123; return; &#125; Map map = (Map)threadLocal.get(); Set&lt;Map.Entry&gt; set = map.entrySet(); List&lt;String&gt; removeKeys = new ArrayList&lt;&gt;(); for( Map.Entry entry : set )&#123; Object key = entry.getKey(); if( key instanceof String )&#123; if( ((String) key).startsWith(prefix) )&#123; removeKeys.add((String)key); &#125; &#125; &#125; for( String key : removeKeys )&#123; map.remove(key); &#125; &#125;&#125; 总结:这个是目前第三方数据接口交互过程中常用的一些参数与使用示例，希望对大家有点帮助。当然如果为了保证更加的安全，可以加上RSA,RSA2，AES等等加密方式，保证了数据的更加的安全，但是唯一的缺点是加密与解密比较耗费CPU的资源。 来源：https://www.cnblogs.com/jurendage/p/12653865.html","categories":[],"tags":[{"name":"JAVA安全","slug":"JAVA安全","permalink":"https://kanchai.club/tags/JAVA%E5%AE%89%E5%85%A8/"}]},{"title":"谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案","slug":"谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案","date":"2020-04-20T02:42:53.764Z","updated":"2020-04-20T02:42:22.000Z","comments":true,"path":"2020/04/20/谈谈关于缓存穿透，缓存击穿，缓存雪崩，热点数据失效问题的解决方案/","link":"","permalink":"https://kanchai.club/2020/04/20/%E8%B0%88%E8%B0%88%E5%85%B3%E4%BA%8E%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%EF%BC%8C%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%EF%BC%8C%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%EF%BC%8C%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"","text":"作者：Tom-shushu cnblogs.com/Tom-shushu/p/10636382.html 1.我们使用缓存时的业务流程大概为： 当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能出现下面的一些现象。 2.缓存穿透2.1什么是缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 2.2缓存穿透带来的问题试想一下，如果有黑客对你的系统进行攻击，拿一个不存在的id去查询数据，会产生大量的请求到你的数据库去查询，可能会导致你的数据库由于压力过大而宕掉。 2.3解决的办法2.3.1缓存空值之所以会发生穿透，就是因为缓存中没有储存这些空数据的key。从而导致每次查询都到数据库去了。 那么我们就可以为这些key对应的值设置为null丢到缓存里面去。后面出现查询这个key的请求的时候直接返回null。 这样就不用再到数据库中去走一圈了，但是别忘了设置过期时间。 缓存空对象会有两个问题： 第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 ( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。 2.3.2用布隆过滤器BloomFilterBloomFilter类似于一个hbase set用来判断某个元素(key)是否存在于某个集合中。 这种方式在大数据场景应用比较多，比如Hbase中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url是否已经被爬取过。 这种方案可以加在第一种方案中，在缓存之前加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查缓存——–&gt;差数据库。 流程图如下： 2.4如何选择针对于一些恶意攻击，攻击带来大量key是不存在的，那么我们采用第一种方案就会缓存大量不存在的数据。此时我们采用第一种方案就不合适了，我们完全可以先使用第二种方案过滤掉这些key。 针对这些key异常多，请求多，重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。 而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。 3.缓存击穿3.1什么是缓存击穿缓存击穿是我们使用缓存可能遇到的第二个问题。 在平时高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去，这种现象我们称为缓存击穿。 3.2会带来什么问题会造成某一时刻数据请求量过大，压力剧增。 3.3如何解决上面现象是多个线程同时去查询数据库的这一条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。（如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）） 其他线程走到这一步拿不到锁就等着，等待第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有了缓存，就直接走缓存。 4.缓存雪崩4.1什么是缓存雪崩缓存雪崩的情况是指：当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到数据库上面，结果就是数据库挂掉。 4.2解决办法4.2.1雪崩前：使用集群缓存，保证缓存服务的高可用这种方案就是在发生雪崩前对缓存集群，实现高可用，如果是使用Redis，可以使用（主从 + 哨兵），Redis Cluster来避免Redis全盘崩溃的情况。 4.2.2雪崩中：ehcache本地缓存 + Hystrix限流 &amp; 降级，避免MySQl被打死使用ehcache本地缓存的目的也是考虑Redis Cluster完全不可用的时候，ehcache本地缓存还能够支撑一阵。 使用Hystrix进行限流 &amp; 降级，比如一秒来了5000个请求，我们可以设置假设一秒只能有2000个请求可以通过这个组件，那么其他剩余的3000请求就会走限流逻辑。 然后去调用我们自己开发的降级组件（降级）,比如设置的一些默认值等等之类的。以此来保护最后的MySQl不会被大量的请求打死。 4.2.3雪崩后：开启Redis持久化，尽快恢复缓存集群。5.解决热点数据集中失效问题我们在设置缓存的时候，一般会给缓存设置一个失效的时间，过了这个时间，缓存就失效了。 对于一些热点数据来说，当缓存失效后会存在大量的请求到数据库上来，从而可能导致数据库崩溃的情况。 5.1解决办法5.1.1设置不同的失效时间为了避免这些热点数据集体失效，那么我们在设置缓存过期时间的时侯，让他们失效的时间错开。比如我们可以在原有的失效时间基础上增加一个随机值。 5.1.2互斥锁结合上面的击穿情况，在第一个请求去查询数据库的时候对它加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。 但是也是由于它会阻塞其他线程，此时系统的吞吐量会下降。需要结合实际业务去考虑。","categories":[],"tags":[{"name":"JAVA缓存","slug":"JAVA缓存","permalink":"https://kanchai.club/tags/JAVA%E7%BC%93%E5%AD%98/"}]},{"title":"FFmpeg 视频处理教程！","slug":"FFmpeg_视频处理入门教程","date":"2020-04-01T03:55:50.809Z","updated":"2020-04-01T03:55:50.804Z","comments":true,"path":"2020/04/01/FFmpeg_视频处理入门教程/","link":"","permalink":"https://kanchai.club/2020/04/01/FFmpeg_%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2020年1月14日 FFmpeg 是视频处理最常用的开源软件。 它功能强大，用途广泛，大量用于视频网站和商业软件（比如 Youtube 和 iTunes），也是许多音频和视频格式的标准编码/解码实现。 FFmpeg 本身是一个庞大的项目，包含许多组件和库文件，最常用的是它的命令行工具。本文介绍 FFmpeg 命令行如何处理视频，比桌面视频处理软件更简洁高效。 如果你还没安装，可以根据官方文档 先完成安装。 一、概念介绍 FFmpeg 用法之前，需要了解一些视频处理的基本概念。 1.1 容器视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。 常见的容器格式有以下几种。一般来说，视频文件的后缀名反映了它的容器格式。 MP4 MKV WebM AVI 下面的命令查看 FFmpeg 支持的容器。 $ ffmpeg -formats 1.2 编码格式视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。 常用的视频编码格式如下。 H.262 H.264 H.265 上面的编码格式都是有版权的，但是可以免费使用。此外，还有几种无版权的视频编码格式。 VP8 VP9 AV1 常用的音频编码格式如下。 MP3 AAC 上面所有这些都是有损的编码格式，编码后会损失一些细节，以换取压缩后较小的文件体积。无损的编码格式压缩出来的文件体积较大，这里就不介绍了。 下面的命令可以查看 FFmpeg 支持的编码格式，视频编码和音频编码都在内。 $ ffmpeg -codecs 1.3 编码器编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。 以下是一些 FFmpeg 内置的视频编码器。 libx264：最流行的开源 H.264 编码器 NVENC：基于 NVIDIA GPU 的 H.264 编码器 libx265：开源的 HEVC 编码器 libvpx：谷歌的 VP8 和 VP9 编码器 libaom：AV1 编码器 音频编码器如下。 libfdk-aac aac 下面的命令可以查看 FFmpeg 已安装的编码器。 $ ffmpeg -encoders 二、FFmpeg 的使用格式FFmpeg 的命令行参数非常多，可以分成五个部分。 $ ffmpeg {1} {2} -i {3} {4} {5} 上面命令中，五个部分的参数依次如下。 全局参数 输入文件参数 输入文件 输出文件参数 输出文件 参数太多的时候，为了便于查看，ffmpeg 命令可以写成多行。 $ ffmpeg \\[全局参数] \\[输入文件参数] \\-i [输入文件] \\[输出文件参数] \\[输出文件] 下面是一个例子。 $ ffmpeg \\-y \\ # 全局参数-c:a libfdk_aac -c:v libx264 \\ # 输入文件参数-i input.mp4 \\ # 输入文件-c:v libvpx-vp9 -c:a libvorbis \\ # 输出文件参数output.webm # 输出文件 上面的命令将 mp4 文件转成 webm 文件，这两个都是容器格式。输入的 mp4 文件的音频编码格式是 aac，视频编码格式是 H.264；输出的 webm 文件的视频编码格式是 VP9，音频格式是 Vorbis。 如果不指明编码格式，FFmpeg 会自己判断输入文件的编码。因此，上面的命令可以简单写成下面的样子。 $ ffmpeg -i input.avi output.mp4 三、常用命令行参数FFmpeg 常用的命令行参数如下。 -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。 四、常见用法下面介绍 FFmpeg 几种常见用法。 4.1 查看文件信息查看视频文件的元信息，比如编码格式和比特率，可以只使用-i参数。 $ ffmpeg -i input.mp4 上面命令会输出很多冗余信息，加上-hide_banner参数，可以只显示元信息。 $ ffmpeg -i input.mp4 -hide_banner 4.2 转换编码格式转换编码格式（transcoding）指的是， 将视频文件从一种编码转成另一种编码。比如转成 H.264 编码，一般使用编码器libx264，所以只需指定输出文件的视频编码器即可。 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 下面是转成 H.265 编码的写法。 $ ffmpeg -i [input.file] -c:v libx265 output.mp4 4.3 转换容器格式转换容器格式（transmuxing）指的是，将视频文件从一种容器转到另一种容器。下面是 mp4 转 webm 的写法。 $ ffmpeg -i input.mp4 -c copy output.webm 上面例子中，只是转一下容器，内部的编码格式不变，所以使用-c copy指定直接拷贝，不经过转码，这样比较快。 4.4 调整码率调整码率（transrating）指的是，改变编码的比特率，一般用来将视频文件的体积变小。下面的例子指定码率最小为964K，最大为3856K，缓冲区大小为 2000K。 $ ffmpeg \\-i input.mp4 \\-minrate 964K -maxrate 3856K -bufsize 2000K output.mp4 4.5 改变分辨率（transsizing）下面是改变视频分辨率（transsizing）的例子，从 1080p 转为 480p 。 $ ffmpeg \\-i input.mp4 \\-vf scale=480:-1 output.mp4 4.6 提取音频有时，需要从视频里面提取音频（demuxing），可以像下面这样写。 $ ffmpeg \\-i input.mp4 \\-vn -c:a copy output.aac 上面例子中，-vn表示去掉视频，-c:a copy表示不改变音频编码，直接拷贝。 4.7 添加音轨添加音轨（muxing）指的是，将外部音频加入视频，比如添加背景音乐或旁白。 $ ffmpeg \\-i input.aac -i input.mp4 output.mp4 上面例子中，有音频和视频两个输入文件，FFmpeg 会将它们合成为一个文件。 4.8 截图下面的例子是从指定时间开始，连续对1秒钟的视频进行截图。 $ ffmpeg \\-y \\-i input.mp4 \\-ss 00:01:24 -t 00:00:01 output_%3d.jpg 如果只需要截一张图，可以指定只截取一帧。 $ ffmpeg \\-ss 01:23:45 \\-i input \\-vframes 1 -q:v 2 output.jpg 上面例子中，-vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。 4.9 裁剪裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output]$ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 下面是实际的例子。 $ ffmpeg -ss 00:01:50 -i [input] -t 10.5 -c copy [output]$ ffmpeg -ss 2.5 -i [input] -to 10 -c copy [output] 上面例子中，-c copy表示不改变音频和视频的编码格式，直接拷贝，这样会快很多。 4.10 为音频添加封面有些视频网站只允许上传视频文件。如果要上传音频文件，必须为音频添加封面，将其转为视频，然后上传。 下面命令可以将音频文件，转为带封面的视频文件。 $ ffmpeg \\-loop 1 \\-i cover.jpg -i input.mp3 \\-c:v libx264 -c:a aac -b:a 192k -shortest output.mp4 上面命令中，有两个输入文件，一个是封面图片cover.jpg，另一个是音频文件input.mp3。-loop 1参数表示图片无限循环，-shortest参数表示音频文件结束，输出视频就结束。 五、参考链接 FFmpeg libav tutorial Digital video introduction FFmpeg encoding and editing course Making Slideshows w/FFMpeg The Complete Guide for Using ffmpeg in Linux （完）","categories":[],"tags":[{"name":"视频处理","slug":"视频处理","permalink":"https://kanchai.club/tags/%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86/"}]},{"title":"GitHub 敏捷开发入门教程","slug":"敏捷开发入门教程","date":"2020-04-01T03:53:11.702Z","updated":"2020-04-01T03:51:42.000Z","comments":true,"path":"2020/04/01/敏捷开发入门教程/","link":"","permalink":"https://kanchai.club/2020/04/01/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2019年3月 6日 敏捷开发（agile development）是非常流行的软件开发方法。据统计，2018年90%的软件开发采用敏捷开发。 但是，到底什么是敏捷开发，能说清的人却不多。本文尝试用简洁易懂的语言，解释敏捷开发。 一、迭代开发敏捷开发的核心是迭代开发（iterative development）。敏捷一定是采用迭代开发的方式。 那么什么是”迭代开发”呢？迭代的英文是 iterative，直译为”重复”，迭代开发其实就是”重复开发”。 对于大型软件项目，传统的开发方式是采用一个大周期（比如一年）进行开发，整个过程就是一次”大开发”；迭代开发的方式则不一样，它将开发过程拆分成多个小周期，即一次”大开发”变成多次”小开发”，每次小开发都是同样的流程，所以看上去就好像重复在做同样的步骤。 举例来说，SpaceX 公司想造一个大推力火箭，将人类送到火星。但是，它不是一开始就造大火箭，而是先造一个最简陋的小火箭 Falcon 1。结果，第一次发射就爆炸了，直到第四次发射，才成功进入轨道。然后，开发了中型火箭 Falcon 9，九年中发射了70次。最后，才开发 Falcon 重型火箭。如果 SpaceX 不采用迭代开发，它可能直到现在还无法上天。 迭代开发将一个大任务，分解成多次连续的开发，本质就是逐步改进。开发者先快速发布一个有效但不完美的最简版本，然后不断迭代。每一次迭代都包含规划、设计、编码、测试、评估五个步骤，不断改进产品，添加新功能。通过频繁的发布，以及跟踪对前一次迭代的反馈，最终接近较完善的产品形态。 二、增量开发迭代开发只是要求将开发分成多个迭代，并没有回答一个重要的问题：怎么划分迭代，哪个任务在这个迭代，哪个任务在下个迭代？这时，一般采用”增量开发”（incremental development）划分迭代。 所谓”增量开发”，指的是软件的每个版本，都会新增一个用户可以感知的完整功能。也就是说，按照新增功能来划分迭代。 举例来说，房产公司开发一个10栋楼的小区。如果采用增量开发的模式，该公司第一个迭代就是交付一号楼，第二个迭代交付二号楼……每个迭代都是完成一栋完整的楼。而不是第一个迭代挖好10栋楼的地基，第二个迭代建好每栋楼的骨架，第三个迭代架设屋顶…… 增量开发加上迭代开发，才算真正的敏捷开发。 三、敏捷开发的好处3.1 早期交付敏捷开发的第一个好处，就是早期交付，从而大大降低成本。 还是以上一节的房产公司为例，如果按照传统的”瀑布开发模式”，先挖10栋楼的地基、再盖骨架、然后架设屋顶，每个阶段都等到前一个阶段完成后开始，可能需要两年才能一次性交付10栋楼。也就是说，如果不考虑预售，该项目必须等到两年后才能回款。 敏捷开发是六个月后交付一号楼，后面每两个月交付一栋楼。因此，半年就能回款10%，后面每个月都会有现金流，资金压力就大大减轻了。 3.2 降低风险敏捷开发的第二个好处是，及时了解市场需求，降低产品不适用的风险。 请想一想，哪一种情况损失比较小：10栋楼都造好以后，才发现卖不出去，还是造好第一栋楼，就发现卖不出去，从而改进或停建后面9栋楼？ 对于软件项目来说，先有一个原型产品，了解市场的接受程度，往往是项目成功的关键。有一本书叫做《梦断代码》，副标题就是”20+个程序员，三年时间，4732个bug，100+万美元，最后失败的故事”，这就是没有采用敏捷开发的结果。相反的，Instagram 最初是一个地理位置打卡 App，后来发现用户不怎么在乎地理位置，更喜欢上传照片，就改做照片上传软件，结果成了独角兽。 由于敏捷开发可以不断试错，找出对业务最重要的功能，然后通过迭代，调整软件方向。相比传统方式，大大增加了产品成功的可能性。如果市场需求不确定，或者你对该领域不熟悉，那么敏捷开发几乎是唯一可行的应对方式。 四、如何进行每一次迭代虽然敏捷开发将软件开发分成多个迭代，但是也要求，每次迭代都是一个完整的软件开发周期，必须按照软件工程的方法论，进行正规的流程管理。 具体来说，每次迭代都必须依次完成以下五个步骤。 需求分析（requirements analysis） 设计（design） 编码（coding） 测试（testing） 部署和评估（deployment / evaluation） 每个迭代大约持续2~6周。 五、敏捷开发的价值观《敏捷软件开发宣言》里面提到四个价值观。 程序员的主观能动性，以及程序员之间的互动，优于既定流程和工具。 软件能够运行，优于详尽的文档。 跟客户的密切协作，优于合同和谈判。 能够响应变化，优于遵循计划。 六、十二条原则该宣言还提出十二条敏捷开发的原则。 通过早期和持续交付有价值的软件，实现客户满意度。 欢迎不断变化的需求，即使是在项目开发的后期。要善于利用需求变更，帮助客户获得竞争优势。 不断交付可用的软件，周期通常是几周，越短越好。 项目过程中，业务人员与开发人员必须在一起工作。 项目必须围绕那些有内在动力的个人而建立，他们应该受到信任。 面对面交谈是最好的沟通方式。 可用性是衡量进度的主要指标。 提倡可持续的开发，保持稳定的进展速度。 不断关注技术是否优秀，设计是否良好。 简单性至关重要，尽最大可能减少不必要的工作。 最好的架构、要求和设计，来自团队内部自发的认识。 团队要定期反思如何更有效，并相应地进行调整。 七、参考链接 Iterative development: the secret to great product launches, Pavlo Zinchenko Agile software development, Wikipedia","categories":[],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"https://kanchai.club/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"OAuth 2.0 的四种方式！","slug":"OAuth_2.0_的四种方式","date":"2020-04-01T03:34:33.238Z","updated":"2020-04-01T03:31:54.000Z","comments":true,"path":"2020/04/01/OAuth_2.0_的四种方式/","link":"","permalink":"https://kanchai.club/2020/04/01/OAuth_2.0_%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月 9日 上一篇文章介绍了 OAuth 2.0 是一种授权机制，主要用来颁发令牌（token）。本文接着介绍颁发令牌的实务操作。 下面我假定，你已经理解了 OAuth 2.0 的含义和设计思想，否则请先阅读这个系列的上一篇文章。 进入正文之前，插播一则活动消息。 4月22日（周一）到4月29日（下周一），每天晚上八点都有两小时的免费直播课，体系化介绍高级前端开发知识，网易云课堂主办。详细介绍请看本文结尾，欢迎关注。 RFC 6749OAuth 2.0 的标准是 RFC 6749 文件。该文件先解释了 OAuth 是什么。 OAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。……资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。 这段话的意思就是，OAuth 的核心就是向第三方应用颁发令牌。然后，RFC 6749 接着写道： （由于互联网有多种场景，）本标准定义了获得令牌的四种授权方式（authorization grant ）。 也就是说，OAuth 2.0 规定了四种获得令牌的流程。你可以选择最适合自己的那一种，向第三方应用颁发令牌。下面就是这四种授权方式。 授权码（authorization-code） 隐藏式（implicit） 密码式（password）： 客户端凭证（client credentials） 注意，不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 第一种授权方式：授权码授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。 这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。 第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 https://b.com/oauth/authorize? response_type=code&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 上面 URL 中，response_type参数表示要求返回授权码（code），client_id参数让 B 知道是谁在请求，redirect_uri参数是 B 接受或拒绝请求后的跳转网址，scope参数表示要求的授权范围（这里是只读）。 第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回redirect_uri参数指定的网址。跳转时，会传回一个授权码，就像下面这样。 https://a.com/callback?code=AUTHORIZATION_CODE 上面 URL 中，code参数就是授权码。 第三步，A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。 https://b.com/oauth/token? client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; grant_type=authorization_code&amp; code=AUTHORIZATION_CODE&amp; redirect_uri=CALLBACK_URL 上面 URL 中，client_id参数和client_secret参数用来让 B 确认 A 的身份（client_secret参数是保密的，因此只能在后端发请求），grant_type参数的值是AUTHORIZATION_CODE，表示采用的授权方式是授权码，code参数是上一步拿到的授权码，redirect_uri参数是令牌颁发后的回调网址。 第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向redirect_uri指定的网址，发送一段 JSON 数据。 { “access_token”:”ACCESS_TOKEN”, “token_type”:”bearer”, “expires_in”:2592000, “refresh_token”:”REFRESH_TOKEN”, “scope”:”read”, “uid”:100101, “info”:{…}} 上面 JSON 数据中，access_token字段就是令牌，A 网站在后端拿到了。 第二种方式：隐藏式有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端。RFC 6749 就规定了第二种方式，允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）”隐藏式”（implicit）。 第一步，A 网站提供一个链接，要求用户跳转到 B 网站，授权用户数据给 A 网站使用。 https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 上面 URL 中，response_type参数为token，表示要求直接返回令牌。 第二步，用户跳转到 B 网站，登录后同意给予 A 网站授权。这时，B 网站就会跳回redirect_uri参数指定的跳转网址，并且把令牌作为 URL 参数，传给 A 网站。 https://a.com/callback#token=ACCESS_TOKEN 上面 URL 中，token参数就是令牌，A 网站因此直接在前端拿到令牌。 注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在”中间人攻击”的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。 这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。 第三种方式：密码式如果你高度信任某个应用，RFC 6749 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为”密码式”（password）。 第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。 https://oauth.b.com/token? grant_type=password&amp; username=USERNAME&amp; password=PASSWORD&amp; client_id=CLIENT_ID 上面 URL 中，grant_type参数是授权方式，这里的password表示”密码式”，username和password是 B 的用户名和密码。 第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。 这种方式需要用户给出自己的用户名/密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。 第四种方式：凭证式最后一种方式是凭证式（client credentials），适用于没有前端的命令行应用，即在命令行下请求令牌。 第一步，A 应用在命令行向 B 发出请求。 https://oauth.b.com/token? grant_type=client_credentials&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET 上面 URL 中，grant_type参数等于client_credentials表示采用凭证式，client_id和client_secret用来让 B 确认 A 的身份。 第二步，B 网站验证通过以后，直接返回令牌。 这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。 令牌的使用A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。 此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个Authorization字段，令牌就放在这个字段里面。 curl -H “Authorization: Bearer ACCESS_TOKEN” \\“https://api.b.com&quot; 上面命令中，ACCESS_TOKEN就是拿到的令牌。 更新令牌令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。 具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh token 字段）。令牌到期前，用户使用 refresh token 发一个请求，去更新令牌。 https://b.com/oauth/token? grant_type=refresh_token&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; refresh_token=REFRESH_TOKEN 上面 URL 中，grant_type参数为refresh_token表示要求更新令牌，client_id参数和client_secret参数用于确认身份，refresh_token参数就是用于更新令牌的令牌。 B 网站验证通过以后，就会颁发新的令牌。 写到这里，颁发令牌的四种方式就介绍完了。下一篇文章会编写一个真实的 Demo，演示如何通过 OAuth 2.0 向 GitHub 的 API 申请令牌，然后再用令牌获取数据。","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"GitHub 第三方登录示例教程！","slug":"GitHub_OAuth_第三方登录示例教程","date":"2020-04-01T03:34:33.147Z","updated":"2020-04-01T03:34:04.000Z","comments":true,"path":"2020/04/01/GitHub_OAuth_第三方登录示例教程/","link":"","permalink":"https://kanchai.club/2020/04/01/GitHub_OAuth_%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95%E7%A4%BA%E4%BE%8B%E6%95%99%E7%A8%8B/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月21日 这组 OAuth 系列教程，第一篇介绍了基本概念，第二篇介绍了获取令牌的四种方式，今天演示一个实例，如何通过 OAuth 获取 API 数据。 很多网站登录时，允许使用第三方网站的身份，这称为”第三方登录”。 下面就以 GitHub 为例，写一个最简单的应用，演示第三方登录。 一、第三方登录的原理所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。 举例来说，A 网站允许 GitHub 登录，背后就是下面的流程。 A 网站让用户跳转到 GitHub。 GitHub 要求用户登录，然后询问”A 网站要求获得 xx 权限，你是否同意？” 用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。 A 网站使用授权码，向 GitHub 请求令牌。 GitHub 返回令牌. A 网站使用令牌，向 GitHub 请求用户数据。 下面就是这个流程的代码实现。 二、应用登记一个应用要求 OAuth 授权，必须先到对方网站登记，让对方知道是谁在请求。 所以，你要先去 GitHub 登记一下。当然，我已经登记过了，你使用我的登记信息也可以，但为了完整走一遍流程，还是建议大家自己登记。这是免费的。 访问这个网址，填写登记表。 应用的名称随便填，主页 URL 填写http://localhost:8080，跳转网址填写 http://localhost:8080/oauth/redirect。 提交表单以后，GitHub 应该会返回客户端 ID（client ID）和客户端密钥（client secret），这就是应用的身份识别码。 三、示例仓库我写了一个代码仓库，请将它克隆到本地。 $ git clone git@github.com:ruanyf/node-oauth-demo.git$ cd node-oauth-demo 两个配置项要改一下，写入上一步的身份识别码。 index.js：改掉变量clientID and clientSecret public/index.html：改掉变量client_id 然后，安装依赖。 $ npm install 启动服务。 $ node index.js 浏览器访问http://localhost:8080，就可以看到这个示例了。 四、浏览器跳转 GitHub示例的首页很简单，就是一个链接，让用户跳转到 GitHub。 跳转的 URL 如下。 https://github.com/login/oauth/authorize? client_id=7e015d8ce32370079895&amp; redirect_uri=http://localhost:8080/oauth/redirect 这个 URL 指向 GitHub 的 OAuth 授权网址，带有两个参数：client_id告诉 GitHub 谁在请求，redirect_uri是稍后跳转回来的网址。 用户点击到了 GitHub，GitHub 会要求用户登录，确保是本人在操作。 五、授权码登录后，GitHub 询问用户，该应用正在请求数据，你是否同意授权。 用户同意授权， GitHub 就会跳转到redirect_uri指定的跳转网址，并且带上授权码，跳转回来的 URL 就是下面的样子。 http://localhost:8080/oauth/redirect? code=859310e7cecc9196f4af 后端收到这个请求以后，就拿到了授权码（code参数）。 六、后端实现示例的后端采用 Koa 框架编写，具体语法请看教程。 这里的关键是针对/oauth/redirect的请求，编写一个路由，完成 OAuth 认证。 const oauth = async ctx =&gt; { // …};app.use(route.get(‘/oauth/redirect’, oauth)); 上面代码中，oauth函数就是路由的处理函数。下面的代码都写在这个函数里面。 路由函数的第一件事，是从 URL 取出授权码。 const requestToken = ctx.request.query.code; 七、令牌后端使用这个授权码，向 GitHub 请求令牌。 const tokenResponse = await axios({ method: ‘post’, url: ‘https://github.com/login/oauth/access_token?&#39; + `client_id=${clientID}&amp;` + `client_secret=${clientSecret}&amp;` + `code=${requestToken}`, headers: { accept: ‘application/json’ }}); 上面代码中，GitHub 的令牌接口https://github.com/login/oauth/access_token需要提供三个参数。 client_id：客户端的 ID client_secret：客户端的密钥 code：授权码 作为回应，GitHub 会返回一段 JSON 数据，里面包含了令牌accessToken。 const accessToken = tokenResponse.data.access_token; 八、API 数据有了令牌以后，就可以向 API 请求数据了。 const result = await axios({ method: ‘get’, url: `https://api.github.com/user\\`, headers: { accept: ‘application/json’, Authorization: `token ${accessToken}` }}); 上面代码中，GitHub API 的地址是https://api.github.com/user，请求的时候必须在 HTTP 头信息里面带上令牌Authorization: token 361507da。 然后，就可以拿到用户数据，得到用户的身份。 const name = result.data.name;ctx.response.redirect(/welcome.html?name=${name}); （完）","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"OAuth 2.0 的一个简单解释！","slug":"OAuth_2.0_的一个简单解释","date":"2020-04-01T03:27:48.218Z","updated":"2020-04-01T03:26:59.000Z","comments":true,"path":"2020/04/01/OAuth_2.0_的一个简单解释/","link":"","permalink":"https://kanchai.club/2020/04/01/OAuth_2.0_%E7%9A%84%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E8%A7%A3%E9%87%8A/","excerpt":"","text":"作者： 阮一峰 日期： 2019年4月 4日 OAuth 2.0 是目前最流行的授权机制，用来授权第三方应用，获取用户数据。 这个标准比较抽象，使用了很多术语，初学者不容易理解。其实说起来并不复杂，下面我就通过一个简单的类比，帮助大家轻松理解，OAuth 2.0 到底是什么。 一、快递员问题我住在一个大型的居民小区。 小区有门禁系统。 进入的时候需要输入密码。 我经常网购和外卖，每天都有快递员来送货。我必须找到一个办法，让快递员通过门禁系统，进入小区。 如果我把自己的密码，告诉快递员，他就拥有了与我同样的权限，这样好像不太合适。万一我想取消他进入小区的权力，也很麻烦，我自己的密码也得跟着改了，还得通知其他的快递员。 有没有一种办法，让快递员能够自由进入小区，又不必知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？ 二、授权机制的设计于是，我设计了一套授权机制。 第一步，门禁系统的密码输入器下面，增加一个按钮，叫做”获取授权”。快递员需要首先按这个按钮，去申请授权。 第二步，他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。 我确认请求属实，就点击按钮，告诉门禁系统，我同意给予他进入小区的授权。 第三步，门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。 第四步，快递员向门禁系统输入令牌，进入小区。 有人可能会问，为什么不是远程为快递员开门，而要为他单独生成一个令牌？这是因为快递员可能每天都会来送货，第二天他还可以复用这个令牌。另外，有的小区有多重门禁，快递员可以使用同一个令牌通过它们。 三、互联网场景我们把上面的例子搬到互联网，就是 OAuth 的设计了。 首先，居民小区就是储存用户数据的网络服务。比如，微信储存了我的好友信息，获取这些信息，就必须经过微信的”门禁系统”。 其次，快递员（或者说快递公司）就是第三方应用，想要穿过门禁系统，进入小区。 最后，我就是用户本人，同意授权第三方应用进入小区，获取我的数据。 简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。 四、令牌与密码令牌（token）与密码（password）的作用是一样的，都可以进入系统，但是有三点差异。 （1）令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。 （2）令牌可以被数据所有者撤销，会立即失效。以上例而言，屋主可以随时取消快递员的令牌。密码一般不允许被他人撤销。 （3）令牌有权限范围（scope），比如只能进小区的二号门。对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。 上面这些设计，保证了令牌既可以让第三方应用获得权限，同时又随时可控，不会危及系统安全。这就是 OAuth 2.0 的优点。 注意，只要知道了令牌，就能进入系统。系统一般不会再次确认身份，所以令牌必须保密，泄漏令牌与泄漏密码的后果是一样的。 这也是为什么令牌的有效期，一般都设置得很短的原因。 OAuth 2.0 对于如何颁发令牌的细节，规定得非常详细。具体来说，一共分成四种授权类型（authorization grant），即四种颁发令牌的方式，适用于不同的互联网场景。下一篇文章，我就来介绍这四种类型，并给出代码实例。 （完） 文档信息 版权声明：自由转载-非商用-非衍生-保持署名（创意共享3.0许可证） 发表日期： 2019年4月 4日","categories":[],"tags":[{"name":"认证授权","slug":"认证授权","permalink":"https://kanchai.club/tags/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"}]},{"title":"【57期】面试官问，MySQL建索引需要遵循哪些原则呢？","slug":"【57期】面试官问，MySQL建索引需要遵循哪些原则呢？","date":"2020-03-25T03:41:06.399Z","updated":"2020-03-25T03:35:40.000Z","comments":true,"path":"2020/03/25/【57期】面试官问，MySQL建索引需要遵循哪些原则呢？/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9057%E6%9C%9F%E3%80%91%E9%9D%A2%E8%AF%95%E5%AE%98%E9%97%AE%EF%BC%8CMySQL%E5%BB%BA%E7%B4%A2%E5%BC%95%E9%9C%80%E8%A6%81%E9%81%B5%E5%BE%AA%E5%93%AA%E4%BA%9B%E5%8E%9F%E5%88%99%E5%91%A2%EF%BC%9F/","excerpt":"","text":"1.选择唯一性索引唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。 2.为经常需要排序、分组和联合操作的字段建立索引经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。 3.为常作为查询条件的字段建立索引如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 4.限制索引的数目索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。 5.尽量使用数据量少的索引如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。 6.尽量使用前缀来索引如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 7.删除不再使用或者很少使用的索引表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 8.最左前缀匹配原则，非常重要的原则。mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a 1=”” and=”” b=”2” c=”“&gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 9.=和in可以乱序。比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 10.尽量选择区分度高的列作为索引。区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就 是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条 记录 11.索引列不能参与计算，保持列“干净”。比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本 太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 12.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 注意：选择索引的最终目的是为了使查询的速度变快。上面给出的原则是最基本的准则，但不能拘泥于上面的准则。读者要在以后的学习和工作中进行不断的实践。根据应用的实际情况进行分析和判断，选择最合适的索引方式。## 目标 去除 iconfinder 上 icon 的水印 原理利用水印像素点和原图像素点颜色合并的原理，如果拥有加过水印的图片和水印图片，就可以反向推出原图原像素点的颜色；前提是你得拥有他的水印图片 来源：https://blog.csdn.net/u013412790/","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"【63期】谈谈MySQL 索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）","slug":"【63期】谈谈MySQL_索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）","date":"2020-03-25T03:41:04.566Z","updated":"2020-03-25T03:34:51.000Z","comments":true,"path":"2020/03/25/【63期】谈谈MySQL_索引，B+树原理，以及建索引的几大原则（MySQL面试第六弹）/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9063%E6%9C%9F%E3%80%91%E8%B0%88%E8%B0%88MySQL_%E7%B4%A2%E5%BC%95%EF%BC%8CB+%E6%A0%91%E5%8E%9F%E7%90%86%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E5%87%A0%E5%A4%A7%E5%8E%9F%E5%88%99%EF%BC%88MySQL%E9%9D%A2%E8%AF%95%E7%AC%AC%E5%85%AD%E5%BC%B9%EF%BC%89/","excerpt":"","text":"MYSQL一直了解得都不多，之前写sql准备提交生产环境之前的时候，老员工帮我检查了下sql，让修改了一下存储引擎，当时我使用的是Myisam，后面改成InnoDB了。为什么要改成这样，之前都没有听过存储引擎，于是网上查了一下。 事实上使用不同的存储引擎也是有很大区别的，下面猿友们可以了解一下。 一、存储引擎的比较 注：上面提到的B树索引并没有指出是B-Tree和B+Tree索引，但是B-树和B+树的定义是有区别的。 在 MySQL 中，主要有四种类型的索引，分别为：B-Tree 索引， Hash 索引， Fulltext 索引和 R-Tree 索引。 B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B-Tree 索引。Archive 引擎直到 MySQL 5.1 才支持索引，而且只支持索引单个 AUTO_INCREMENT 列。 不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中B-Tree 索引也同样是作为最主要的索引类型，这主要是因为 B-Tree 索引的存储结构在数据库的数据检索中有非常优异的表现。 一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node(叶子节点) ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引。 当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息（增加了顺序访问指针），这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。 InnoDB是Mysql的默认存储引擎(Mysql5.5.5之前是MyISAM） 可能对于没有了解过索引的猿友这样看这篇文章十分吃力，这类猿友有必要先对Mysql索引有个大体的了解。 接下来我们先看看B-树、B+树的概念。弄清楚，为什么加了索引查询速度会加快？ 二、B-树、B+树概念B树即二叉搜索树： 所有非叶子结点至多拥有两个儿子（Left和Right）； 所有结点存储一个关键字； 非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； 如： B-树是一种多路搜索树（并不是二叉的）： 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； 如：（M=3） B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点； B-树的特性： 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； 由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少利用率。 所以B-树的性能总是等价于二分查找（与M值无关），也就没有B树平衡的问题； 由于M/2的限制，在插入结点时，如果结点已满，需要将结点分裂为两个各占M/2的结点；删除结点时，需将两个不足M/2的兄弟结点合并； B+树B+树是B-树的变体，也是一种多路搜索树： 其定义基本与B-树同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； 如：（M=3） B+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的特性： 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 更适合文件索引系统； 三、建索引的几大原则1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 3.尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 来源：blog.csdn.net/u013142781/article/details/51706790","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"【58期】盘点那些面试中最常问的MySQL问题，第一弹！","slug":"【58期】盘点那些面试中最常问的MySQL问题，第一弹！","date":"2020-03-25T03:41:02.744Z","updated":"2020-03-25T03:40:05.000Z","comments":true,"path":"2020/03/25/【58期】盘点那些面试中最常问的MySQL问题，第一弹！/","link":"","permalink":"https://kanchai.club/2020/03/25/%E3%80%9058%E6%9C%9F%E3%80%91%E7%9B%98%E7%82%B9%E9%82%A3%E4%BA%9B%E9%9D%A2%E8%AF%95%E4%B8%AD%E6%9C%80%E5%B8%B8%E9%97%AE%E7%9A%84MySQL%E9%97%AE%E9%A2%98%EF%BC%8C%E7%AC%AC%E4%B8%80%E5%BC%B9%EF%BC%81/","excerpt":"","text":"1、MySQL中myisam与innodb的区别 MyISAM： 不支持事务，但是每次查询都是原子的； 支持表级锁，即每次操作对整个表加锁； 存储表的总行数； 一个MYISAM表有三个文件：索引文件、表结构文件、数据文件； 采用非聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。 InnoDb： 支持ACID的事务，支持事务的四种隔离级别； 支持行级锁及外键约束：因此可以支持写并发； 不存储总行数； 一个InnoDb引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制； 主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。 两者的适用场景： 因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原子性要求低。那么MyISAM最好的选择。且MyISAM恢复速度快。可直接用备份覆盖恢复。 如果系统读少，写多的时候，尤其是并发写入高的时候。InnoDB就是首选了。 扩展问题：myisam与innodb引擎下select count(*)哪个更快，为什么？ 知道的童鞋，欢迎留言说出正确答案~ 2、MySQL INT和CHAR隐式类型转换需要注意什么？ 主要需要记住下面两点： 1、当查询字段是INT类型，如果查询条件为CHAR，将查询条件转换为INT，如果是字符串前导都是数字，将截取前导数字用来比较，如果没有前导数字，则转换为0。 2.、当查询字段是CHAR/VARCHAR类型，如果查询条件为INT，将查询字段转换为INT再进行比较，可能会造成全表扫描。 答案解析 有如下一张测试表product，id为int类型，name为varchar类型。 +----+----------+| id | name |+----+----------+| 1 | apple || 2 | banana || 3 | 99cat |+----+----------+ 情况1: // 查询条件转化为数字1再比较mysql&gt; select * from product where id = &#39;1abc23&#39;;+----+---------+| id | name |+----+---------+| 1 | apple |+----+---------+ 情况2: // 查询字段全部转化成数字，id:1和id:2字段值转化为0，id:3转化成99，再比较mysql&gt; select * from product where name=0;+----+----------+| id | name |+----+----------+| 1 | apple || 2 | banana |+----+----------+ 3、MySQL 如何高效率随机获取N条数据？ 假设表叫做mm_account。 ID连续的情况下（注意不能带where，否则结果不好）： SELECT *FROM `mm_account` AS t1 JOIN (SELECT ROUND(RAND() * (SELECT MAX(id) FROM `mm_account`)) AS id) AS t2WHERE t1.id &gt;= t2.idORDER BY t1.id ASC LIMIT 4; ID不连续的情况下： SELECT * FROM `mm_account` WHERE id &gt;= (SELECT floor(RAND() * (SELECT MAX(id) FROM `mm_account`))) and city=&quot;city_91&quot; and showSex=1ORDER BY id LIMIT 4; 如果有一个字段叫id，最快的方法如下（随机获取5条）： SELECT * FROM mm_account WHERE id &gt;= ((SELECT MAX(id) FROM mm_account)-(SELECT MIN(id) FROM mm_account)) * RAND() + (SELECT MIN(id) FROM mm_account)limit 5; 如果带where语句，上面就不适合了，带where语句请看下面： SELECT *FROM `mm_account` AS t1 JOIN (SELECT ROUND(RAND() * ((SELECT MAX(id) FROM `mm_account` where id&lt;1000 )-(SELECT MIN(id) FROM `mm_account` where id&lt;1000 ))+(SELECT MIN(id) FROM `mm_account` where id&lt;1000 )) AS id) AS t2WHERE t1.id &gt;= t2.idORDER BY t1.id LIMIT 5; 4、说说你知道的MySQL的索引类型，并分别简述一下各自的场景。 普通索引：没有任何限制条件的索引，该索引可以在任何数据类型中创建。 唯一索引：使用UNIQUE参数可以设置唯一索引。创建该索引时，索引列的值必须唯一，但允许有空值。通过唯一索引，用户可以快速地定位某条记录，主键索引是一种特殊的唯一索引。 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引耗时耗空间。 空间索引：只能建立在空间数据类型上。这样可以提高系统获取空间数据类型的效率。仅可用于 MyISAM 表，索引的字段不能为空值。使用SPATIAL参数可以设置索引为空间索引。 单列索引：只对应一个字段的索引。 多列索引：在表的多个字段上创建一个索引。该索引指向创建时对应的多个字段，用户可以通过这几个字段进行查询，想使用该索引，用户必须使用这些字段中的一个字段。","categories":[],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://kanchai.club/tags/MYSQL/"}]},{"title":"POI-Excel的导出导入","slug":"excel","date":"2020-03-17T15:36:46.688Z","updated":"2020-03-17T15:33:59.000Z","comments":true,"path":"2020/03/17/excel/","link":"","permalink":"https://kanchai.club/2020/03/17/excel/","excerpt":"","text":"excel-poimaven使用方式123456&lt;!-- excel导入导出 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.stupdit1t&lt;/groupId&gt; &lt;artifactId&gt;poi-excel&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt;&lt;/dependency&gt; 前言 本工程并没有使用注解方式实现，完全是编码方式。个人觉得注解方式对代码侵入比较大。不如纯编码方便，请以maven版本为主，此源码可能不是最新版本。环境为，POI4.0.1 ，JDK1.8 导入 支持严格的单元格校验 支持数据行的图片导入 3支持数据回调处理 03和07都支持 导出 动态表头+表尾 支持List数据 支持图片导出， 支持复杂对象的导出 支持回调处理数据后再导出 支持单元格的样式设置 支持模板导出 导出03和07都支持，默认为03，具体看以下使用方式 支持多sheet导出 选择03还是07？ 03速度较快，单sheet最大65535行，体积大 07速度慢，单sheet最大1048576行，体积小 主要功能：导入1.简单的导入: 1234567891011121314// 1.获取源文件Workbook wb = WorkbookFactory.create(new FileInputStream(\"src\\\\test\\\\java\\\\excel\\\\imports\\\\import.xlsx\"));// 2.获取sheet0导入Sheet sheet = wb.getSheetAt(0);// 3.生成VO数据//参数：1.生成VO的class类型;2.校验规则;3.导入的sheet;3.从第几行导入;4.尾部非数据行数量ImportRspInfo&lt;ProjectEvaluate&gt; list = ExcelUtils.parseSheet(ProjectEvaluate.class, EvaluateVerifyBuilder.getInstance(), sheet, 3, 2);if (list.isSuccess()) &#123; // 导入没有错误，打印数据 System.out.println(JSON.toJSONString(list.getData()));&#125; else &#123; // 导入有错误，打印输出错误 System.out.println(list.getMessage());&#125; 2.复杂导入，带图片导入，带回调处理 1234567891011121314151617181920212223// 1.获取源文件Workbook wb = WorkbookFactory.create(new FileInputStream(\"src\\\\test\\\\java\\\\excel\\\\imports\\\\import.xlsx\"));// 2.获取sheet0导入Sheet sheet = wb.getSheetAt(0);// 3.生成VO数据//参数：1.生成VO的class类型;2.校验规则;3.导入的sheet;3.从第几行导入;4.尾部非数据行数量;5.导入每条数据的回调ImportRspInfo&lt;ProjectEvaluate&gt; list = ExcelUtils.parseSheet(ProjectEvaluate.class, ProjectVerifyBuilder.getInstance(), sheet, 3, 2, (row, rowNum) -&gt; &#123; //1.此处可以完成更多的校验 if(row.getAreaName() == \"中青旅\")&#123; throw new POIException(\"第\"+rowNum+\"行，区域名字不能为中青旅！\"); &#125; //2.图片导入，再ProjectEvaluate定义类型为byte[]的属性就可以，ProjectVerifyBuilder定义ImgVerfiy校验列.就OK了&#125;);if (list.isSuccess()) &#123; // 导入没有错误，打印数据 System.out.println(JSON.toJSONString(list.getData())); //打印图片byte数组长度 byte[] img = list.getData().get(0).getImg(); System.out.println(img);&#125; else &#123; // 导入有错误，打印输出错误 System.out.println(list.getMessage());&#125; 3.自定义校验器，导入需要校验字段,必须继承AbstractVerifyBuidler 1234567891011121314151617181920212223242526public class ProjectVerifyBuilder extends AbstractVerifyBuidler &#123; private static ProjectVerifyBuilder builder = new ProjectVerifyBuilder(); public static ProjectVerifyBuilder getInstance() &#123; return builder; &#125; /** * 定义列校验实体：提取的字段、提取列、校验规则 */ private ProjectVerifyBuilder() &#123; cellEntitys.add(new CellVerifyEntity(\"projectName\", \"B\", new StringVerify(\"项目名称\", true))); cellEntitys.add(new CellVerifyEntity(\"areaName\", \"C\", new StringVerify(\"所属区域\", true))); cellEntitys.add(new CellVerifyEntity(\"province\", \"D\", new StringVerify(\"省份\", true))); cellEntitys.add(new CellVerifyEntity(\"city\", \"E\", new StringVerify(\"市\", true))); cellEntitys.add(new CellVerifyEntity(\"people\", \"F\", new StringVerify(\"项目所属人\", true))); cellEntitys.add(new CellVerifyEntity(\"leader\", \"G\", new StringVerify(\"项目领导人\", true))); cellEntitys.add(new CellVerifyEntity(\"scount\", \"H\", new IntegerVerify(\"总分\", true))); cellEntitys.add(new CellVerifyEntity(\"avg\", \"I\", new DoubleVerify(\"历史平均分\", true))); cellEntitys.add(new CellVerifyEntity(\"createTime\", \"J\", new DateTimeVerify(\"创建时间\", \"yyyy-MM-dd HH:mm\", true))); cellEntitys.add(new CellVerifyEntity(\"img\", \"K\", new ImgVerify(\"图片\", false))); // 必须调用 super.init(); &#125;&#125; 导入示例图 导出0.基础数据构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 单sheet数据 */static List&lt;ProjectEvaluate&gt; sheetData = new ArrayList&lt;&gt;();/** * map型数据 */static List&lt;Map&lt;String, Object&gt;&gt; mapData = new ArrayList&lt;&gt;();/** * 复杂对象数据 */static List&lt;Student&gt; complexData = new ArrayList&lt;&gt;();/** * 多sheet数据 */static List&lt;List&lt;?&gt;&gt; moreSheetData = new ArrayList&lt;&gt;();static &#123; // 1.单sheet数据填充 for (int i = 0; i &lt; 10; i++) &#123; ProjectEvaluate obj = new ProjectEvaluate(); obj.setProjectName(\"中青旅\" + i); obj.setAreaName(\"华东长三角\"); obj.setProvince(\"河北省\"); obj.setCity(\"保定市\"); obj.setPeople(\"张三\" + i); obj.setLeader(\"李四\" + i); obj.setScount(50); obj.setAvg(60.0); obj.setCreateTime(new Date()); obj.setImg(ImageParseBytes(new File(\"src/test/java/excel/export/1.png\"))); sheetData.add(obj); &#125; // 2.map型数据填充 for (int i = 0; i &lt; 15; i++) &#123; Map&lt;String, Object&gt; obj = new HashMap&lt;&gt;(); obj.put(\"name\", \"张三\" + i); obj.put(\"age\", 5 + i); mapData.add(obj); &#125; // 3.复杂对象数据 for (int i = 0; i &lt; 20; i++) &#123; // 學生 Student stu = new Student(); // 學生所在的班級，用對象 stu.setClassRoom(new ClassRoom(\"六班\")); // 學生的更多信息，用map Map&lt;String, Object&gt; moreInfo = new HashMap&lt;&gt;(); moreInfo.put(\"parent\", new Parent(\"張無忌\")); stu.setMoreInfo(moreInfo); stu.setName(\"张三\"); complexData.add(stu); &#125; // 4.多sheet数据填充 moreSheetData.add(sheetData); moreSheetData.add(mapData); moreSheetData.add(complexData);&#125; 1.简单导出 12345678910111213141516171819// 1.获取导出的数据体 // 1.导出的hearder设置String[] hearder = &#123;\"序号\", \"项目名称\", \"所属区域\", \"省份\", \"市\", \"项目所属人\", \"项目领导人\", \"得分\", \"平均分\", \"创建时间\", \"项目图片\"&#125;;// 2.导出hearder对应的字段设置Column[] column = &#123;Column.field(\"projectName\"), Column.field(\"areaName\"), Column.field(\"province\"), Column.field(\"city\"), Column.field(\"people\"), Column.field(\"leader\"), Column.field(\"scount\"), Column.field(\"avg\"), Column.field(\"createTime\"), // 项目图片 Column.field(\"img\")&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(sheetData, ExportRules.simpleRule(column, hearder).title(\"项目资源统计\").sheetName(\"mysheet1\").autoNum(true), true, (feildName, value, t, customStyle) -&gt; &#123; //此处指向回调逻辑，可以修改写入excel的值,以及单元格样式，如颜色等 return value; &#125;);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export1.xlsx\")); 1导出图 2.复杂表格导出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 1.表头设置,可以对应excel设计表头，一看就懂HashMap&lt;String, String&gt; headerRules = new HashMap&lt;&gt;();headerRules.put(\"1,1,A,K\", \"项目资源统计\");headerRules.put(\"2,3,A,A\", \"序号\");headerRules.put(\"2,2,B,E\", \"基本信息\");headerRules.put(\"3,3,B,B\", \"项目名称\");headerRules.put(\"3,3,C,C\", \"所属区域\");headerRules.put(\"3,3,D,D\", \"省份\");headerRules.put(\"3,3,E,E\", \"市\");headerRules.put(\"2,3,F,F\", \"项目所属人\");headerRules.put(\"2,3,G,G\", \"市项目领导人\");headerRules.put(\"2,2,H,I\", \"分值\");headerRules.put(\"3,3,H,H\", \"得分\");headerRules.put(\"3,3,I,I\", \"平均分\");headerRules.put(\"2,3,J,J\", \"创建时间\");headerRules.put(\"2,3,K,K\", \"项目图片\");// 2.尾部设置，一般可以用来设计合计栏HashMap&lt;String, String&gt; footerRules = new HashMap&lt;&gt;();footerRules.put(\"1,2,A,C\", \"注释:\");footerRules.put(\"1,2,D,K\", \"导出参考代码！\");// 3.导出hearder对应的字段设置Column[] column = &#123; Column.field(\"projectName\"), // 4.1设置此列宽度为10 Column.field(\"areaName\").width(10), // 4.2设置此列下拉框数据 Column.field(\"province\").width(5).dorpDown(new String[]&#123;\"陕西省\", \"山西省\", \"辽宁省\"&#125;), // 4.3设置此列水平居右 Column.field(\"city\").align(HorizontalAlignment.RIGHT), // 4.4 设置此列垂直居上 Column.field(\"people\").valign(VerticalAlignment.TOP), // 4.5 设置此列单元格 自定义校验 只能输入文本 Column.field(\"leader\").width(4).verifyCustom(\"VALUE(F3:F500)\", \"我是提示\"), // 4.6设置此列单元格 整数 数据校验 ，同时设置背景色为棕色 Column.field(\"scount\").verifyIntNum(\"10~20\").backColor(IndexedColors.BROWN), // 4.7设置此列单元格 浮点数 数据校验， 同时设置字体颜色红色 Column.field(\"avg\").verifyFloatNum(\"10.0~20.0\").color(IndexedColors.RED), // 4.8设置此列单元格 日期 数据校验 ，同时宽度为20、限制用户表格输入、水平居中、垂直居中、背景色、字体颜色 Column.field(\"createTime\").width(20).verifyDate(\"2000-01-03 12:35~3000-05-06 23:23\") .align(HorizontalAlignment.LEFT).valign(VerticalAlignment.CENTER) .backColor(IndexedColors.YELLOW).color(IndexedColors.GOLD), // 4.9项目图片 Column.field(\"img\")&#125;;// 4.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook( sheetData, ExportRules.complexRule(column, headerRules).autoNum(true).footerRules(footerRules).sheetName(\"mysheet2\"), true, (fieldName, value, row, col) -&gt; &#123; if (\"projectName\".equals(fieldName) &amp;&amp; row.getProjectName().equals(\"中青旅23\")) &#123; col.align(HorizontalAlignment.LEFT); col.valign(VerticalAlignment.CENTER); col.height(2); col.backColor(IndexedColors.RED); col.color(IndexedColors.YELLOW); &#125; return value; &#125;);// 5.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export2.xlsx\")); 2导出图 3.复杂的对象级联导出 123456789 // 1.导出的hearder设置String[] hearder = &#123;\"學生姓名\", \"所在班級\", \"所在學校\", \"更多父母姓名\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"name\"), Column.field(\"classRoom.name\"), Column.field(\"classRoom.school.name\"), Column.field(\"moreInfo.parent.name\"),&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(complexData, ExportRules.simpleRule(column, hearder).title(\"學生基本信息\"), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export3.xlsx\")); 3导出图 4.map对象的简单导出 12345678910// 1.导出的hearder设置String[] hearder = &#123;\"姓名\", \"年龄\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"name\"), Column.field(\"age\"),&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(mapData, ExportRules.simpleRule(column, hearder), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export4.xlsx\")); 4导出图 5.模板导出 123456789101112131415161718 // 1.导出的hearder设置String[] hearder = &#123;\"宝宝姓名\", \"宝宝昵称\", \"家长姓名\", \"手机号码\", \"宝宝生日\", \"月龄\", \"宝宝性别\", \"来源渠道\", \"市场人员\", \"咨询顾问\", \"客服顾问\", \"分配校区\", \"备注\"&#125;;// 2.导出hearder对应的字段设置，列宽设置Column[] column = &#123;Column.field(\"宝宝姓名\"), Column.field(\"宝宝昵称\"), Column.field(\"家长姓名\"), Column.field(\"手机号码\").verifyText(\"11~11\", \"请输入11位的手机号码！\"), Column.field(\"宝宝生日\").verifyDate(\"2000-01-01~3000-12-31\"), Column.field(\"月龄\").width(4).verifyCustom(\"VALUE(F3:F6000)\", \"月齡格式：如1年2个月则输入14\"), Column.field(\"宝宝性别\").dorpDown(new String[]&#123;\"男\", \"女\"&#125;), Column.field(\"来源渠道\").width(12).dorpDown(new String[]&#123;\"品推\", \"市场\"&#125;), Column.field(\"市场人员\").width(6).dorpDown(new String[]&#123;\"张三\", \"李四\"&#125;), Column.field(\"咨询顾问\").width(6).dorpDown(new String[]&#123;\"张三\", \"李四\"&#125;), Column.field(\"客服顾问\").width(6).dorpDown(new String[]&#123;\"大唐\", \"银泰\"&#125;), Column.field(\"分配校区\").width(6).dorpDown(new String[]&#123;\"大唐\", \"银泰\"&#125;), Column.field(\"备注\")&#125;;// 3.执行导出到工作簿Workbook bean = ExcelUtils.createWorkbook(Collections.emptyList(), ExportRules.simpleRule(column, hearder), true);// 4.写出文件bean.write(new FileOutputStream(\"src/test/java/excel/export/export5.xlsx\")); 5导出图 6.多sheet合并导出 12345678910111213141516171819202122232425262728293031323334353637383940414243 // 1.导出的hearder设置Workbook emptyWorkbook = ExcelUtils.createEmptyWorkbook(true);// 2.执行导出到工作簿.1.项目数据2.map数据3.复杂对象数据for (int i = 0; i &lt; moreSheetData.size(); i++) &#123; if (i == 0) &#123; List&lt;ProjectEvaluate&gt; data1 = (ArrayList&lt;ProjectEvaluate&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"序号\", \"项目名称\", \"所属区域\", \"省份\", \"市\", \"项目所属人\", \"项目领导人\", \"得分\", \"平均分\", \"创建时间\", \"项目图片\"&#125;; // 2.导出hearder对应的字段设置 Column[] column = &#123;Column.field(\"projectName\"), Column.field(\"areaName\"), Column.field(\"province\"), Column.field(\"city\"), Column.field(\"people\"), Column.field(\"leader\"), Column.field(\"scount\"), Column.field(\"avg\"), Column.field(\"createTime\"), // 项目图片 Column.field(\"img\") &#125;; ExcelUtils.fillBook(emptyWorkbook, data1, ExportRules.simpleRule(column, hearder).title(\"项目资源统计\").sheetName(\"mysheet1\").autoNum(true)); &#125; if (i == 1) &#123; List&lt;Map&lt;String, Object&gt;&gt; data2 = (ArrayList&lt;Map&lt;String, Object&gt;&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"姓名\", \"年龄\"&#125;; // 2.导出hearder对应的字段设置，列宽设置 Column[] column = &#123;Column.field(\"name\"), Column.field(\"age\"), &#125;; ExcelUtils.fillBook(emptyWorkbook, data2, ExportRules.simpleRule(column, hearder).sheetName(\"mysheet2\")); &#125; if (i == 2) &#123; List&lt;Student&gt; data3 = (ArrayList&lt;Student&gt;) moreSheetData.get(i); // 1.导出的hearder设置 String[] hearder = &#123;\"學生姓名\", \"所在班級\", \"所在學校\", \"更多父母姓名\"&#125;; // 2.导出hearder对应的字段设置，列宽设置 Column[] column = &#123;Column.field(\"name\"), Column.field(\"classRoom.name\"), Column.field(\"classRoom.school.name\"), Column.field(\"moreInfo.parent.name\"),&#125;; // 3.执行导出到工作簿 ExcelUtils.fillBook(emptyWorkbook, data3, ExportRules.simpleRule(column, hearder).title(\"學生基本信息\")); &#125;&#125;// 4.写出文件emptyWorkbook.write(new FileOutputStream(\"src/test/java/excel/export/export6.xlsx\"));","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"轮子工具","slug":"轮子工具","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90%E5%B7%A5%E5%85%B7/"},{"name":"POI","slug":"POI","permalink":"https://kanchai.club/tags/POI/"},{"name":"Excel","slug":"Excel","permalink":"https://kanchai.club/tags/Excel/"}]},{"title":"RedisKey设计类","slug":"RedisKey设计类","date":"2020-03-17T15:36:46.510Z","updated":"2020-03-17T15:34:22.000Z","comments":true,"path":"2020/03/17/RedisKey设计类/","link":"","permalink":"https://kanchai.club/2020/03/17/RedisKey%E8%AE%BE%E8%AE%A1%E7%B1%BB/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.ym.common.utils.redis;import org.apache.commons.lang3.StringUtils;/** * 生成RedisKey工具 * * @author: 李涛 * @version: 2019年05月07日 15:19 */public class RedisKeyUtil &#123; /** * 主数据系统标识 */ public static final String KEY_PREFIX = \"ym\"; /** * 分割字符，默认[:]，使用:可用于rdm分组查看 */ private static final String KEY_SPLIT_CHAR = \":\"; /** * redis的key键规则定义 * * @param module 模块名称 * @param func 方法名称 * @param args 参数.. * @return key */ public static String keyBuilder(String module, String func, String... args) &#123; return keyBuilder(null, module, func, args); &#125; /** * redis的key键规则定义 * * @param module 模块名称 * @param func 方法名称 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(String module, String func, String objStr) &#123; return keyBuilder(null, module, func, new String[]&#123;objStr&#125;); &#125; /** * redis的key键规则定义 * * @param prefix 项目前缀 * @param module 模块名称 * @param func 方法名称 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(String prefix, String module, String func, String objStr) &#123; return keyBuilder(prefix, module, func, new String[]&#123;objStr&#125;); &#125; /** * redis的key键规则定义 * * @param prefix 项目前缀 * @param module 模块名称 * @param func 方法名称 * @param args 参数.. * @return key */ public static String keyBuilder(String prefix, String module, String func, String... args) &#123; // 项目前缀 if (prefix == null) &#123; prefix = KEY_PREFIX; &#125; StringBuilder key = new StringBuilder(prefix); // KEY_SPLIT_CHAR 为分割字符 key.append(KEY_SPLIT_CHAR).append(module); if (StringUtils.isNotBlank(func)) &#123; key.append(KEY_SPLIT_CHAR).append(func); &#125; for (String arg : args) &#123; key.append(KEY_SPLIT_CHAR).append(arg); &#125; return key.toString(); &#125; /** * redis的key键规则定义 * * @param redisKeyEnum 枚举对象 * @param objStr 对象.toString() * @return key */ public static String keyBuilder(RedisKeyEnum redisKeyEnum, String... objStr) &#123; return keyBuilder(redisKeyEnum.getKeyPrefix(), redisKeyEnum.getModule(), redisKeyEnum.getFunc(), objStr); &#125;&#125;","categories":[],"tags":[]},{"title":"短信发送模板","slug":"短信发送模板","date":"2020-03-17T15:36:46.400Z","updated":"2020-03-17T15:34:27.000Z","comments":true,"path":"2020/03/17/短信发送模板/","link":"","permalink":"https://kanchai.club/2020/03/17/%E7%9F%AD%E4%BF%A1%E5%8F%91%E9%80%81%E6%A8%A1%E6%9D%BF/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231package com.ym.enums.common;import com.alibaba.fastjson.JSONObject;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 阿里云短信模板 * * @author: 李涛 * @version: 2019年05月17日 17:58 */public enum SmsTemplateEnum &#123; /** * 模版名称:通用验证码 * &lt;p&gt; */ UNIVERSAL_VERIFICATION_CODE(\"SMS_173141326\", \"您的验证码$&#123;code&#125;，该验证码5分钟内有效，请勿泄漏于他人！\"), /** * 模版名称:身份验证验证码 * &lt;p&gt; */ AUTHENTICATION_CODE(\"SMS_173191624\", \"验证码$&#123;code&#125;，您正在进行身份验证，打死不要告诉别人哦！\"), /** * 模版名称:登录确认验证码 * &lt;p&gt; */ LOGON_CONFIRMATION_AUTHENTICATION_CODE(\"SMS_173191623\", \"验证码$&#123;code&#125;，您正在登录，若非本人操作，请勿泄露。\"), /** * 模版名称:登录异常验证码 * &lt;p&gt; */ LOGON_EXCEPTION_AUTHENTICATION_CODE(\"SMS_173191622\", \"验证码$&#123;code&#125;，您正尝试异地登录，若非本人操作，请勿泄露。\"), /** * 模版名称:用户注册验证码 * &lt;p&gt; */ USER_REGISTRATION_AUTHENTICATION_CODE(\"SMS_173191621\", \"验证码$&#123;code&#125;，您正在注册成为新用户，感谢您的支持！\"), /** * 模版名称:修改密码验证码 * &lt;p&gt; */ MODIFY_PASSWORD_AUTHENTICATION_CODE(\"SMS_173191620\", \"验证码$&#123;code&#125;，您正在尝试修改登录密码，请妥善保管账户信息。\"), /** * 模版名称:信息变更验证码 * &lt;p&gt; */ INFORMATION_CHANGE_VERIFICATION_CODE(\"SMS_173191619\", \"验证码$&#123;code&#125;，您正在尝试变更重要信息，请妥善保管账户信息。\"), /** * 模版名称:医生资料审核不通过 * &lt;p&gt; * 变量：p2-其他；p3-电话号码； * &lt;p&gt; * 备注：用户资料审核不通过，发送短信告诉用户！ */ DATA_AUDIT_FAILED(\"SMS_174986989\", \"抱歉，您暂未通过资质审核，未通过原因：$&#123;p2&#125;。客服电话：$&#123;p3&#125;\"), /** * 模版名称:医生资料审核通过 * &lt;p&gt; * 变量：p2-金额； * &lt;p&gt; * 备注：用户资料审核通过，发送短信通知用户！ */ DATA_AUDIT_SUCCESS(\"SMS_174986992\", \"恭喜，您已通过资质审核，请登录APP开启您的个人诊所之旅吧，完成首单可获得$&#123;p2&#125;元奖励哦！\"), /** * 模版名称:用户注册通知 * &lt;p&gt; * 变量：p2-其他；p3-电话号码；p4-其他号码；p5-金额；p6-电话号码； * &lt;p&gt; * 备注：注册我方亚米健康产品后，发送此短信通知用户注册成功！ */ USER_REGISTRATION_NOTICE(\"SMS_174986988\", \"您已成功注册$&#123;p2&#125;，账号$&#123;p3&#125; ，初始密码 $&#123;p4&#125;。快去亚米健康完成医疗资质认证开启您的线上诊所赢取 $&#123;p5&#125; 元奖励。客服电话：$&#123;p6&#125;。\"), /** * 模版名称:电话预约成功 * &lt;p&gt; * 变量：p2-其他；p3-其他；p4-时间；p5-时间；p6-电话号码； * &lt;p&gt; * 备注：用户电话预约成功后，发送短信通知用户 */ SUCCESSFUL_TELEPHONE_RESERVATION(\"SMS_174991908\", \"您预约了$&#123;p2&#125;医生的$&#123;p3&#125;，时间$&#123;p4&#125;，共$&#123;p5&#125;分钟，到时您会接到$&#123;p6&#125;的来电，请保持电话畅通。\"), /** * 模版名称:图文问诊支付成功 * &lt;p&gt; * 变量：p2-金额；p3-其他； * &lt;p&gt; * 备注：图文问诊支付成功后，向用户发送短信通知 */ SUCCESSFUL_PAYMENT_FOR_CONSULTATION(\"SMS_174991905\", \"您刚支付了$&#123;p2&#125;元向$&#123;p3&#125;医生医生提问。可在我的问诊/当前问诊中找到该问题，查看医生回复。\"), /** * 模版名称:图问问诊医生首次回复 * &lt;p&gt; * 变量：p2-其他；p3-其他号码；p4-电话号码； * &lt;p&gt; * 备注：图问问诊医生首次回复后，需要发送短信告诉用户，让用户及时查看订单 */ DOCTOR_FIRST_REPLY(\"SMS_174986972\", \"医生$&#123;p2&#125;回复了您的问题，请您及时查看并进行后续交流。问题将在$&#123;p3&#125;小时后关闭。 有疑问请联系客服 $&#123;p4&#125;。\"), /** * 模版名称:问诊电话开始短信提醒 * &lt;p&gt; * 变量：p2-其他；p3-其他；p4-电话号码； * &lt;p&gt; * 备注：问诊电话服务快要开始的时候，向患者发送短信提醒。 */ INQUIRY_TELEPHONE_START_SHORT_MESSAGE_REMINDER(\"SMS_174991891\", \"您预约了$&#123;p2&#125;医生的$&#123;p3&#125;服务即将开始，请您合理按排时间，注意接听。到时您会接到$&#123;p4&#125;的来电，请保持电话畅通。\"), /** * 模版名称:患者预约成功推送 * &lt;p&gt; * 变量：p0-其他；p1-其他；p2-时间； * &lt;p&gt; * 备注：患者预约成功推送短信给医生，让医生及时联系患者 */ SUCCESSFUL_PUSH_OF_PATIENT_APPOINTMENT(\"SMS_175245305\", \"$&#123;p0&#125;医生您好，$&#123;p1&#125;患者预约了电话问诊服务，请于$&#123;p2&#125;在亚米医疗APP端拨打电话\"), /** * 模版名称:医生电话问诊即将开始通知 * &lt;p&gt; * 变量：p0-其他；p1-其他； * &lt;p&gt; * 备注：医生电话问诊即将开始通知 */ DOCTOR_S_TELEPHONE_CONSULTATION_IS_ABOUT_TO_START(\"SMS_175240289\", \"$&#123;p0&#125;医生您好，$&#123;p1&#125;患者预约的电话问诊服务即将开始，请及时拨打电话。\"), ; private String code; private String content; private static final Logger LOGGER = LoggerFactory.getLogger(SmsTemplateEnum.class); private SmsTemplateEnum(String code, String content) &#123; this.code = code; this.content = content; &#125; public String getCode() &#123; return code; &#125; /** * 输入对应模板的参数，生成JSON格式 * * @param prams * @return */ public String buildParams(Object... prams) &#123; JSONObject buildParams = new JSONObject(); String content = this.content; Pattern pattern = Pattern.compile(\"\\\\$\\\\&#123;[^&#125;]*\\\\&#125;\"); Matcher matcher = pattern.matcher(content); int index = 0; List&lt;String&gt; logs = new ArrayList&lt;&gt;(); while (matcher.find()) &#123; String group = matcher.group(0); logs.add(group); String key = group.replaceAll(\"\\\\$|\\\\&#123;|\\\\&#125;\", \"\"); buildParams.put(key, prams[index]); index++; &#125; for (int i = 0; i &lt; logs.size(); i++) &#123; content = content.replace(logs.get(i), String.valueOf(prams[i])); &#125; String result = buildParams.toJSONString(); LOGGER.info(\"发送SMS内容为：&#123;&#125;\", content); LOGGER.info(\"发送SMS参数为：&#123;&#125;\", result); return result; &#125; /** * 根据code获取验证码发送模板 * * @param code * @return */ public static SmsTemplateEnum getCodeTemp(String code) &#123; SmsTemplateEnum codeTemp = null; switch (code) &#123; case \"01\": //身份验证 codeTemp = SmsTemplateEnum.AUTHENTICATION_CODE; break; case \"02\": //正常登录 codeTemp = SmsTemplateEnum.LOGON_CONFIRMATION_AUTHENTICATION_CODE; break; case \"03\": //登录异常 codeTemp = SmsTemplateEnum.LOGON_EXCEPTION_AUTHENTICATION_CODE; break; case \"04\": //用户注册 codeTemp = SmsTemplateEnum.USER_REGISTRATION_AUTHENTICATION_CODE; break; case \"05\": //修改密码 codeTemp = SmsTemplateEnum.MODIFY_PASSWORD_AUTHENTICATION_CODE; break; case \"06\": //信息变更 codeTemp = SmsTemplateEnum.INFORMATION_CHANGE_VERIFICATION_CODE; break; default: codeTemp = SmsTemplateEnum.UNIVERSAL_VERIFICATION_CODE; &#125; return codeTemp; &#125;&#125;","categories":[],"tags":[]},{"title":"rabbitmq实现延时队列任务","slug":"rabbitmq实现延时队列任务","date":"2020-03-17T15:36:46.276Z","updated":"2020-03-17T15:34:31.000Z","comments":true,"path":"2020/03/17/rabbitmq实现延时队列任务/","link":"","permalink":"https://kanchai.club/2020/03/17/rabbitmq%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97%E4%BB%BB%E5%8A%A1/","excerpt":"此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时。","text":"此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时。 此前实现过一个基于redis和jvm的延时队列任务执行，有个弊端就是吞吐量和可靠性上得不到保障，比如系统重启队列任务丢失，需要人工的加载等等。所以此次利用rabbitmq来实现一个延时… 要开发肯定先安装MQ,MQ的安装方式可以自行百度，我这里介绍简单的docker安装，首先安装docker服务，再安装带管理界面的rabbitMQ。1234567891011121314151617181920212223#### 1.更新yum源&gt; yum update#### 2.安装docker&gt; yum install -y docker#### 3拉取镜像&gt; docker pull rabbitmq:management#### 4启动容器&gt; docker run -d --name rabbitmq --privileged=true -p 9158:5672 -p 9159:15672 -v /home/rabbit/data:/var/lib/rabbitmq -v /home/rabbit/log:/var/log/rabbitmq -v /home/rabbit/plugins:/plugins --hostname ymRabbit -e RABBITMQ_DEFAULT_VHOST=/ -e RABBITMQ_DEFAULT_USER=ym_rabbit -e RABBITMQ_DEFAULT_PASS=ym_rabbit d8f707718f06#### 5进入容器方式&gt; docker exec -it 容器ID /bin/bash#### 6退出容器&gt; exit 或者 Ctrl+p+q#### 7向容器发送命令&gt; docker exec -d 13dc7c8ce0bd rabbitmq-plugins enable rabbitmq_delayed_message_exchange 两种延时方式 死信+普通交换器，依靠消息过期自动进入死信队列，然后消费死信队列的数据这个思路，但是由于这种方式不管设置队列过期时间还是消息过期时间，都不能达到单个队列消息灵活过期的目的。比如，先放入队列10s过期消息，再放入2s过期。mq会检测头部10s是否过期，10s不过期的情况下，2s就算过去也不会跑到死信。 使用插件rabbitmq_delayed_message_exchange。这个可以很好的解决消息不能灵活过期的问题，但是有个弊端就是很难查看消息堆积的情况，因为他把要发送的延时消息存在本地的分布式mnesia 数据库中，其次过期时间为最大int值，超过这个值得代码判定重复过期设置。 延时插件的使用方式 去MQ官网下载插件 ++https://www.rabbitmq.com/community-plugins.html++(rabbitmq_delayed_message_exchange) 把插件放到MQ的安装目录的plugins下 然后执行rabbitmq-plugins enable rabbitmq_delayed_message_exchange 命令启用插件 然后就也可以在web页面查看新的交换器x-delayed-message（其实并不是真正意义上的，真正的只有4个） 然后上代码实现延时任务，配置文件1234567891011121314151617181920212223spring: rabbitmq: host: 192.168.0.245 port: 9158 username: ym_rabbit password: ym_rabbit listener: simple: acknowledge-mode: manual #手动应答 retry: enabled: true# 用户自定义配置config-center: rabbitRuleConfig: # 系统标志 systemMark: local # 普通消息 normalExchange: topic.normal # 延时消息 delayExchange: topic.delay # 普通和延时消息死信 deadExchange: topic.dead spring中MQ的配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174/** * RabbitMQConfig 配置 * * @author: 李涛 * @version: 2019年05月07日 14:47 */@Configurationpublic class RabbitMQConfig &#123; //----------------------------常量定义----------------------- private static final String POINT = \".\"; private static final String NORMAL = \"nml\"; private static final String DELAY = \"dly\"; private static final String QUEUE = \"que\"; //----------------------------交换器定义---------------------------- /** * 普通交换器名字 */ public static String NORMAL_EXCHANGE = \"\"; /** * 死信交换器名字 */ public static String DEAD_EXCHANGE = \"\"; /** * 延时交换器名字 */ public static String DELAY_EXCHANGE = \"\"; //-------------------------队列定义-------------------------- /** * 普通队列 */ public static String NORMAL_QUEUE = null; /** * 延时队列存放任务 */ public static String DELAY_QUEUE = null; /** * 普通死信队列 */ public static String DEAD_NORMAL_QUEUE = null; /** * 延时死信队列 */ public static String DEAD_DELAY_QUEUE = null; @Autowired private ConfigCenterProperties configCenterProperties; @Bean public RabbitTemplate rabbitTemplate(CachingConnectionFactory rabbitListenerContainerFactory) &#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(rabbitListenerContainerFactory); rabbitTemplate.setUsePublisherConnection(true); rabbitTemplate.setChannelTransacted(true); return rabbitTemplate; &#125; @PostConstruct public void init() &#123; RabbitRuleConfig rabbitRuleConfig = configCenterProperties.getRabbitRuleConfig(); NORMAL_EXCHANGE = rabbitRuleConfig.getNormalExchange() + POINT + rabbitRuleConfig.getSystemMark(); DEAD_EXCHANGE = rabbitRuleConfig.getDeadExchange() + POINT + rabbitRuleConfig.getSystemMark(); DELAY_EXCHANGE = rabbitRuleConfig.getDelayExchange() + POINT + rabbitRuleConfig.getSystemMark(); NORMAL_QUEUE = rabbitRuleConfig.getNormalExchange() + POINT + QUEUE + POINT + rabbitRuleConfig.getSystemMark(); DELAY_QUEUE = rabbitRuleConfig.getDelayExchange() + POINT + QUEUE + POINT + rabbitRuleConfig.getSystemMark(); DEAD_NORMAL_QUEUE = rabbitRuleConfig.getDeadExchange() + POINT + QUEUE + POINT + NORMAL + POINT + rabbitRuleConfig.getSystemMark(); DEAD_DELAY_QUEUE = rabbitRuleConfig.getDeadExchange() + POINT + QUEUE + POINT + DELAY + POINT + rabbitRuleConfig.getSystemMark(); &#125; @Bean public RabbitListenerContainerFactory&lt;?&gt; rabbitListenerContainerFactory(ConnectionFactory connectionFactory) &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setChannelTransacted(true); return factory; &#125; @Bean public RabbitListenerContainerFactory&lt;?&gt; rabbitListenerContainerFactory2(ConnectionFactory connectionFactory) &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setMessageConverter(new SerializerMessageConverter()); factory.setChannelTransacted(true); return factory; &#125; //------------------------------交换器声明start--------------------------- @Bean public TopicExchange normalExchange() &#123; return new TopicExchange(NORMAL_EXCHANGE); &#125; @Bean public TopicExchange deadExchange() &#123; return new TopicExchange(DEAD_EXCHANGE); &#125; @Bean public CustomExchange delayExchange() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(\"x-delayed-type\", \"topic\"); return new CustomExchange(DELAY_EXCHANGE, \"x-delayed-message\", true, false, args); &#125; //------------------------------交换器声明end--------------------------- //-------------------------------队列start--------------------------------- @Bean public Queue deadNormalQueue() &#123; return new Queue(DEAD_NORMAL_QUEUE); &#125; @Bean public Queue deadDelayQueue() &#123; return new Queue(DEAD_DELAY_QUEUE); &#125; @Bean public Queue normalQueue() &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); params.put(\"x-dead-letter-routing-key\", DEAD_NORMAL_QUEUE); return new Queue(NORMAL_QUEUE, true, false, false, params); &#125; @Bean public Queue delayQueue() &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); params.put(\"x-dead-letter-routing-key\", DEAD_DELAY_QUEUE); return new Queue(DELAY_QUEUE, true, false, false, params); &#125; //-------------------------------队列end--------------------------------- //-------------------------------绑定start--------------------------------- @Bean public Binding bindingNormalExchange(Queue normalQueue, TopicExchange normalExchange) &#123; return BindingBuilder.bind(normalQueue).to(normalExchange).with(NORMAL_QUEUE); &#125; @Bean public Binding bindingNormalDeadExchange(Queue deadNormalQueue, TopicExchange deadExchange) &#123; return BindingBuilder.bind(deadNormalQueue).to(deadExchange).with(DEAD_NORMAL_QUEUE); &#125; @Bean public Binding bindingDelayExchange(Queue delayQueue, CustomExchange delayExchange) &#123; return BindingBuilder.bind(delayQueue).to(delayExchange).with(DELAY_QUEUE).noargs(); &#125; @Bean public Binding bindingDelayDeadExchange(Queue deadDelayQueue, TopicExchange deadExchange) &#123; return BindingBuilder.bind(deadDelayQueue).to(deadExchange).with(DEAD_DELAY_QUEUE); &#125; //-----------------------------------------绑定end------------------------------------------&#125; 7.生产者代码开发,我这里将延时任务和普通消息分开了，所以有2个发送方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * 发送消息给MQ * * @author: 李涛 * @version: 2019年09月19日 11:58 */@Servicepublic class IMessageSenderSV &#123; private static final Logger LOG = LoggerFactory.getLogger(IMessageSenderSV.class); @Autowired private RabbitTemplate rabbitTemplate; /** * 发送云信消息 * * @param messageTask 消息内容 */ public void sendMsg(NormalMessageTask messageTask) &#123; LOG.info(\"发送[ &#123;&#125; ]消息到MQ\", messageTask.getMessageTypeEnum().getDescribe()); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.NORMAL_EXCHANGE, RabbitMQConfig.NORMAL_QUEUE, messageTask, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); messageProperties.setMessageId(messageTask.getUuid()); messageProperties.setType(messageTask.getMessageTypeEnum().getDescribe()); messageProperties.setContentType(MessageProperties.CONTENT_TYPE_JSON); String sendTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date()); // 发送时间 messageProperties.setHeader(\"send_time\", sendTime); return message; &#125;); &#125; /** * 发送延时任务给队列 * * @param task 任务 */ public void sendDelayTask(AbstractDelayedTask task) &#123; LOG.info(\"发送延时任务 [ &#123;&#125;:&#123;&#125; ] 到MQ\", task.getDescribe(), task.getDelay()); rabbitTemplate.setMessageConverter(new SerializerMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.DELAY_EXCHANGE, RabbitMQConfig.DELAY_QUEUE, task, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); long nextDelay = 0; if (task.getDelay() &gt; Integer.MAX_VALUE) &#123; //如果延时时间大于erlang最大数值，多次延时 messageProperties.setDelay(Integer.MAX_VALUE); nextDelay = task.getDelay() - Integer.MAX_VALUE; &#125; else &#123; messageProperties.setDelay(task.getDelay().intValue()); &#125; // 下次延时的时间 messageProperties.setHeader(\"next_delay\", nextDelay); messageProperties.setMessageId(task.getUuid()); messageProperties.setType(task.getDescribe()); messageProperties.setContentType(MessageProperties.CONTENT_TYPE_SERIALIZED_OBJECT); String sendTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date()); // 发送时间 messageProperties.setHeader(\"send_time\", sendTime); String expirationTime = DateKit.parseDateToStr(DateKit.YYYY_MM_DD_HH_MM_SS, new Date(System.currentTimeMillis() + task.getDelay())); // 过期时间 messageProperties.setHeader(\"expiration_time\", expirationTime); // 任务的入参 messageProperties.setHeader(\"params\", task.getParams().toString()); return message; &#125;); &#125; /** * 多次延时，再次发送任务 * @param task 任务 * @param nextDelay 下次延时时间 */ public void sendAgain(Message task, final long nextDelay) &#123; rabbitTemplate.setMessageConverter(new SerializerMessageConverter()); rabbitTemplate.convertAndSend(RabbitMQConfig.DELAY_EXCHANGE, RabbitMQConfig.DELAY_QUEUE, task, (message) -&gt; &#123; MessageProperties messageProperties = message.getMessageProperties(); long nextDelayNew = 0; if (nextDelay &gt; Integer.MAX_VALUE) &#123; //如果延时时间大于erlang最大数值，多次延时 messageProperties.setDelay(Integer.MAX_VALUE); nextDelayNew = nextDelay - Integer.MAX_VALUE; &#125; else &#123; messageProperties.setDelay((int) nextDelay); &#125; // 下次延时的时间 messageProperties.setHeader(\"next_delay\", nextDelayNew); return message; &#125;); &#125;&#125; 8.消费者代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158/** * 消费MQ消息 * * @author: 李涛 * @version: 2019年09月18日 10:41 */@Service@EnableRabbitpublic class IMessageReceiveSV &#123; private static final Logger LOG = LoggerFactory.getLogger(IMessageReceiveSV.class); @Autowired private IMessageSenderSV messageSenderSV; @Autowired private IYunxinUserSV yunxinUserSV; @Autowired private RabbitTemplate rabbitTemplate; @Value(\"$&#123;config-center.rabbitRuleConfig.deadExchange&#125;.que.nml.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\") private String normalDeadQueue; @Value(\"$&#123;config-center.rabbitRuleConfig.deadExchange&#125;.que.dly.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\") private String delayDeadQueue; /** * 普通消息 */ @RabbitListener(queues = \"$&#123;config-center.rabbitRuleConfig.normalExchange&#125;.que.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\", containerFactory = \"rabbitListenerContainerFactory\") public void autoNormalMsg(@Payload NormalMessageTask messageTask, @Headers Map&lt;String, Object&gt; headers, Channel channel) throws Exception &#123; channel.txSelect(); boolean success = normalHandle(messageTask); if (success) &#123; channel.basicAck((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; else &#123; channel.basicReject((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; channel.txCommit(); &#125; /** * 手动消费普通消息 */ public void manualConsumptionNormal() &#123; rabbitTemplate.receiveAndReply(normalDeadQueue, (payload) -&gt; &#123; NormalMessageTask normalMessageTask = (NormalMessageTask) payload; boolean success = normalHandle(normalMessageTask); if (!success) &#123; throw new AmqpException(\"普通消息消费异常\"); &#125; return true; &#125;); &#125; /** * 消费普通消息方法 * * @param messageTask */ private boolean normalHandle(NormalMessageTask messageTask) &#123; try &#123; MessageTypeEnum messageTypeEnum = messageTask.getMessageTypeEnum(); Object msg = messageTask.getMsg(); LOG.info(\"消费消息 [ &#123;&#125; ],消息ID为[ &#123;&#125; ]\", messageTypeEnum.getDescribe(), messageTask.getUuid()); switch (messageTypeEnum) &#123; case YUN_XIN: &#123; yunxinUserSV.syncMessages((String) msg); &#125; break; default: &#123; // do LOG.info(\"未知消息:&#123;&#125;\", (String) msg); &#125; &#125; &#125; catch (Exception e) &#123; if (e instanceof BusinessException) &#123; LOG.info(e.getMessage()); return true; &#125; else &#123; LOG.error(\"消费异常:&#123;&#125;\", ExceptionUtil.getExceptionMessage(e)); return false; &#125; &#125; return true; &#125; /** * 延时消息,执行策略 * &lt;p&gt; * 能收到说明已经到时间了 */ @RabbitListener(queues = \"$&#123;config-center.rabbitRuleConfig.delayExchange&#125;.que.$&#123;config-center.rabbitRuleConfig.systemMark&#125;\", containerFactory = \"rabbitListenerContainerFactory2\") public void autoDelayMsg(@Payload Message message, @Headers Map&lt;String, Object&gt; headers, Channel channel) throws Exception &#123; channel.txSelect(); boolean success = delayHandle(message); if (success) &#123; channel.basicAck((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; else &#123; channel.basicReject((long) headers.get(AmqpHeaders.DELIVERY_TAG), false); &#125; channel.txCommit(); &#125; /** * 消费延时消息方法 * * @param message */ private boolean delayHandle(Message message) &#123; MessageProperties messageProperties = message.getMessageProperties(); Map&lt;String, Object&gt; headers = messageProperties.getHeaders(); try &#123; // 判定是否要多次延时 long nextDelay = (long) headers.get(\"next_delay\"); if (nextDelay &gt; 0) &#123; messageSenderSV.sendAgain(message, nextDelay); return true; &#125; byte[] body = message.getBody(); if (body != null &amp;&amp; body.length &gt; 0) &#123; //判定为一个有效消息，进行执行 try (ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(body));) &#123; AbstractDelayedTask abstractDelayedTask = (AbstractDelayedTask) ois.readObject(); LOG.info(\"执行延时任务 [ &#123;&#125; ],消息ID为[ &#123;&#125; ],参数为:&#123;&#125;\", abstractDelayedTask.getDescribe(), abstractDelayedTask.getUuid(), JSONObject.toJSONString(headers)); abstractDelayedTask.excute(); &#125; &#125; return true; &#125; catch (Throwable e) &#123; if (e instanceof BusinessException) &#123; LOG.info(e.getMessage()); return true; &#125; else &#123; LOG.error(\"消费异常:&#123;&#125;\", ExceptionUtil.getExceptionMessage(e)); return false; &#125; &#125; &#125; /** * 手动消费延时消息 */ public void manualConsumptionDelay() &#123; rabbitTemplate.receiveAndReply(delayDeadQueue, (payload) -&gt; &#123; AbstractDelayedTask abstractDelayedTask = (AbstractDelayedTask) payload; try &#123; abstractDelayedTask.excute(); &#125; catch (Exception e) &#123; LOG.error(ExceptionUtil.getExceptionMessage(e)); throw new AmqpException(\"延时消息异常\"); &#125; return true; &#125;); &#125;&#125; 9.延时任务抽象类定义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 延时队列Task * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:34:43 */@Datapublic abstract class AbstractDelayedTask implements Serializable &#123; protected static final Logger LOG = LoggerFactory.getLogger(AbstractDelayedTask.class); /** * 任务唯一性标志 */ private String uuid = UUID.uuid(); /** * 任务描述 */ private String describe; /** * 多久后执行，单位毫秒 */ private Long delay; /** * 方法需要执行的参数 */ private JSONObject params; public AbstractDelayedTask(String describe, long delay, JSONObject params) &#123; this.describe = describe; this.delay = delay; this.params = params; &#125; /** * 执行任务 */ public void excute() throws Exception &#123; LOG.info(\"执行延时任务开始===========》&#123;&#125;\", describe); this.run(); LOG.info(\"执行延时任务结束===========》&#123;&#125;\", describe); &#125; public abstract void run() throws Exception;&#125; 使用方式 12345//15分钟未支付取消订单操作JSONObject params = new JSONObject();params.put(\"id\",\"订单ID\");UnPayCancelOrderTask unPayCancelOrderTask = new UnPayCancelOrderTask(\"下单后不支付自动取消订单\", TimeUnit.MINUTES.toMillis(15), params);messageSenderSV.sendDelayTask(unPayCancelOrderTask);","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://kanchai.club/tags/rabbitMQ/"}]},{"title":"基于注解的Redis分布式锁","slug":"基于注解的Redis分布式锁","date":"2020-03-17T15:36:46.103Z","updated":"2020-03-17T15:34:34.000Z","comments":true,"path":"2020/03/17/基于注解的Redis分布式锁/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂…………","text":"基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂………… 为什么使用基于注解的方式？ 基于之前用redis的lua脚本来实现安全的分布式锁,发现代码是加锁虽然灵活，但是非常的不便捷。每次需要加锁的时候，都要写出非常多的重复性代码。遂考虑利用AOP的方式，完成这一重复性的工作。在没利用注解之前加锁方式如下,基本每次都要这样写 123456789101112// 会话IDString uuid = UUID.uuid();try &#123; boolean getLock = RedisLockUtil.tryGetDistributedLock(key, uuid, 5000); if (getLock) &#123; //如果获取锁，执行业务代码 // todo &#125;&#125; finally &#123; RedisLockUtil.releaseDistributedLock(key, uuid);&#125; 基于注解的使用放入如下，比较便捷 12345@Locker(key &#x3D; RedisKeyEnum.POOL_ORDER_LOCK, paramExp &#x3D; &quot;0&quot;, noGetMsg &#x3D; &quot;老铁来晚了!&quot;)public GrabAndAnswerVo grabOrderAnswer(String orderId, RedisKeyEnum poolType, User currentUser) &#123; Long workId &#x3D; orderExist(poolType, orderId); return doctorGrabOrderAnswer(poolType, orderId, currentUser);&#125; 下面介绍以下代码 首先AOP的使用方式我定义为利用注解来判断是否需要加锁，类似事务的方式，我们定义一个Locker注解,这个注解的功能可以看代码; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 锁注解 * * @author 625 */@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Locker &#123; /** * 要锁定的Key * * @return */ RedisKeyEnum key(); /** * 要锁定的参数 * 格式: * 0 表示一个参数toString * 0?payOrder 表示一个参数toString，且额外拼接锁定的Key为payOrder * 0#name 表示第一个参数的name字段 * 0#name?payOrder 表示第一个参数的name字段，且额外拼接锁定的Key为payOrder * 0#name+1#name?payOrder 表示第一个参数的name字段+第二个参数的name字段，且额外拼接锁定的Key为payOrder * * @return */ String paramExp(); /** * 业务超时自动释放锁的时间,应该大于正常业务执行时间 * * @return */ long expireTime() default 10000; /** * 最小持有锁的时间 * * @return */ long limitTime() default 0; /** * 是否持续竞争锁，是则阻塞方法直至获取锁，或者达到最大竞争次数释放锁 * * @return */ boolean continueGet() default false; /** * 最大竞争次数。默认0不限次 * * @return */ int maxGetNum() default 0; /** * 拿不到锁，异常返回信息 * * @return */ String noGetMsg() default \"未获取锁\";&#125; 实现AOP的拦截规则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&#x2F;** * 锁AOP拦截规则 *&#x2F;@Aspect@Componentpublic class LockerAspect &#123; private static Logger LOGGER &#x3D; LoggerFactory.getLogger(LockerAspect.class); @Pointcut(&quot;@annotation(com.ym.common.utils.annotation.Locker)&quot;) public void pointcut() &#123; &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint joinPoint) &#123; Object proceed &#x3D; null; long startTime &#x3D; System.currentTimeMillis(); Locker locker &#x3D; getAnnotation(joinPoint, Locker.class); Object[] args &#x3D; joinPoint.getArgs(); &#x2F;&#x2F; 最大尝试次数 int maxGetNum &#x3D; locker.maxGetNum(); &#x2F;&#x2F; 会话标志 String uuid &#x3D; UUID.uuid(); &#x2F;&#x2F; 锁key String lockFiled &#x3D; getLockFiled(args, locker.paramExp()); String lockKey &#x3D; RedisKeyUtil.keyBuilder(locker.key(), lockFiled); &#x2F;&#x2F; 过期时间 long expireTime &#x3D; locker.expireTime(); boolean lock &#x3D; RedisLockUtil.tryGetDistributedLock(lockKey, uuid, expireTime); int getNum &#x3D; 0; while (!lock &amp;&amp; locker.continueGet() &amp;&amp; (maxGetNum &#x3D;&#x3D; 0 || getNum &lt; maxGetNum)) &#123; &#x2F;&#x2F; 如果获取失败，且持续获取，且尝试次数小于最大次数 Threads.sleep(100); lock &#x3D; RedisLockUtil.tryGetDistributedLock(lockKey, uuid, expireTime); &#125; if (!lock) &#123; throw new BusinessException(locker.noGetMsg()); &#125; &#x2F;&#x2F; -------------------------------before------------------------- try &#123; proceed &#x3D; joinPoint.proceed(); &#x2F;&#x2F; -------------------------------after------------------------- &#x2F;&#x2F; 如果业务时间小于最小持有锁时间，休眠一会 long sleepTime &#x3D; locker.limitTime() - (System.currentTimeMillis() - startTime); if (sleepTime &gt; 0) &#123; Threads.sleep(sleepTime); &#125; &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 释放锁 RedisLockUtil.releaseDistributedLock(lockKey, uuid); &#125; return proceed; &#125; &#x2F;** * 根据表达式获取要锁的字段 * * @param args * @param expression 表达式 * @return *&#x2F; private String getLockFiled(Object[] args, String expression) &#123; if (args &#x3D;&#x3D; null || args.length &#x3D;&#x3D; 0 || StringUtils.isBlank(expression)) &#123; throw new UnsupportedOperationException(&quot;Locker所在方法参数为空! 请使用代码锁&quot;); &#125; String[] extraParams &#x3D; expression.split(&quot;\\\\?&quot;); String extraKey &#x3D; null; if (extraParams.length &gt; 1) &#123; extraKey &#x3D; extraParams[1]; expression &#x3D; extraParams[0]; &#125; String[] commboExpression &#x3D; expression.split(&quot;\\\\+&quot;); StringBuilder field &#x3D; new StringBuilder(); for (String commbo : commboExpression) &#123; String[] split &#x3D; commbo.split(&quot;#&quot;); int argsNum &#x3D; 0; try &#123; if (split.length &#x3D;&#x3D; 1) &#123; argsNum &#x3D; Integer.parseInt(split[0]); field.append(String.valueOf(args[argsNum])); &#125; else &#123; argsNum &#x3D; Integer.parseInt(split[0]); Object fieldValue &#x3D; ReflectUtils.getFieldValue(args[argsNum], split[1]); field.append(String.valueOf(fieldValue)); &#125; &#125; catch (Exception e) &#123; throw new UnsupportedOperationException(&quot;Locker表达式paramExp不正确！&quot;); &#125; &#125; if (extraKey !&#x3D; null) &#123; field.append(extraKey); &#125; return field.toString(); &#125; &#x2F;** * 是否存在注解，如果存在就获取 *&#x2F; private &lt;T&gt; T getAnnotation(JoinPoint joinPoint, Class&lt;? extends Annotation&gt; t) &#123; Signature signature &#x3D; joinPoint.getSignature(); MethodSignature methodSignature &#x3D; (MethodSignature) signature; Method method &#x3D; methodSignature.getMethod(); if (method !&#x3D; null) &#123; return (T) method.getAnnotation(t); &#125; return null; &#125;&#125;","categories":[{"name":"分布式锁","slug":"分布式锁","permalink":"https://kanchai.club/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}],"tags":[{"name":"Redis锁","slug":"Redis锁","permalink":"https://kanchai.club/tags/Redis%E9%94%81/"},{"name":"分布式","slug":"分布式","permalink":"https://kanchai.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Java根据文件流准确判定文件类型","slug":"Java根据文件流准确判定文件类型","date":"2020-03-17T15:36:45.980Z","updated":"2020-03-17T15:34:34.000Z","comments":true,"path":"2020/03/17/Java根据文件流准确判定文件类型/","link":"","permalink":"https://kanchai.club/2020/03/17/Java%E6%A0%B9%E6%8D%AE%E6%96%87%E4%BB%B6%E6%B5%81%E5%87%86%E7%A1%AE%E5%88%A4%E5%AE%9A%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B/","excerpt":"判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀…..","text":"判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀….. 判断文件类型通常可以简单的通过文件的后缀判定，如123.MP3,则判定文件的格式是MP3可播放文件。但是到底能不能播放，其实并不是通过后缀判断的。而是通过文件本身的二进制数据，软件来解析到底一定的目的。话不多说上代码，通过判断文件流的前几个字节，来判断文件的类型。可以自己添加新的类型，类型不一定对，可以自己调试调整一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161package com.ym.common.utils.qiniu;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import java.io.InputStream;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Map.Entry;public class FileTypeHelper &#123; public final static Map&lt;String, String&gt; FILE_TYPE_MAP = new HashMap&lt;String, String&gt;(); private FileTypeHelper() &#123; &#125; static &#123; //初始化文件类型信息 getAllFileType(); &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getAllFileType,常见文件头信息]&lt;/p&gt; * * @author:[shixing_11@sina.com] */ private static void getAllFileType() &#123; FILE_TYPE_MAP.put(\"jpg\", \"FFD8FF\"); //JPEG (jpg) FILE_TYPE_MAP.put(\"png\", \"89504E47\"); //PNG (png) FILE_TYPE_MAP.put(\"gif\", \"47494638\"); //GIF (gif) FILE_TYPE_MAP.put(\"tif\", \"49492A00\"); //TIFF (tif) FILE_TYPE_MAP.put(\"bmp\", \"424D\"); //Windows Bitmap (bmp) FILE_TYPE_MAP.put(\"dwg\", \"41433130\"); //CAD (dwg) FILE_TYPE_MAP.put(\"html\", \"68746D6C3E\"); //HTML (html) FILE_TYPE_MAP.put(\"rtf\", \"7B5C727466\"); //Rich Text Format (rtf) FILE_TYPE_MAP.put(\"xml\", \"3C3F786D6C\"); FILE_TYPE_MAP.put(\"zip\", \"504B03041400000008005959104FFE4A759FF1\"); FILE_TYPE_MAP.put(\"rar\", \"52617221\"); FILE_TYPE_MAP.put(\"psd\", \"38425053\"); //Photoshop (psd) FILE_TYPE_MAP.put(\"eml\", \"44656C69766572792D646174653A\"); //Email [thorough only] (eml) FILE_TYPE_MAP.put(\"dbx\", \"CFAD12FEC5FD746F\"); //Outlook Express (dbx) FILE_TYPE_MAP.put(\"pst\", \"2142444E\"); //Outlook (pst) FILE_TYPE_MAP.put(\"xls\", \"D0CF11E0A1B11AE1000000000000000000000000000000003B\"); //MS Word FILE_TYPE_MAP.put(\"xlsx\", \"504B03041400060008000000210097454E26A\"); //MS Word FILE_TYPE_MAP.put(\"docx\", \"504B030414000600080000002100DFA4D26C5A\"); //MS Excel 注意：word 和 excel的文件头一样 FILE_TYPE_MAP.put(\"pptx\", \"504B030414000600080000002100DFCC18F5AD\"); FILE_TYPE_MAP.put(\"doc\", \"D0CF11E0A1B11AE1000000000000000000000000000000003E000300FEFF090006000000000000000000000001\"); FILE_TYPE_MAP.put(\"ppt\", \"D0CF11E0A1B11AE1000000000000000000000000000000003E000300FEFF090006000000000000000000000003\"); FILE_TYPE_MAP.put(\"mdb\", \"5374616E64617264204A\"); //MS Access (mdb) FILE_TYPE_MAP.put(\"wpd\", \"FF575043\"); //WordPerfect (wpd) FILE_TYPE_MAP.put(\"eps\", \"252150532D41646F6265\"); FILE_TYPE_MAP.put(\"ps\", \"252150532D41646F6265\"); FILE_TYPE_MAP.put(\"pdf\", \"255044462D312E\"); //Adobe Acrobat (pdf) FILE_TYPE_MAP.put(\"qdf\", \"AC9EBD8F\"); //Quicken (qdf) FILE_TYPE_MAP.put(\"pwl\", \"E3828596\"); //Windows Password (pwl) FILE_TYPE_MAP.put(\"wav\", \"57415645,52494646\"); //Wave (wav) FILE_TYPE_MAP.put(\"avi\", \"41564920\"); FILE_TYPE_MAP.put(\"ram\", \"2E7261FD\"); //Real Audio (ram) FILE_TYPE_MAP.put(\"rm\", \"2E524D46\"); //Real Media (rm) FILE_TYPE_MAP.put(\"mpg\", \"000001BA\"); // FILE_TYPE_MAP.put(\"mov\", \"6D6F6F76\"); //Quicktime (mov) FILE_TYPE_MAP.put(\"asf\", \"3026B2758E66CF11\"); //Windows Media (asf) FILE_TYPE_MAP.put(\"mid\", \"4D546864\"); //MIDI (mid) FILE_TYPE_MAP.put(\"aac\", \"FFF15C4013\"); //aac语音 FILE_TYPE_MAP.put(\"mp3\", \"FFE368\"); //mp3 FILE_TYPE_MAP.put(\"webm\", \"1A45DFA39F42868101\"); //webm FILE_TYPE_MAP.put(\"m4a\", \"0000001C667479704D344120000000004D3441206D70\"); //webm &#125; /** * 根据文件判定流类型 * * @param file * @return */ public final static String getFileTypeByFile(File file) &#123; InputStream is = null; try &#123; is = new FileInputStream(file); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; return getFileTypeByStream(is); &#125; /** * 根据流判定文件类型 * * @param is * @return */ public final static String getFileTypeByStream(InputStream is) &#123; String filetype = null; byte[] b = new byte[50]; try &#123; is.read(b); filetype = getFileTypeByByte(b); is.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return filetype; &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getFileTypeByStream]&lt;/p&gt; * * @param b * @return fileType * @author:[shixing_11@sina.com] */ public final static String getFileTypeByByte(byte[] b) &#123; String filetypeHex = String.valueOf(getFileHexString(b)); Iterator&lt;Entry&lt;String, String&gt;&gt; entryiterator = FILE_TYPE_MAP.entrySet().iterator(); while (entryiterator.hasNext()) &#123; Entry&lt;String, String&gt; entry = entryiterator.next(); String fileTypeHexValue = entry.getValue(); String[] split = fileTypeHexValue.split(\",\"); for (String sufix : split) &#123; if (filetypeHex.toUpperCase().startsWith(sufix)) &#123; return entry.getKey(); &#125; &#125; &#125; return \"txt\"; &#125; /** * Created on 2010-7-1 * &lt;p&gt;Discription:[getFileHexString]&lt;/p&gt; * * @param b * @return fileTypeHex * @author:[shixing_11@sina.com] */ private final static String getFileHexString(byte[] b) &#123; StringBuilder stringBuilder = new StringBuilder(); int byteLength = 50; if (b == null || b.length &lt;= 0) &#123; return null; &#125; else if (b.length &lt; byteLength) &#123; byteLength = b.length; &#125; for (int i = 0; i &lt; byteLength; i++) &#123; int v = b[i] &amp; 0xFF; String hv = Integer.toHexString(v); if (hv.length() &lt; 2) &#123; stringBuilder.append(0); &#125; stringBuilder.append(hv); &#125; return stringBuilder.toString(); &#125;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"文件类型判断","slug":"文件类型判断","permalink":"https://kanchai.club/tags/%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD/"}]},{"title":"一些常用的linux基础命令","slug":"Linux命令记录","date":"2020-03-17T15:36:45.859Z","updated":"2020-03-17T15:34:47.000Z","comments":true,"path":"2020/03/17/Linux命令记录/","link":"","permalink":"https://kanchai.club/2020/03/17/Linux%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"记录一些日常用到的基础命令,防止重复去百度搜索,主要是Centos中,个人记不住的一些命令,ls什么的肯定没有记录","text":"记录一些日常用到的基础命令,防止重复去百度搜索,主要是Centos中,个人记不住的一些命令,ls什么的肯定没有记录 端口 端口占用情况 12&gt; lsof -i tcp:8000 &gt; netstat -tunlp |grep 8000 列出所有端口 1&gt; netstat -ntlp 根据程序名找进程 1&gt; ps axu |grep 程序名&#x2F;端口号&#x2F;IP等等 查询指定端口是否已开 1&gt; firewall-cmd --query-port&#x3D;666&#x2F;tcp 查看所有开放的端口 1&gt; iptables -t filter -L INPUT 防火墙 查看防火墙状态 1&gt; systemctl status firewalld 开启防火墙 123456&gt; systemctl start firewalld&gt; service firewalld start &gt; ##若遇到无法开启,先用：&gt; systemctl unmask firewalld.service &gt; 然后：&gt; systemctl start firewalld.service 关闭防火墙 1&gt; systemctl stop firewalld 对外开放端口 123456&gt; firewall-cmd --zone&#x3D;public --add-port&#x3D;8080&#x2F;tcp --permanent&gt; iptables -I INPUT -p tcp --dport 9150 -j ACCEPT&gt; ##或者&gt; sudo vi sysconfig&#x2F;iptables&gt; ##然后&gt; -A INPUT -m state --state NEW -m tcp -p tcp --dport 9150 -j ACCEPT 查看对外开放的端口 1&gt; iptables -t filter -L INPUT 重启防火墙 12&gt; firewall-cmd --reload systemctl &gt; restart firewalld.service； 关闭指定端口 1&gt; firewall-cmd --permanent --remove-port&#x3D;123&#x2F;tcp 查看文件内容 关键词查找 12&gt; ##执行的是返回的内容 &gt; grep 正则 文件目录 关键词查找及随后的目录中搜索字符串 1&gt; grep -R 正则 文件目录 jvm相关 查看JAVA进程并输出JVM参数 1&gt; jps -v dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名 1&gt; jmap -dump:live,format&#x3D;b,file&#x3D;dump.hprof 28920 查看堆的使用情况 1&gt; jmap -heap 28920 查看堆中的对象信息 1&gt; jmap -histo:live 28920 | more 查看当前程序的线程快照 1&gt; jstack -l 11494|more 实时查看调整Jvm参数 1&gt; jinfo -flag 11494 系统信息查看 显示电脑以及操作系统的相关信息1&gt; uname -a 正在运行的内核版本1&gt; cat &#x2F;proc&#x2F;version 发行版本信息1&gt; cat &#x2F;etc&#x2F;issue","categories":[{"name":"Linux","slug":"Linux","permalink":"https://kanchai.club/categories/Linux/"}],"tags":[{"name":"基础命令","slug":"基础命令","permalink":"https://kanchai.club/tags/%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"name":"Jvm","slug":"Jvm","permalink":"https://kanchai.club/tags/Jvm/"}]},{"title":"基于Delayed实现一个定时延时任务","slug":"实现一个延时任务","date":"2020-03-17T15:36:45.731Z","updated":"2020-03-17T15:34:54.000Z","comments":true,"path":"2020/03/17/实现一个延时任务/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"在spring中加入一个守护线程+延时队列来处理一些延时任务.比如用户注册后5分钟后发送短信.等等","text":"在spring中加入一个守护线程+延时队列来处理一些延时任务.比如用户注册后5分钟后发送短信.等等 延时任务Bean的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package com.ym.common.utils;import java.util.concurrent.Delayed;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;/** * 延时队列Task * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:34:43 */public class DelayedTask&lt;T extends Runnable&gt; implements Delayed &#123; /** * 任务名称 */ private final String name; /** * 到期时间 */ private final long time; /** * 问题对象 */ private final T task; private static final AtomicLong atomic = new AtomicLong(0); private final long n; public DelayedTask(long timeout, T t, String name) &#123; this.time = System.nanoTime() + timeout; this.task = t; this.name = name; this.n = atomic.getAndIncrement(); &#125; /** * 返回与此对象相关的剩余延迟时间，以给定的时间单位表示 */ @Override public long getDelay(TimeUnit unit) &#123; return unit.convert(this.time - System.nanoTime(), TimeUnit.NANOSECONDS); &#125; @Override public int compareTo(Delayed other) &#123; // TODO Auto-generated method stub if (other == this) // compare zero ONLY if same object return 0; if (other instanceof DelayedTask) &#123; DelayedTask&lt;Runnable&gt; x = (DelayedTask) other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (getN() &lt; x.getN()) return -1; else return 1; &#125; long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS)); return (d == 0) ? 0 : ((d &lt; 0) ? -1 : 1); &#125; public T getTask() &#123; return this.task; &#125; @Override public int hashCode() &#123; return task.hashCode(); &#125; @Override public boolean equals(Object object) &#123; if (object instanceof DelayedTask) &#123; return object.hashCode() == hashCode() ? true : false; &#125; return false; &#125; public String getName() &#123; return name; &#125; public long getN() &#123; return n; &#125;&#125; Spring容器Bean的定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144package com.ym.web.bean;import com.ym.common.utils.DelayedTask;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import java.util.concurrent.DelayQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;/** * 延时队列任务管理 * * @author 李涛 * @version 创建时间：2018年6月16日 下午3:35:39 */@Componentpublic class TaskQueueBean &#123; private static final Logger LOG = LoggerFactory.getLogger(TaskQueueBean.class); private static volatile boolean started = false; private TaskQueueBean() &#123; &#125; private static class LazyHolder &#123; private static TaskQueueBean taskQueueDaemonThread = new TaskQueueBean(); &#125; public static TaskQueueBean getInstance() &#123; return LazyHolder.taskQueueDaemonThread; &#125; /** * 执行任务的线程 */ private ExecutorService executor = null; /** * 创建一个最初为空的新 DelayQueue */ private DelayQueue&lt;DelayedTask&lt;Runnable&gt;&gt; queue = null; /** * 守护线程 */ private Thread daemonThread; /** * 初始化守护线程 */ @PostConstruct public synchronized void start() &#123; // 1.初始化线程池 if (!started) &#123; started = true; executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); queue = new DelayQueue&lt;&gt;(); // 2.判断是否启动 if (daemonThread != null &amp;&amp; daemonThread.isInterrupted()) &#123; daemonThread.start(); return; &#125; &#125; daemonThread = new Thread() &#123; public void run() &#123; try &#123; execute(); &#125; catch (InterruptedException e) &#123; daemonThread.interrupt(); &#125; &#125; &#125;; daemonThread.setDaemon(true); daemonThread.setName(\"DelayedTask\"); daemonThread.start(); LOG.info(\"~~~~~~~~~~~~~~~~~~~~延时任务开启~~~~~~~~~~~~~~~~~~~~~~~~~\"); &#125; private void execute() throws InterruptedException &#123; LOG.info(\"[ task start &#123;&#125; ]:\", System.currentTimeMillis()); while (started) &#123; // 从延迟队列中取值,如果没有对象过期则队列一直等待， DelayedTask&lt;Runnable&gt; t1 = queue.take(); if (t1 != null) &#123; // 修改问题的状态 Runnable task = t1.getTask(); if (task == null) &#123; continue; &#125; executor.execute(task); LOG.info(\"[ &#123;&#125; task &#123;&#125; execute ] \", t1.getN(), t1.getName()); &#125; &#125; &#125; /** * 添加任务， time 延迟时间 task 任务 用户为问题设置延迟时间 */ public void put(long time, Runnable task, String taskName) &#123; if (!started) &#123; throw new UnsupportedOperationException(\"请先启动taskQueneBean！\"); &#125; // 转换成ns long nanoTime = TimeUnit.NANOSECONDS.convert(time, TimeUnit.MILLISECONDS); // 创建一个任务 DelayedTask&lt;Runnable&gt; k = new DelayedTask&lt;Runnable&gt;(nanoTime, task, taskName); // 将任务放在延迟的队列中 queue.put(k); LOG.info(\"新任务：&#123;&#125;加入队列，当前队列任务数量：&#123;&#125;\", taskName, queue.size()); &#125; /** * 结束 * * @param task */ public boolean endTask(DelayedTask&lt;Runnable&gt; task) &#123; if (!started) &#123; throw new UnsupportedOperationException(\"请先启动taskQueneBean！\"); &#125; return queue.remove(task); &#125; /** * 手动关闭任务 */ public synchronized void stop() &#123; if (started) &#123; LOG.info(\"shutdown TaskQueueBean\"); started = false; daemonThread.interrupt(); executor.shutdown(); daemonThread = null; queue = null; &#125; &#125;&#125;`","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"},{"name":"Spring","slug":"Spring","permalink":"https://kanchai.club/tags/Spring/"}]},{"title":"实现基于Redis的lua的分布式锁","slug":"实现基于Redis的lua的分布式锁","date":"2020-03-17T15:36:45.602Z","updated":"2020-03-17T15:34:57.000Z","comments":true,"path":"2020/03/17/实现基于Redis的lua的分布式锁/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERedis%E7%9A%84lua%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"基于目前有需求需要实现一个分布式锁,用zk的话由于项目本身暂时没有用到zk,所以暂不考虑zk锁.用redis的lua脚本来实现安全的分布式锁,保证指令的原子性.","text":"基于目前有需求需要实现一个分布式锁,用zk的话由于项目本身暂时没有用到zk,所以暂不考虑zk锁.用redis的lua脚本来实现安全的分布式锁,保证指令的原子性. 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.ym.common.utils.redis;import com.ym.common.utils.Sha1Util;import com.ym.common.utils.spring.SpringUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.script.RedisScript;import java.util.Collections;/** * 基于redis lua分布式锁 * * @author: 李涛 * @version: 2019年05月08日 16:15 */public class RedisLockUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisLockUtil.class); /** * 成功标识 */ private static final Long SUCCESS = 1L; /** * 加锁lua脚本,不可重入,reqId只是为了解锁使用,代表当前线程在使用资源,给UUID比较好 */ private static final String SCRIPT_LOCK = \"if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then redis.call('pexpire', KEYS[1], ARGV[2]) return 1 else return 0 end\"; /** * 解锁lua脚本 */ private static final String SCRIPT_UNLOCK = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; /** * 加锁脚本sha1值 */ private static final String SCRIPT_LOCK_SHA1 = Sha1Util.encrypt(SCRIPT_LOCK); /** * 解锁脚本sha1值 */ private static final String SCRIPT_UNLOCK_SHA1 = Sha1Util.encrypt(SCRIPT_UNLOCK); /** * 内部持有模板 */ private static final RedisTemplate redisTemplate = (RedisTemplate) SpringUtil.getObject(\"redisTemplate\"); /** * 尝试获取分布式锁 * * @param lockKey 锁 * @param requestId 请求标识,唯一ID * @param expireTimeMilliseconds 超期时间，多少毫秒后这把锁自动释放 * @return 返回true表示拿到锁 */ public static boolean tryGetDistributedLock(String lockKey, String requestId, int expireTimeMilliseconds) &#123; LOGGER.info(\"[&#123;&#125;]尝试获取[&#123;&#125;]锁,超时时间为:&#123;&#125;毫秒\", requestId, lockKey, expireTimeMilliseconds); /** * 脚本设置 */ RedisScript&lt;Long&gt; redisScript = new RedisScript&lt;Long&gt;() &#123; @Override public String getSha1() &#123; return SCRIPT_LOCK_SHA1; &#125; @Override public Class&lt;Long&gt; getResultType() &#123; return Long.class; &#125; @Override public String getScriptAsString() &#123; return SCRIPT_LOCK; &#125; &#125;; Object result = redisTemplate.execute( redisScript,// lua脚本 Collections.singletonList(lockKey),// KEYS[1] requestId, // ARGV[1] expireTimeMilliseconds // ARGV[2] ); boolean b = SUCCESS.equals(result); LOGGER.info(\"释放结果:\", b); return b; &#125; /** * 释放分布式锁 * * @param lockKey 锁 * @param requestId 请求标识 * @return 返回true表示释放锁成功 */ public static boolean releaseDistributedLock(String lockKey, String requestId) &#123; LOGGER.info(\"[&#123;&#125;]释放锁[&#123;&#125;]锁\", requestId, lockKey); /** * lua脚本 */ RedisScript&lt;Long&gt; redisScript = new RedisScript&lt;Long&gt;() &#123; @Override public String getSha1() &#123; return SCRIPT_UNLOCK_SHA1; &#125; @Override public Class&lt;Long&gt; getResultType() &#123; return Long.class; &#125; @Override public String getScriptAsString() &#123; return SCRIPT_UNLOCK; &#125; &#125;; Object result = redisTemplate.execute( redisScript, Collections.singletonList(lockKey), requestId ); boolean b = SUCCESS.equals(result); LOGGER.info(\"释放结果:\", b); return b; &#125;&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/categories/Redis/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://kanchai.club/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/tags/Redis/"}]},{"title":"上传自己的git项目到maven","slug":"上传自己的git项目到maven","date":"2020-03-17T15:36:45.470Z","updated":"2020-03-17T15:35:02.000Z","comments":true,"path":"2020/03/17/上传自己的git项目到maven/","link":"","permalink":"https://kanchai.club/2020/03/17/%E4%B8%8A%E4%BC%A0%E8%87%AA%E5%B7%B1%E7%9A%84git%E9%A1%B9%E7%9B%AE%E5%88%B0maven/","excerpt":"上传自己的git项目到maven，结合两位博客成功上传。","text":"上传自己的git项目到maven，结合两位博客成功上传。 感谢两位博主，地址分别为 https://www.jianshu.com/p/8c3d7fb09bce https://blog.csdn.net/sinat_23290725/article/details/85018092","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://kanchai.club/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://kanchai.club/tags/maven/"}]},{"title":"mongo搭建副本集","slug":"mongo搭建副本集","date":"2020-03-17T15:36:45.353Z","updated":"2020-03-17T15:35:06.000Z","comments":true,"path":"2020/03/17/mongo搭建副本集/","link":"","permalink":"https://kanchai.club/2020/03/17/mongo%E6%90%AD%E5%BB%BA%E5%89%AF%E6%9C%AC%E9%9B%86/","excerpt":"搭建副本集的作用和其他数据库思路大致一样，主从配置，仲裁节点，也就是说最起码要保证3个节点….","text":"搭建副本集的作用和其他数据库思路大致一样，主从配置，仲裁节点，也就是说最起码要保证3个节点…. Replica Set介绍 中文翻译叫做副本集,其实简单来说就是集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。 搭建集群 般情况下不会把数据目录建立在mongodb的解压目录下，不过这里方便起见，就建在mongodb解压目录下吧。 1234mkdir -p &#x2F;mongodb&#x2F;data&#x2F;master mkdir -p &#x2F;mongodb&#x2F;data&#x2F;slaver mkdir -p &#x2F;mongodb&#x2F;data&#x2F;arbiter #三个目录分别对应主，备，仲裁节点 建立配置文件,由于配置比较多，所以我们将配置写到文件里，以文件的方式启动，以下配置文件仔细看可以说是只有端口不同，搭建的伪集群。 123456789101112131415161718192021222324#master.conf 主节点配置#数据存放目录dbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;master #日志存放路径logpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;master.log#进程文件pidfilepath&#x3D;&#x2F;mongodb&#x2F;master.pid#为每一个数据库按照数据库名建立文件夹存放directoryperdb&#x3D;true#以追加的方式记录日志logappend&#x3D;true#replica set的名字replSet&#x3D;testrs#绑定暴露的ID地址bind_ip&#x3D;127.0.0.1#端口port&#x3D;27017#mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%oplogSize&#x3D;10000#以后台方式运行进程fork&#x3D;true#不预先分配存储noprealloc&#x3D;true 12345678910111213#master.conf 副本节点配置#slaver.confdbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;slaverlogpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;slaver.logpidfilepath&#x3D;&#x2F;mongodb&#x2F;slaver.piddirectoryperdb&#x3D;truelogappend&#x3D;truereplSet&#x3D;testrsbind_ip&#x3D;127.0.0.1port&#x3D;27018oplogSize&#x3D;10000fork&#x3D;truenoprealloc&#x3D;true 123456789101112#arbiter.conf 仲裁节点配置dbpath&#x3D;&#x2F;mongodb&#x2F;data&#x2F;arbiterlogpath&#x3D;&#x2F;mongodb&#x2F;log&#x2F;arbiter.logpidfilepath&#x3D;&#x2F;mongodb&#x2F;arbiter.piddirectoryperdb&#x3D;truelogappend&#x3D;truereplSet&#x3D;testrsbind_ip&#x3D;127.0.0.1port&#x3D;27019oplogSize&#x3D;10000fork&#x3D;truenoprealloc&#x3D;true 启动mongo 123.&#x2F;monood -f master.conf.&#x2F;mongod -f slaver.conf.&#x2F;mongod -f arbiter.conf 开始配置主从、仲裁节点，可以通过客户端连接mongodb，也可以直接在三个节点中选择一个连接mongodb。 12345&gt;.&#x2F;mongo 127.0.0.1:27017 #ip和port是某个节点的地址&gt;use admin&gt;cfg&#x3D;&#123; _id:&quot;testrs&quot;, members:[ &#123;_id:0,host:&#39;127.0.0.1:27017&#39;,priority:2&#125;, &#123;_id:1,host:&#39;127.0.0.1:27017&#39;,priority:1&#125;, &#123;_id:2,host:&#39;127.0.0.1:27017&#39;,arbiterOnly:true&#125;] &#125;;&gt;rs.initiate(cfg) #使配置生效 cfg是可以任意的名字，当然最好不要是mongodb的关键字，conf，config都可以。最外层的_id表示replica set的名字，members里包含的是所有节点的地址以及优先级。优先级最高的即成为主节点，即这里的127.0.0.1:27017。特别注意的是，对于仲裁节点，需要有个特别的配置——arbiterOnly:true。这个千万不能少了，不然主备模式就不能生效。配置的生效时间根据不同的机器配置会有长有短，配置不错的话基本上十几秒内就能生效，有的配置需要一两分钟。如果生效了，执行rs.status()命令会看到如下信息： 1234567891011121314151617181920212223242526272829303132333435363738394041 &#123; &quot;set&quot; : &quot;testrs&quot;, &quot;date&quot; : ISODate(&quot;2013-01-05T02:44:43Z&quot;), &quot;myState&quot; : 1, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;name&quot; : &quot;127.0.0.1:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 200, &quot;optime&quot; : Timestamp(1357285565000, 1), &quot;optimeDate&quot; : ISODate(&quot;2013-01-04T07:46:05Z&quot;), &quot;self&quot; : true &#125;, &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;127.0.0.1:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 200, &quot;optime&quot; : Timestamp(1357285565000, 1), &quot;optimeDate&quot; : ISODate(&quot;2013-01-04T07:46:05Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2013-01-05T02:44:42Z&quot;), &quot;pingMs&quot; : 0 &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;127.0.0.1:27019&quot;, &quot;health&quot; : 1, &quot;state&quot; : 7, &quot;stateStr&quot; : &quot;ARBITER&quot;, &quot;uptime&quot; : 200, &quot;lastHeartbeat&quot; : ISODate(&quot;2013-01-05T02:44:42Z&quot;), &quot;pingMs&quot; : 0 &#125; ], &quot;ok&quot; : 1&#125;如果配置正在生效，其中会包含如下信息,同时可以查看对应节点的日志，发现正在等待别的节点生效或者正在分配数据文件： 1&quot;stateStr&quot; : &quot;RECOVERING&quot; 现在基本上已经完成了集群的所有搭建工作。至于测试工作，可以留给大家自己试试。一个是往主节点插入数据，能从备节点查到之前插入的数据（查询备节点可能会遇到某个问题，可以自己去网上查查看）。二是停掉主节点，备节点能变成主节点提供服务。三是恢复主节点，备节点也能恢复其备的角色，而不是继续充当主的角色。二和三都可以通过rs.status()命令实时查看集群的变化。 转载来源","categories":[{"name":"Mongo","slug":"Mongo","permalink":"https://kanchai.club/categories/Mongo/"}],"tags":[{"name":"mongo集群","slug":"mongo集群","permalink":"https://kanchai.club/tags/mongo%E9%9B%86%E7%BE%A4/"}]},{"title":"IDEA快捷键","slug":"史上最全IDEA快捷键","date":"2020-03-17T15:36:45.229Z","updated":"2020-03-17T15:35:12.000Z","comments":true,"path":"2020/03/17/史上最全IDEA快捷键/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8IDEA%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"IDEA快捷键比较全面的","text":"IDEA快捷键比较全面的 常规 Ctrl+Shift + Enter，语句完成 “！”，否定完成，输入表达式时按 “！”键 Ctrl+E，最近的文件 Ctrl+Shift+E，最近更改的文件 Shift+Click，可以关闭文件 Ctrl+[ OR ]，可以跑到大括号的开头与结尾 Ctrl+F12，可以显示当前文件的结构 Ctrl+F7，可以查询当前元素在当前文件中的引用，然后按 F3 可以选择 Ctrl+N，可以快速打开类 Ctrl+Shift+N，可以快速打开文件 Alt+Q，可以看到当前方法的声明 Ctrl+P，可以显示参数信息 Ctrl+Shift+Insert，可以选择剪贴板内容并插入 Alt+Insert，可以生成构造器/Getter/Setter等 Ctrl+Alt+V，可以引入变量。例如：new String(); 自动导入变量定义 Ctrl+Alt+T，可以把代码包在一个块内，例如：try/catch Ctrl+Enter，导入包，自动修正 Ctrl+Alt+L，格式化代码 Ctrl+Alt+I，将选中的代码进行自动缩进编排，这个功能在编辑 JSP 文件时也可以工作 Ctrl+Alt+O，优化导入的类和包 Ctrl+R，替换文本 Ctrl+F，查找文本 Ctrl+Shift+Space，自动补全代码 Ctrl+空格，代码提示（与系统输入法快捷键冲突） Ctrl+Shift+Alt+N，查找类中的方法或变量 Alt+Shift+C，最近的更改 Alt+Shift+Up/Down，上/下移一行 Shift+F6，重构 - 重命名 Ctrl+X，删除行 Ctrl+D，复制行 Ctrl+/或Ctrl+Shift+/，注释（//或者/**/） Ctrl+J，自动代码（例如：serr） Ctrl+Alt+J，用动态模板环绕 Ctrl+H，显示类结构图（类的继承层次） Ctrl+Q，显示注释文档 Alt+F1，查找代码所在位置 Alt+1，快速打开或隐藏工程面板 Ctrl+Alt+left/right，返回至上次浏览的位置 Alt+left/right，切换代码视图 Alt+Up/Down，在方法间快速移动定位 Ctrl+Shift+Up/Down，向上/下移动语句 F2 或 Shift+F2，高亮错误或警告快速定位 Tab，代码标签输入完成后，按 Tab，生成代码 Ctrl+Shift+F7，高亮显示所有该文本，按 Esc 高亮消失 Alt+F3，逐个往下查找相同文本，并高亮显示 Ctrl+Up/Down，光标中转到第一行或最后一行下 Ctrl+B/Ctrl+Click，快速打开光标处的类或方法（跳转到定义处） Ctrl+Alt+B，跳转到方法实现处 Ctrl+Shift+Backspace，跳转到上次编辑的地方 Ctrl+O，重写方法 Ctrl+Alt+Space，类名自动完成 Ctrl+Alt+Up/Down，快速跳转搜索结果 Ctrl+Shift+J，整合两行 Alt+F8，计算变量值 Ctrl+Shift+V，可以将最近使用的剪贴板内容选择插入到文本 Ctrl+Alt+Shift+V，简单粘贴 Shift+Esc，不仅可以把焦点移到编辑器上，而且还可以隐藏当前（或最后活动的）工具窗口 F12，把焦点从编辑器移到最近使用的工具窗口 Shift+F1，要打开编辑器光标字符处使用的类或者方法 Java 文档的浏览器 Ctrl+W，可以选择单词继而语句继而行继而函数 Ctrl+Shift+W，取消选择光标所在词 Alt+F7，查找整个工程中使用地某一个类、方法或者变量的位置 Ctrl+I，实现方法 Ctrl+Shift+U，大小写转化 Ctrl+Y，删除当前行 Shift+Enter，向下插入新行 psvm/sout，main/System.out.println(); Ctrl+J，查看更多 Ctrl+Shift+F，全局查找 Ctrl+F，查找/Shift+F3，向上查找/F3，向下查找 Ctrl+Shift+S，高级搜索 Ctrl+U，转到父类 Ctrl+Alt+S，打开设置对话框 Alt+Shift+Inert，开启/关闭列选择模式 Ctrl+Alt+Shift+S，打开当前项目/模块属性 Ctrl+G，定位行 Alt+Home，跳转到导航栏 Ctrl+Enter，上插一行 Ctrl+Backspace，按单词删除 Ctrl+”+/-“，当前方法展开、折叠 Ctrl+Shift+”+/-“，全部展开、折叠 调试部分、编译 Ctrl+F2，停止 Alt+Shift+F9，选择 Debug Alt+Shift+F10，选择 Run Ctrl+Shift+F9，编译 Ctrl+Shift+F10，运行 Ctrl+Shift+F8，查看断点 F8，步过 F7，步入 Shift+F7，智能步入 Shift+F8，步出 Alt+Shift+F8，强制步过 Alt+Shift+F7，强制步入 Alt+F9，运行至光标处 Ctrl+Alt+F9，强制运行至光标处 F9，恢复程序 Alt+F10，定位到断点 Ctrl+F8，切换行断点 Ctrl+F9，生成项目 Alt+1，项目 Alt+2，收藏 Alt+6，TODO Alt+7，结构 Ctrl+Shift+C，复制路径 Ctrl+Alt+Shift+C，复制引用，必须选择类名 Ctrl+Alt+Y，同步 Ctrl+~，快速切换方案（界面外观、代码风格、快捷键映射等菜单） Shift+F12，还原默认布局 Ctrl+Shift+F12，隐藏/恢复所有窗口 Ctrl+F4，关闭 Ctrl+Shift+F4，关闭活动选项卡 Ctrl+Tab，转到下一个拆分器 Ctrl+Shift+Tab，转到上一个拆分器 重构 Ctrl+Alt+Shift+T，弹出重构菜单 Shift+F6，重命名 F6，移动 F5，复制 Alt+Delete，安全删除 Ctrl+Alt+N，内联 查找 Ctrl+F，查找 Ctrl+R，替换 F3，查找下一个 Shift+F3，查找上一个 Ctrl+Shift+F，在路径中查找 Ctrl+Shift+R，在路径中替换 Ctrl+Shift+S，搜索结构 Ctrl+Shift+M，替换结构 Alt+F7，查找用法 Ctrl+Alt+F7，显示用法 Ctrl+F7，在文件中查找用法 Ctrl+Shift+F7，在文件中高亮显示用法 VCS Alt+~，VCS 操作菜单 Ctrl+K，提交更改 Ctrl+T，更新项目 Ctrl+Alt+Shift+D，显示变化","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://kanchai.club/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"IDEA快捷键","slug":"IDEA快捷键","permalink":"https://kanchai.club/tags/IDEA%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"Java实现天平秤秤球？","slug":"Java实现天平秤球","date":"2020-03-17T15:36:45.109Z","updated":"2020-03-17T15:35:16.000Z","comments":true,"path":"2020/03/17/Java实现天平秤球/","link":"","permalink":"https://kanchai.club/2020/03/17/Java%E5%AE%9E%E7%8E%B0%E5%A4%A9%E5%B9%B3%E7%A7%A4%E7%90%83/","excerpt":"一朋友发来一道面试题，百度半天没有很合适的，自己实现这个。题目：有N个铁球，其中一个是塑料球。仅使用一个天平，如何快速找到球？","text":"一朋友发来一道面试题，百度半天没有很合适的，自己实现这个。题目：有N个铁球，其中一个是塑料球。仅使用一个天平，如何快速找到球？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public static void main(String[] args) &#123; Boolean[] balls = new Boolean[] &#123; false, false, false, false, true, false, false System.out.println(\"已知的空球为:\" + balls[4].hashCode()); searchBall(balls, true);&#125;/** * 天平称重找出不同的球，此处通过打印hashCode来判断球的唯一标志 * * @param balls * @param findValue */public static void searchBall(Boolean[] balls, boolean findValue) &#123; System.out.println(\"称重.....\"); if (balls == null) &#123; return; &#125; int size = 0; int indexSize = 0; if (balls.length % 2 != 0) &#123; size = balls.length - 1; &#125; else &#123; size = balls.length; &#125; indexSize = size / 2; Boolean[] preBalls = Arrays.copyOfRange(balls, 0, indexSize); Boolean[] lastBalls = Arrays.copyOfRange(balls, indexSize, size); int weight1 = getWeight(preBalls); int weight2 = getWeight(lastBalls); if (weight1 == weight2) &#123; System.out.println(\"已找到不同的球：\" + balls[balls.length - 1].hashCode()); &#125; else if (weight1 &gt; weight2) &#123; if (lastBalls.length == 1) &#123; System.out.println(\"已找到不同的球：：\" + lastBalls[0].hashCode()); return; &#125; searchBall(lastBalls, findValue); &#125; else &#123; if (preBalls.length == 1) &#123; System.out.println(\"已找到不同的球：：\" + lastBalls[0].hashCode()); return; &#125; searchBall(preBalls, findValue); &#125;&#125;/** * 称重方法 * * @param balls * @return */public static int getWeight(Boolean[] balls) &#123; int count = 0; for (boolean b : balls) &#123; if (!b) &#123; count++; &#125; &#125; return count;&#125; 运行结果为:1234已知的空球为:1231称重.....称重.....已找到不同的球：：1231 可以看出来2次称重，找到不规则的球。","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"算法基础题","slug":"算法基础题","permalink":"https://kanchai.club/tags/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E9%A2%98/"}]},{"title":"一致性hash是什么意思？","slug":"一致性hash解释","date":"2020-03-17T15:36:44.999Z","updated":"2020-03-17T15:35:22.000Z","comments":true,"path":"2020/03/17/一致性hash解释/","link":"","permalink":"https://kanchai.club/2020/03/17/%E4%B8%80%E8%87%B4%E6%80%A7hash%E8%A7%A3%E9%87%8A/","excerpt":"在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么…","text":"在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么… &nbsp; 在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么，我们先来描述一下这个经典的分布式缓存的应用场景。 场景描述假设，我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为0号、1号、2号，现在，有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么，我们应该怎样做呢？如果我们没有任何规律的将3万张图片平均的缓存在3台服务器上，可以满足我们的要求吗？可以！但是如果这样做，当我们需要访问某个缓存项时，则需要遍历3台缓存服务器，从3万个缓存项中找到我们需要访问的缓存，遍历的过程效率太低，时间太长，当我们找到需要访问的缓存项时，时长可能是不能被接受的，也就失去了缓存的意义，缓存的目的就是提高速度，改善用户体验，减轻后端服务器压力，如果每次访问一个缓存项都需要遍历所有缓存服务器的所有缓存项，想想就觉得很累，那么，我们该怎么办呢？原始的做法是对缓存项的键进行哈希，将hash后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上，这样说可能不太容易理解，我们举例说明，仍然以刚才描述的场景为例，假设我们使用图片名称作为访问图片的key，假设图片名称是不重复的，那么，我们可以使用如下公式，计算出图片应该存放在哪台服务器上。 hash（图片名称）% N 因为图片的名称是不重复的，所以，当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的，如果我们有3台服务器，使用哈希后的结果对3求余，那么余数一定是0、1或者2，没错，正好与我们之前的服务器编号相同，如果求余的结果为0， 我们就把当前图片名称对应的图片缓存在0号服务器上，如果余数为1，就把当前图片名对应的图片缓存在1号服务器上，如果余数为2，同理，那么，当我们访问任意一个图片的时候，只要再次对图片名称进行上述运算，即可得出对应的图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可，如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了，通过这样的方法，即可将3万张图片随机的分布到3台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，这样就能满足我们的需求了，我们暂时称上述算法为HASH算法或者取模算法，取模算法的过程可以用下图表示。 但是，使用上述HASH算法进行缓存时，会出现一些缺陷，试想一下，如果3台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？没错，很简单，多增加两台缓存服务器不就行了，假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由3台变成了4台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变，换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据，同理，假设3台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从3台变为2台，如果想要访问一张图片，这张图片的缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义，由于大量缓存在同一时间失效，造成了缓存的雪崩，此时前端缓存已经无法起到承担部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述HASH算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。 &nbsp; 我们来回顾一下使用上述算法会出现的问题。 问题1：当缓存服务器数量发生变化时，会引起缓存的雪崩，可能会引起整体系统压力过大而崩溃（大量缓存同一时间失效）。 问题2：当缓存服务器数量发生变化时，几乎所有缓存的位置都会发生改变，怎样才能尽量减少受影响的缓存呢？ &nbsp; 其实，上面两个问题是一个问题，那么，一致性哈希算法能够解决上述问题吗？ 我们现在就来了解一下一致性哈希算法。 &nbsp; &nbsp; 一致性哈希算法的基本概念其实，一致性哈希算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性哈希算法是对2^32取模，什么意思呢？我们慢慢聊。 &nbsp; 首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆，示意图如下： 圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1&nbsp; 我们把这个由2的32次方个点组成的圆环称为hash环。 &nbsp; 那么，一致性哈希算法与上图中的圆环有什么关系呢？我们继续聊，仍然以之前描述的场景为例，假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产环境中，这三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模，可以使用如下公式示意。 hash（服务器A的IP地址） % &nbsp;2^32 通过上述公式算出的结果一定是一个0到2^32-1之间的一个整数，我们就用算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环上必定有一个点与这个整数对应，而我们刚才已经说明，使用这个整数代表服务器A，那么，服务器A就可以映射到这个环上，用下图示意 同理，服务器B与服务器C也可以通过相同的方法映射到上图中的hash环中 hash（服务器B的IP地址） % &nbsp;2^32 hash（服务器C的IP地址） % &nbsp;2^32 通过上述方法，可以将服务器B与服务器C映射到上图中的hash环上，示意图如下 假设3台服务器映射到hash环上以后如上图所示（当然，这是理想的情况，我们慢慢聊）。 &nbsp; 好了，到目前为止，我们已经把缓存服务器与hash环联系在了一起，我们通过上述方法，把缓存服务器映射到了hash环上，那么使用同样的方法，我们也可以将需要缓存的对象映射到hash环上。 &nbsp; 假设，我们需要使用缓存服务器缓存图片，而且我们仍然使用图片的名称作为找到图片的key，那么我们使用如下公式可以将图片映射到上图中的hash环上。 hash（图片名称） % &nbsp;2^32 映射后的示意图如下，下图中的橘黄色圆形表示图片 好了，现在服务器与图片都被映射到了hash环上，那么上图中的这个图片到底应该被缓存到哪一台服务器上呢？上图中的图片将会被缓存到服务器A上，为什么呢？因为从图片的位置开始，沿顺时针方向遇到的第一个服务器就是A服务器，所以，上图中的图片将会被缓存到服务器A上，如下图所示。 没错，一致性哈希算法就是通过这种方法，判断一个对象应该被缓存到哪台服务器上的，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一张图片必定会被缓存到固定的服务器上，那么，当下次想要访问这张图片时，只要再次使用相同的算法进行计算，即可算出这个图片被缓存在哪个服务器上，直接去对应的服务器查找对应的图片即可。 &nbsp; 刚才的示例只使用了一张图片进行演示，假设有四张图片需要缓存，示意图如下 1号、2号图片将会被缓存到服务器A上，3号图片将会被缓存到服务器B上，4号图片将会被缓存到服务器C上。 &nbsp; &nbsp; 一致性哈希算法的优点经过上述描述，我想兄弟你应该已经明白了一致性哈希算法的原理了，但是话说回来，一致性哈希算法能够解决之前出现的问题吗，我们说过，如果简单的对服务器数量进行取模，那么当服务器数量发生变化时，会产生缓存的雪崩，从而很有可能导致系统崩溃，那么使用一致性哈希算法，能够避免这个问题吗？我们来模拟一遍，即可得到答案。 &nbsp; 假设，服务器B出现了故障，我们现在需要将服务器B移除，那么，我们将上图中的服务器B从hash环上移除即可，移除服务器B以后示意图如下。 在服务器B未移除时，图片3应该被缓存到服务器B中，可是当服务器B移除以后，按照之前描述的一致性哈希算法的规则，图片3应该被缓存到服务器C中，因为从图片3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器C，也就是说，如果服务器B出现故障被移除时，图片3的缓存位置会发生改变 &nbsp; &nbsp; 但是，图片4仍然会被缓存到服务器C中，图片1与图片2仍然会被缓存到服务器A中，这与服务器B移除之前并没有任何区别，这就是一致性哈希算法的优点，如果使用之前的hash算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分缓存会失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一时间集中到后端服务器上。 &nbsp; 这就是一致性哈希算法所体现出的优点。 &nbsp; &nbsp; hash环的偏斜在介绍一致性哈希的概念时，我们理想化的将3台服务器均匀的映射到了hash环上，如下图所示 但是，理想很丰满，现实很骨感，我们想象的与实际情况往往不一样。 在实际的映射中，服务器可能会被映射成如下模样。 聪明如你一定想到了，如果服务器被映射成上图中的模样，那么被缓存的对象很有可能大部分集中缓存在某一台服务器上，如下图所示。 上图中，1号、2号、3号、4号、6号图片均被缓存在了服务器A上，只有5号图片被缓存在了服务器B上，服务器C上甚至没有缓存任何图片，如果出现上图中的情况，A、B、C三台服务器并没有被合理的平均的充分利用，缓存分布的极度不均匀，而且，如果此时服务器A出现故障，那么失效缓存的数量也将达到最大值，在极端情况下，仍然有可能引起系统的崩溃，上图中的情况则被称之为hash环的偏斜，那么，我们应该怎样防止hash环的偏斜呢？一致性hash算法中使用”虚拟节点”解决了这个问题，我们继续聊。 &nbsp; &nbsp; 虚拟节点话接上文，由于我们只有3台服务器，当我们把服务器映射到hash环上的时候，很有可能出现hash环偏斜的情况，当hash环偏斜以后，缓存往往会极度不均衡的分布在各服务器上，聪明如你一定已经想到了，如果想要均衡的将缓存分布到3台服务器上，最好能让这3台服务器尽量多的、均匀的出现在hash环上，但是，真实的服务器资源只有3台，我们怎样凭空的让它们多起来呢，没错，就是凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。加入虚拟节点以后的hash环如下。 “虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。 从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了，上图中，1号、3号图片被缓存在服务器A中，5号、4号图片被缓存在服务器B中，6号、2号图片被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点，以便减小hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 &nbsp; &nbsp; 好了，一致性哈希算法的原理就总结到这里，如有错误，欢迎赐教，如需转载，请联系作者。 原文链接：白话解析：一致性哈希算法 consistent hashing &nbsp;","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://kanchai.club/tags/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Redis基本介绍","slug":"Redis基本介绍","date":"2020-03-17T15:36:44.819Z","updated":"2020-03-17T15:35:35.000Z","comments":true,"path":"2020/03/17/Redis基本介绍/","link":"","permalink":"https://kanchai.club/2020/03/17/Redis%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/","excerpt":"Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。","text":"Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。 Redis是什么？ Redis安装在磁盘；Redis数据存储在内存，redis是一种基于键值对（key-value）数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。Redis 的流水线功能允许客户端一次将多个命令请求发送给服务器， 并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端， 使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。 特性 速度快，数据放在内存中，官方给出的读写性能10万/S，与机器性能也有关 数据放内存中是速度快的主要原因 C语言实现，与操作系统距离近 使用了单线程架构，预防多线程可能产生的竞争问题 键值对的数据结构服务器 丰富的功能：见上功能 简单稳定：单线程 持久化：发生断电或机器故障，数据可能会丢失，持久化到硬盘 主从复制：实现多个相同数据的redis副本 高可用和分布式：哨兵机制实现高可用，保证redis节点故障发现和自动转移 客户端语言多：java php python c c++ nodejs等 使用场景 缓存：合理使用缓存加快数据访问速度，降低后端数据源压力 排行榜：按照热度排名，按照发布时间排行，主要用到列表和有序集合 计数器应用：视频网站播放数，网站浏览数，使用redis计数 社交网络：赞、踩、粉丝、下拉刷新 消息队列：发布和订阅 常用客户端命令 可执行文件 作用 redis-server 启动redis redis-cli redis命令行客户端 redis-benchmark 基准测试工具 redis-check-aof AOF持久化文件检测和修复工具 redis-check-dump RDB持久化文件检测和修复工具 redis-sentinel 启动哨兵 &gt;1. redis-server启动： &gt;&gt;1. 默认配置：redis-server, 日志输出版本信息，端口6379 &gt;&gt;2. 运行启动：redis-server –port 6380 不建议 &gt;&gt;3. 配置文件启动： redis-server /opt/redis/redis.conf，灵活，生产环境使用这种 &gt;2. redis-cli 启动 &gt;&gt;1. 交互式：redis-cli -h {host} -p {prot}连接到redis服务，没有h默认连127.0 redis-cli -h 127.0.0.1 -p 6379 //没有p 默认连6379 &gt;&gt;2. 命令式：redis-cli -h 127.0.0.1 -p 6379 get hello //取key=hello的value &gt;3. 停止redis服务： redis-cli shutdown &gt;&gt;* a.关闭时：断开连接，持久化文件生成，相对安 &gt;&gt;* b.还可以用kill关闭，此方式不会做持久化，还会造成缓冲区非法关闭，可能会造成AOF和丢失数据 &gt;4. 版本： &gt;&gt;* 版本号第二位为奇数，为非稳定版本（2.7、2.9、3.1） &gt;&gt;* 第二为偶数，为稳定版本（2.6、2.8、3.0） &gt;&gt;* 当前奇数版本是下一个稳定版本的开发版本，如2.9是3.0的开发版本","categories":[{"name":"Redis","slug":"Redis","permalink":"https://kanchai.club/categories/Redis/"}],"tags":[{"name":"redis基本介绍","slug":"redis基本介绍","permalink":"https://kanchai.club/tags/redis%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"}]},{"title":"POI-Excel的导出导入","slug":"并发编程-线程基础-基础概念","date":"2020-03-17T15:36:44.711Z","updated":"2020-03-17T15:35:39.000Z","comments":true,"path":"2020/03/17/并发编程-线程基础-基础概念/","link":"","permalink":"https://kanchai.club/2020/03/17/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"计算机中线程的基本概念","text":"计算机中线程的基本概念 计算机中线程的基本概念 CPU核心数，线程数之间有什么关系？ CPU核心数量和线程数量一般情况下为1:1的关系，但是使用了超线程技术后，比例为1:2，这个技术是指CPU的工业技术。window可以在任务管理器查看，就是我们常说的4核八线程，4核4线程。 什么是指CPU时间片轮转机制？ 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。每个进程被分配一时间段，称作它的时间片，即该进程允许运行的时间。又叫RR调度，在JAVA中过多的线程会导致上下文切换。比如你4核4线程，你new了8个线程，那么其实4个物理线程公平的分配给8个JAVA线程使用。 什么是进程和线程? 进程:程序运行资源分配的最小单位，进程内部有多个线程，会共享这个进程的资源 线程:CPU调度的最小单位，必须依赖进程而存在。 什么是并发和并行? 并行:同一时刻，可以同时处理事情的能力 并发:与单位时间相关，在单位时间内可以处理事情的能力 高并发编程的意义、好处和注意事项 好处:充分利用cpu的资源、加快用户响应的时间，程序模块化，异步化 问题:线程共享资源，存在冲突；容易导致死锁；启用太多的线程，就有搞垮机器的可能","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://kanchai.club/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"计算机线程","slug":"计算机线程","permalink":"https://kanchai.club/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BA%BF%E7%A8%8B/"}]},{"title":"SpringBoot配置","slug":"springboot配置","date":"2020-03-17T15:36:44.596Z","updated":"2020-03-17T15:36:00.000Z","comments":true,"path":"2020/03/17/springboot配置/","link":"","permalink":"https://kanchai.club/2020/03/17/springboot%E9%85%8D%E7%BD%AE/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179# ----------------------------------------# 核心属性# ----------------------------------------# 文件编码banner.charset&#x3D; UTF-8# 文件位置banner.location&#x3D; classpath:banner.txt# 日志配置# 日志配置文件的位置。 例如对于Logback的&#96;classpath：logback.xml&#96;logging.config&#x3D; # ％wEx#记录异常时使用的转换字。logging.exception-conversion-word&#x3D; # 日志文件名。 例如&#96;myapp.log&#96;logging.file&#x3D; # 日志级别严重性映射。 例如&#96;logging.level.org.springframework &#x3D; DEBUG&#96;logging.level.*&#x3D; # 日志文件的位置。 例如&#96;&#x2F; var &#x2F; log&#96;logging.path&#x3D; # 用于输出到控制台的Appender模式。 只支持默认的logback设置。logging.pattern.console&#x3D; # 用于输出到文件的Appender模式。 只支持默认的logback设置。logging.pattern.file&#x3D; # 日志级别的Appender模式（默认％5p）。 只支持默认的logback设置。logging.pattern.level&#x3D; #注册日志记录系统的初始化挂钩。logging.register-shutdown-hook&#x3D; false# AOP 切面# 添加@EnableAspectJAutoProxy。spring.aop.auto&#x3D; true# 是否要创建基于子类（CGLIB）的代理（true），而不是基于标准的基于Java接口的代理（false）。spring.aop.proxy-target-class&#x3D; false# 应用程序上下文初始化器# 应用指标。spring.application.index&#x3D; # 应用程序名称。spring.application.name&#x3D; # 国际化（消息源自动配置）#spring.messages.basename&#x3D; messages# 以逗号分隔的基础名称列表，每个都在ResourceBundle约定之后。# 加载的资源束文件缓存到期，以秒为单位。 设置为-1时，软件包将永久缓存。spring.messages.cache-seconds&#x3D; -1# 消息编码。spring.messages.encoding&#x3D; UTF-8# 设置是否返回到系统区域设置，如果没有找到特定语言环境的文件。spring.messages.fallback-to-system-locale&#x3D; true# REDIS (Redis 配置)# 连接工厂使用的数据库索引。spring.redis.database&#x3D; 0# Redis服务器主机。spring.redis.host&#x3D; localhost# 登录redis服务器的密码。spring.redis.password&#x3D; # 给定时间池可以分配的最大连接数。 使用负值为无限制。spring.redis.pool.max-active&#x3D; 8# 池中“空闲”连接的最大数量。 使用负值来表示无限数量的空闲连接。spring.redis.pool.max-idle&#x3D; 8# 连接分配在池耗尽之前在抛出异常之前应阻止的最大时间量（以毫秒为单位）。 使用负值无限期地阻止。spring.redis.pool.max-wait&#x3D; -1# 定义池中维护的最小空闲连接数。 此设置只有在正值时才有效果。spring.redis.pool.min-idle&#x3D; 0# redis服务器端口spring.redis.port&#x3D; 6379# redis服务器名称spring.redis.sentinel.master&#x3D;# spring.redis.sentinel.nodes&#x3D; # 连接超时（毫秒）。spring.redis.timeout&#x3D; 0# 管理员 （Spring应用程序管理员JMX自动配置）# 开启应用管理功能。spring.application.admin.enabled&#x3D; false# JMX应用程序名称MBean。spring.application.admin.jmx-name&#x3D; org.springframework.boot:type&#x3D; Admin,name&#x3D; SpringApplication# 自动配置# 自动配置类排除。spring.autoconfigure.exclude&#x3D; # spring 核心配置# 跳过搜索BeanInfo类。spring.beaninfo.ignore&#x3D; true# spring 缓存配置# 由底层缓存管理器支持的要创建的缓存名称的逗号分隔列表。spring.cache.cache-names&#x3D; # 用于初始化EhCache的配置文件的位置。spring.cache.ehcache.config&#x3D; # 用于创建缓存的规范。 检查CacheBuilderSpec有关规格格式的更多细节。spring.cache.guava.spec&#x3D; # 用于初始化Hazelcast的配置文件的位置。spring.cache.hazelcast.config&#x3D; # 用于初始化Infinispan的配置文件的位置。spring.cache.infinispan.config&#x3D; # 用于初始化缓存管理器的配置文件的位置。spring.cache.jcache.config&#x3D; # 用于检索符合JSR-107的缓存管理器的CachingProvider实现的完全限定名称。 只有在类路径上有多个JSR-107实现可用时才需要。spring.cache.jcache.provider&#x3D; # 缓存类型，默认情况下根据环境自动检测。spring.cache.type&#x3D; # spring配置 （配置文件应用侦听器）# 配置文件位置。spring.config.location&#x3D; # 配置文件名。spring.config.name&#x3D; application# hazelcast配置(Hazelcast是一个高度可扩展的数据分发和集群平台，提供了高效的、可扩展的分布式数据存储、数据缓存.)# 用于初始化Hazelcast的配置文件的位置。spring.hazelcast.config&#x3D; # JMX# JMX域名。spring.jmx.default-domain&#x3D; # 将管理bean暴露给JMX域。spring.jmx.enabled&#x3D; true# MBean服务器bean名称。spring.jmx.server&#x3D; mbeanServer# Email (MailProperties) 邮件属性# 默认MimeMessage编码。spring.mail.default-encoding&#x3D; UTF-8# SMTP服务器主机。 例如&#96;smtp.example.com&#96;spring.mail.host&#x3D; # 会话JNDI名称。 设置时，优先于其他邮件设置。spring.mail.jndi-name&#x3D; # 登录SMTP服务器的密码。spring.mail.password&#x3D; # SMTP服务器端口。spring.mail.port&#x3D; # 其他JavaMail会话属性。spring.mail.properties.*&#x3D; # SMTP服务器使用的协议。spring.mail.protocol&#x3D; smtp# 测试邮件服务器在启动时可用。spring.mail.test-connection&#x3D; false# 登录SMTP服务器的用户。spring.mail.username&#x3D; # 应用设置（spring应用）# 用于在应用程序运行时显示横幅的模式。spring.main.banner-mode&#x3D; console# 源（类名，包名或XML资源位置）包含在ApplicationContext中。spring.main.sources&#x3D; # 在Web环境中运行应用程序（默认情况下自动检测）。spring.main.web-environment&#x3D; # 文件编码（文件编码应用程序侦听器）# 应用程序使用的预期字符编码。spring.mandatory-file-encoding&#x3D; # 输出# 配置ANSI输出（可以是“detect”，“always”，“never”）--&gt;“检测”，“永远”，“从不”spring.output.ansi.enabled&#x3D; detect# PID文件（应用程序文件写入器）# 如果使用ApplicationPidFileWriter但是无法写入PID文件，则失败。spring.pid.fail-on-write-error&#x3D; # 要写入的PID文件的位置（如果使用ApplicationPidFileWriter）。spring.pid.file&#x3D; # 简介（profiles 这个单词翻译过来就是这样... 没用过这个属性，有哪位大神用过请留言我改正，感谢。）# 活动配置文件的逗号分隔列表。spring.profiles.active&#x3D; # 无条件地激活指定的逗号分隔的配置文件。spring.profiles.include&#x3D; # SendGrid（SendGrid自动配置）# SendGrid帐号用户名spring.sendgrid.username&#x3D; # SendGrid帐号密码spring.sendgrid.password&#x3D; # SendGrid代理主机spring.sendgrid.proxy.host&#x3D; # SendGrid代理端口spring.sendgrid.proxy.port&#x3D; # ----------------------------------------# WEB属性# ----------------------------------------# 文件上传属性# 启用对文件上传的支持。multipart.enabled&#x3D; true# 将文件写入磁盘后的阈值。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.file-size-threshold&#x3D; 0# 上传文件的位置。multipart.location&#x3D; # 最大文件大小。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.max-file-size&#x3D; 1Mb# 最大请求大小。 值可以使用后缀“MB”或“KB”表示兆字节或千字节大小。multipart.max-request-size&#x3D; 10Mb# 嵌入式服务器配置（服务器属性）# 服务器应绑定到的网络地址。server.address&#x3D; # 如果启用响应压缩。server.compression.enabled&#x3D; false# 从压缩中排除的用户代理列表。server.compression.excluded-user-agents&#x3D; # 应该压缩的MIME类型的逗号分隔列表。 例如&#96;text &#x2F; html，text &#x2F; css，application &#x2F; json&#96;server.compression.mime-types&#x3D; # 执行压缩所需的最小响应大小。 例如2048server.compression.min-response-size&#x3D; # Servlet上下文初始化参数。 例如&#96;server.context-parameters.a &#x3D; alpha&#96;server.context-parameters.*&#x3D; # 应用程序的上下文路径。server.context-path&#x3D; # 显示应用程序的名称。server.display-name&#x3D; application# 何时包含“stacktrace”属性。server.error.include-stacktrace&#x3D; never# 错误控制器的路径。server.error.path&#x3D; &#x2F;error# 启动浏览器中出现服务器错误时显示的默认错误页面。server.error.whitelabel.enabled&#x3D; true# JSP servlet的类名。server.jsp-servlet.class-name&#x3D; org.apache.jasper.servlet.JspServlet# Init参数用于配置JSP servletserver.jsp-servlet.init-parameters.*&#x3D; # JSP servlet是否被注册server.jsp-servlet.registered&#x3D; true# 服务器HTTP端口。server.port&#x3D; 8080# 主调度程序servlet的路径。server.servlet-path&#x3D; &#x2F;# 会话cookie的注释。server.session.cookie.comment&#x3D; # 会话cookie的域。server.session.cookie.domain&#x3D; # “HttpOnly”标志为会话cookie。server.session.cookie.http-only&#x3D; # 会话cookie的最大时长（以秒为单位）。server.session.cookie.max-age&#x3D; # 会话cookie名称。server.session.cookie.name&#x3D; # 会话cookie的路径。server.session.cookie.path&#x3D; # 会话cookie的“安全”标志。server.session.cookie.secure&#x3D; # 重启之间持续会话数据。server.session.persistent&#x3D; false# 用于存储会话数据的目录。server.session.store-dir&#x3D; # 会话超时（秒）。server.session.timeout&#x3D; # 会话跟踪模式（以下一个或多个：“cookie”，“url”，“ssl”）。server.session.tracking-modes&#x3D; # 支持SSL密码。server.ssl.ciphers&#x3D; # 客户端认证是否需要（“want”）或需要（“need”）。 需要信任存储。server.ssl.client-auth&#x3D; # ssl配置server.ssl.enabled&#x3D; server.ssl.key-alias&#x3D; server.ssl.key-password&#x3D; server.ssl.key-store&#x3D; server.ssl.key-store-password&#x3D; server.ssl.key-store-provider&#x3D; server.ssl.key-store-type&#x3D; server.ssl.protocol&#x3D; server.ssl.trust-store&#x3D; server.ssl.trust-store-password&#x3D; server.ssl.trust-store-provider&#x3D; server.ssl.trust-store-type&#x3D; # 创建日志文件的目录。 可以相对于tomcat base dir或absolute。server.tomcat.accesslog.directory&#x3D; # 启用访问日志。server.tomcat.accesslog.enabled&#x3D; false# 访问日志的格式化模式。server.tomcat.accesslog.pattern&#x3D; common# 日志文件名前缀。server.tomcat.accesslog.prefix&#x3D; access_log# 日志文件名后缀。server.tomcat.accesslog.suffix&#x3D; .log# 在调用backgroundProcess方法之间延迟秒。server.tomcat.background-processor-delay&#x3D; 30# Tomcat基本目录。 如果未指定，将使用临时目录。server.tomcat.basedir&#x3D; # 正则表达式匹配可信IP地址。server.tomcat.internal-proxies&#x3D; 10\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\192\\\\.168\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\169\\\\.254\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\127\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.1[6-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.2[0-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\172\\\\.3[0-1]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;# HTTP消息头的最大大小（以字节为单位）。server.tomcat.max-http-header-size&#x3D; 0# 最大工作线程数。server.tomcat.max-threads&#x3D; 0# 用于覆盖原始端口值的HTTP头的名称。server.tomcat.port-header&#x3D; X-Forwarded-Port# 头文件，保存传入协议，通常命名为“X-Forwarded-Proto”。server.tomcat.protocol-header&#x3D; # 表示传入请求使用SSL的协议头的值。server.tomcat.protocol-header-https-value&#x3D; https# 提取远程ip的HTTP头的名称。 例如&#96;X-FORWARDED-FOR&#96;server.tomcat.remote-ip-header&#x3D; # 用于解码URI的字符编码。server.tomcat.uri-encoding&#x3D; UTF-8# 访问日志目录。server.undertow.accesslog.dir&#x3D; # 启用访问日志。server.undertow.accesslog.enabled&#x3D; false# 访问日志的格式化模式。server.undertow.accesslog.pattern&#x3D; common# 每个缓冲区的大小字节数。server.undertow.buffer-size&#x3D; # 每个区域的缓冲区数。server.undertow.buffers-per-region&#x3D; # 在Java堆之外分配缓冲区。server.undertow.direct-buffers&#x3D; # 为工作者创建的I &#x2F; O线程数。server.undertow.io-threads&#x3D; # 工作线程数。server.undertow.worker-threads&#x3D; # 如果X-Forwarded- *头应该应用于HttpRequest。server.use-forward-headers&#x3D; # 自由标记（自由标记自动配置）# 设置是否允许HttpServletRequest属性重写（隐藏）控制器生成的同名模型属性。spring.freemarker.allow-request-override&#x3D; false# 设置是否允许HttpSession属性重写（隐藏）控制器生成的相同名称的模型属性。spring.freemarker.allow-session-override&#x3D; false# 启用模板缓存。spring.freemarker.cache&#x3D; false# 模板编码。spring.freemarker.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.freemarker.check-template-location&#x3D; true# Content-Type值。spring.freemarker.content-type&#x3D; text&#x2F;html# 启用此技术的MVC视图分辨率。spring.freemarker.enabled&#x3D; true# 设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.freemarker.expose-request-attributes&#x3D; false# 设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.freemarker.expose-session-attributes&#x3D; false# 设置是否公开一个RequestContext供Spring 的宏库使用，名称为“springMacroRequestContext”。spring.freemarker.expose-spring-macro-helpers&#x3D; true# 首选文件系统访问模板加载。 文件系统访问可以对模板更改进行热检测。spring.freemarker.prefer-file-system-access&#x3D; true# 前缀，在构建URL时先查看名称。spring.freemarker.prefix&#x3D; # 所有视图的RequestContext属性的名称。spring.freemarker.request-context-attribute&#x3D; # 公开的FreeMarker密钥将被传递给FreeMarker的配置。spring.freemarker.settings.*&#x3D; # 后缀，在构建URL时附加到查看名称。spring.freemarker.suffix&#x3D; # 逗号分隔的模板路径列表。spring.freemarker.template-loader-path&#x3D; classpath:&#x2F;templates&#x2F;# 可以解决的视图名称的白名单。spring.freemarker.view-names&#x3D; # groovr模板（Groovy模板自动配置）# 设置是否允许HttpServletRequest属性重写（隐藏）控制器生成的同名模型属性。spring.groovy.template.allow-request-override&#x3D; false# 设置是否允许HttpSession属性重写（隐藏）控制器生成的相同名称的模型属性。spring.groovy.template.allow-session-override&#x3D; false# 启用模板缓存。spring.groovy.template.cache&#x3D; # 模板编码。spring.groovy.template.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.groovy.template.check-template-location&#x3D; true# 请参阅GroovyMarkupConfigurerspring.groovy.template.configuration.*&#x3D; # Content-Type值。spring.groovy.template.content-type&#x3D; test&#x2F;html# 启用此技术的MVC视图分辨率。spring.groovy.template.enabled&#x3D; true# 设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.groovy.template.expose-request-attributes&#x3D; false# 设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.groovy.template.expose-session-attributes&#x3D; false# 设置是否公开一个RequestContext供Spring Spring的宏库使用，名称为“springMacroRequestContext”。spring.groovy.template.expose-spring-macro-helpers&#x3D; true# 前缀，在构建URL时先查看名称。spring.groovy.template.prefix&#x3D; # 所有视图的RequestContext属性的名称。spring.groovy.template.request-context-attribute&#x3D; # 模板路径。spring.groovy.template.resource-loader-path&#x3D; classpath:&#x2F;templates&#x2F;# 后缀，在构建URL时附加到查看名称。spring.groovy.template.suffix&#x3D; .tpl# 可以解决的视图名称的白名单。spring.groovy.template.view-names&#x3D; # spring Hateoas 配置# 指定应用程序&#x2F; hal + json响应是否应发送到接受application &#x2F; json的请求。spring.hateoas.use-hal-as-default-json-media-type&#x3D; true# HTTP 消息转换# 首选JSON映射程序用于HTTP消息转换。 设置为“gson”强制使用Gson，当它和Jackson都在类路径上时。spring.http.converters.preferred-json-mapper&#x3D; jackson# HTTP 编码（Http编码属性）# HTTP请求和响应的字符集。 如果未明确设置，则添加到“Content-Type”头。spring.http.encoding.charset&#x3D; UTF-8# 启用http编码支持。spring.http.encoding.enabled&#x3D; true# 将编码强制到HTTP请求和响应上配置的字符集。spring.http.encoding.force&#x3D; true# Jackson(解析json和序列化json) 配置# 日期格式字符串或全限定日期格式类名。 例如&#96;yyyy-MM-dd HH：mm：ss&#96;。spring.jackson.date-format&#x3D; # Jones开&#x2F;关功能，影响Java对象反序列化的方式。spring.jackson.deserialization.*&#x3D; # 关闭或者打开Jackson 功能spring.jackson.generator.*&#x3D; # Joda日期时间格式字符串。 如果未配置，如果配置了格式字符串，则“日期格式”将用作后备。spring.jackson.joda-date-time-format&#x3D; # 用于格式化的区域设置。spring.jackson.locale&#x3D; # jackson通用开&#x2F;关功能。spring.jackson.mapper.*&#x3D; # Jackson 解析器的开&#x2F;关功能。spring.jackson.parser.*&#x3D; # Jackson的PropertyNamingStrategy的一个常量。 也可以是PropertyNamingStrategy子类的完全限定类名。spring.jackson.property-naming-strategy&#x3D; # Jones开&#x2F;关功能，影响Java对象序列化的方式。spring.jackson.serialization.*&#x3D; # 控制在序列化期间包含属性。 配置了Jackson的JsonInclude.Include枚举中的一个值。spring.jackson.serialization-inclusion&#x3D; # 格式化日期时使用的时区。 例如&#96;America &#x2F; Los_Angeles&#96;spring.jackson.time-zone&#x3D; # Jersey 配置# 作为应用程序的基本URI的路径。 如果指定，则覆盖“@ApplicationPath”的值。spring.jersey.application-path&#x3D; # jersey过滤器链顺序。spring.jersey.filter.order&#x3D; 0# init参数传递到Jersey通过servlet或过滤器。spring.jersey.init.*&#x3D; # jersey整合型。可以是“servlet”也可以是“filter”。spring.jersey.type&#x3D; servlet# spring 视图分解器 配置# 启用后退解析支持。spring.mobile.devicedelegatingviewresolver.enable-fallback&#x3D; false# 启用设备视图解析器。spring.mobile.devicedelegatingviewresolver.enabled&#x3D; false# 前缀，用于查看移动设备的名称。spring.mobile.devicedelegatingviewresolver.mobile-prefix&#x3D; mobile&#x2F;# 后缀，附加到查看移动设备的名称。spring.mobile.devicedelegatingviewresolver.mobile-suffix&#x3D; # 前缀，用于查看普通设备的名称。spring.mobile.devicedelegatingviewresolver.normal-prefix&#x3D; # 后缀，附加到查看普通设备的名称。spring.mobile.devicedelegatingviewresolver.normal-suffix&#x3D; # 前缀，用于查看平板设备的名称。spring.mobile.devicedelegatingviewresolver.tablet-prefix&#x3D; tablet&#x2F;# 后缀，附加到查看平板电脑设备的名称。spring.mobile.devicedelegatingviewresolver.tablet-suffix&#x3D; # 移动网站首选项 （站点首选项自动配置）# 启用SitePreferenceHandler。spring.mobile.sitepreference.enabled&#x3D; true# MUSTACHE模板（Mustache AutoConfiguration）# 启用模板缓存。spring.mustache.cache&#x3D; false# 模板编码。spring.mustache.charset&#x3D; UTF-8# 检查模板位置是否存在。spring.mustache.check-template-location&#x3D; true# Content-Type值spring.mustache.content-type&#x3D; text&#x2F;html# 启用此技术的MVC视图分辨率。spring.mustache.enabled&#x3D; true# 前缀应用于模板名称。spring.mustache.prefix&#x3D; classpath:&#x2F;templates&#x2F;# 后缀应用于模板名称。spring.mustache.suffix&#x3D; .html# 可以解决的视图名称的白名单。spring.mustache.view-names&#x3D; # SPRING MVC (Web Mvc 配置)# 异步请求处理超时之前的时间量（以毫秒为单位）。spring.mvc.async.request-timeout&#x3D; # 要使用的日期格式。 例如&#96;dd &#x2F; MM &#x2F; yyyy&#96;。spring.mvc.date-format&#x3D; # 发送TRACE请求到FrameworkServlet doService方法。spring.mvc.dispatch-trace-request&#x3D; false# 发送OPTIONS请求到FrameworkServlet doService方法。spring.mvc.dispatch-options-request&#x3D; false# 启用favicon.ico的解析。spring.mvc.favicon.enabled&#x3D; true# 如果在重定向方案期间应该忽略“默认”模型的内容。spring.mvc.ignore-default-model-on-redirect&#x3D; true# 要使用的区域设置。spring.mvc.locale&#x3D; # 将文件扩展名映射到内容协商的媒体类型。spring.mvc.media-types.*&#x3D; # 消息代码格式策略。 例如&#96;PREFIX_ERROR_CODE&#96;。spring.mvc.message-codes-resolver-format&#x3D; # 用于静态资源的路径模式。spring.mvc.static-path-pattern&#x3D; &#x2F;**# 如果没有发现处理程序来处理请求，则应抛出“NoHandlerFoundException”。spring.mvc.throw-exception-if-no-handler-found&#x3D; false# Spring MVC视图前缀。spring.mvc.view.prefix&#x3D; # Spring MVC视图后缀。spring.mvc.view.suffix&#x3D; #SPRING RESOURCES HANDLING（ResourceProperties）资源处理spring.resources.add-mappings &#x3D; true #启用默认资源处理。spring.resources.cache-period &#x3D; #由资源处理程序提供的资源的缓存期，以秒为单位。spring.resources.chain.cache &#x3D; true #在资源链中启用缓存。spring.resources.chain.enabled &#x3D; #启用Spring资源处理链。默认情况下禁用，除非启用了至少一个策略。spring.resources.chain.html-application-cache &#x3D; false #启用HTML5应用程序缓存清单重写。spring.resources.chain.strategy.content.enabled &#x3D; false #启用内容版本策略。spring.resources.chain.strategy.content.paths &#x3D; &#x2F; ** #应用于版本策略的模式的逗号分隔列表。spring.resources.chain.strategy.fixed.enabled &#x3D; false #启用固定版本策略。spring.resources.chain.strategy.fixed.paths &#x3D; #应用于版本策略的逗号分隔的模式列表。spring.resources.chain.strategy.fixed.version &#x3D; #用于版本策略的版本字符串。spring.resources.static-locations &#x3D; classpath：&#x2F; META-INF &#x2F; resources &#x2F;，classpath：&#x2F; resources &#x2F;，classpath：&#x2F; static &#x2F;，classpath：&#x2F; public &#x2F; #静态资源的位置。 #SPRING SOCIAL（SocialWebAutoConfiguration）集群spring.social.auto-connection-views &#x3D; false #启用支持的提供程序的连接状态视图。 #SPRING SOCIAL FACEBOOK（FacebookAutoConfiguration）spring.social.facebook.app-id &#x3D; #您的应用程序的Facebook应用程序IDspring.social.facebook.app-secret &#x3D; #你的应用程序的Facebook应用程序密码 #SPRING SOCIAL LINKEDIN（LinkedInAutoConfiguration）spring.social.linkedin.app-id &#x3D; #您的应用程序的LinkedIn应用程序IDspring.social.linkedin.app-secret &#x3D; #您的应用程序的LinkedIn App Secret #SPRING SOCIAL TWITTER（TwitterAutoConfiguration）spring.social.twitter.app-id &#x3D; #你的应用程序的Twitter应用程序IDspring.social.twitter.app-secret &#x3D; #你的应用程序的Twitter App Secret #THYMELEAF Thymeleaf模板引擎配置spring.thymeleaf.cache &#x3D; true #启用模板缓存。spring.thymeleaf.check-template-location &#x3D; true #检查模板位置是否存在。spring.thymeleaf.content-type &#x3D; text &#x2F; html #Content-Type值。spring.thymeleaf.enabled &#x3D; true #启用MVC Thymeleaf视图分辨率。spring.thymeleaf.encoding &#x3D; UTF-8 #模板编码。spring.thymeleaf.excluded-view-names &#x3D; #应该从解决方案中排除的视图名称的逗号分隔列表。spring.thymeleaf.mode &#x3D; HTML5 #应用于模板的模板模式。另请参见StandardTemplateModeHandlers。spring.thymeleaf.prefix &#x3D; classpath：&#x2F; templates &#x2F; #在构建URL时预先查看名称的前缀。spring.thymeleaf.suffix &#x3D; .html #构建URL时附加查看名称的后缀。spring.thymeleaf.template-resolver-order &#x3D; #链中模板解析器的顺序。spring.thymeleaf.view-names &#x3D; #可以解析的视图名称的逗号分隔列表。 #VELOCITY TEMPLATES（VelocityAutoConfiguration）spring.velocity.allow-request-override &#x3D; false #设置是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名的模型属性。spring.velocity.allow-session-override &#x3D; false #设置是否允许HttpSession属性重写（隐藏）控制器生成的同名的模型属性。spring.velocity.cache &#x3D; #启用模板缓存。spring.velocity.charset &#x3D; UTF-8 #模板编码。spring.velocity.check-template-location &#x3D; true #检查模板位置是否存在。spring.velocity.content-type &#x3D; text &#x2F; html #Content-Type值。spring.velocity.date-tool-attribute &#x3D; #在视图的Velocity上下文中公开的DateTool辅助对象的名称。spring.velocity.enabled &#x3D; true #启用此技术的MVC视图分辨率。spring.velocity.expose-request-attributes &#x3D; false #设置在与模板合并之前是否应将所有请求属性添加到模型中。spring.velocity.expose-session-attributes &#x3D; false #设置在与模板合并之前是否应将所有HttpSession属性添加到模型中。spring.velocity.expose-spring-macro-helpers &#x3D; true #设置是否公开一个RequestContext供Spring Spring的宏库使用，名称为“springMacroRequestContext”。spring.velocity.number-tool-attribute &#x3D; #在视图的Velocity上下文中公开的NumberTool帮助对象的名称。spring.velocity.prefer-file-system-access &#x3D; true #首选文件系统访问模板加载。文件系统访问可以对模板更改进行热检测。spring.velocity.prefix &#x3D; #前缀，用于在构建URL时查看名称。spring.velocity.properties。* &#x3D; #附加速度属性。spring.velocity.request-context-attribute &#x3D; #所有视图的RequestContext属性的名称。spring.velocity.resource-loader-path &#x3D; classpath：&#x2F; templates &#x2F; #模板路径。spring.velocity.suffix &#x3D; .vm #构建URL时附加到查看名称的后缀。spring.velocity.toolbox-config-location &#x3D; #Velocity Toolbox配置位置。例如&#96;&#x2F; WEB-INF &#x2F; toolbox.xml&#39;spring.velocity.view-names &#x3D; #可以解决的视图名称的白名单。 #---------------------------------------- #安全属性 #---------------------------------------- #SECURITY（SecurityProperties）security.basic.authorize-mode &#x3D; role #应用安全授权模式。security.basic.enabled &#x3D; true #启用基本身份验证。security.basic.path &#x3D; &#x2F; ** #安全路径的逗号分隔列表。security.basic.realm &#x3D; Spring #HTTP基本的领域名称。security.enable-csrf &#x3D; false #启用跨站点请求伪造支持。security.filter-order &#x3D; 0 #安全过滤器连锁订单。security.headers.cache &#x3D; true #启用缓存控制HTTP头。security.headers.content-type &#x3D; true# 启用“X-Content-Type-Options”头。security.headers.frame &#x3D; true #启用“X-Frame-Options”标题。security.headers.hsts &#x3D; # HTTP严格传输安全（HSTS）模式（无，域，全部）。security.headers.xss &#x3D; true #启用跨站点脚本（XSS）保护。security.ignored &#x3D; #从默认安全路径中排除的路径的逗号分隔列表。security.require-ssl &#x3D; false #为所有请求启用安全通道。security.sessions &#x3D; stateless #会话创建策略（永远不会，if_required，无状态）。security.user.name &#x3D; user #默认用户名。security.user.password &#x3D; #默认用户名的密码。默认情况下，启动时会记录随机密码。security.user.role &#x3D; USER #为默认用户名授予角色。 #SECURITY OAUTH2 CLIENT（OAuth2ClientPropertiessecurity.oauth2.client.client-id &#x3D; #OAuth2客户端ID。security.oauth2.client.client-secret &#x3D; #OAuth2客户机密码。默认生成随机密码 #SECURITY OAUTH2 RESOURCES（ResourceServerPropertiessecurity.oauth2.resource.id &#x3D; #资源的标识符。security.oauth2.resource.jwt.key-uri &#x3D; #JWT令牌的URI。如果值不可用并且密钥是公共的，可以设置。security.oauth2.resource.jwt.key-value &#x3D; #JWT令牌的验证密钥。可以是对称秘密或PEM编码的RSA公钥。security.oauth2.resource.prefer-token-info &#x3D; true #使用令牌信息，可以设置为false以使用用户信息。security.oauth2.resource.service-id &#x3D; resource #security.oauth2.resource.token-info-uri &#x3D; #令牌解码端点的URI。security.oauth2.resource.token-type &#x3D; #使用userInfoUri时发送的令牌类型。security.oauth2.resource.user-info-uri &#x3D; #用户端点的URI。 #SECURITY OAUTH2 SSO（OAuth2SsoPropertiessecurity.oauth2.sso.filter-order &#x3D; #如果不提供显式的WebSecurityConfigurerAdapter，则应用过滤器顺序security.oauth2.sso.login-path &#x3D; &#x2F; login #登录页面的路径，即触发重定向到OAuth2授权服务器的路径# ----------------------------------------# DATA PROPERTIES 数据性能# ----------------------------------------# FLYWAY (FlywayProperties)flyway.baseline-description &#x3D; #flyway.baseline-version &#x3D; 1 #版本开始迁移flyway.baseline-on-migrate &#x3D; #flyway.check-location &#x3D; false #检查迁移脚本位置是否存在。flyway.clean-on-validation-error &#x3D; #flyway.enabled &#x3D; true #启用飞行路线。flyway.encoding &#x3D; #flyway.ignore-failed-future-migration &#x3D; #flyway.init-sqls &#x3D; #执行SQL语句，以便在获取连接后立即初始化连接。flyway.locations &#x3D; classpath：db &#x2F; migration #迁移脚本的位置flyway.out-of-order &#x3D; #如果您希望Flyway创建自己的DataSource，则需要使用#path密码flyway.placeholder-prefix &#x3D; #flyway.placeholder-replacement &#x3D; #flyway.placeholder-suffix &#x3D; #flyway.placeholders。* &#x3D; #flyway.schemas &#x3D; #schemas来更新flyway.sql-migration-prefix &#x3D; V #flyway.sql-migration-separator &#x3D; #flyway.sql-migration-suffix &#x3D; .sql #flyway.table &#x3D; #flyway.url &#x3D; #要迁移的数据库的JDBC url。如果未设置，则使用主配置的数据源。flyway.user &#x3D; #登录要迁移的数据库的用户。flyway.validate-on-migrate &#x3D; ## LIQUIBASE (LiquibaseProperties)liquibase.change-log &#x3D; classpath：&#x2F;db&#x2F;changelog&#x2F;db.changelog-master.yaml #更改日志配置路径。liquibase.check-change-log-location &#x3D; true #检查更改日志位置是否存在。liquibase.contexts &#x3D; #使用逗号分隔的运行时上下文列表。liquibase.default-schema &#x3D; #默认数据库模式。liquibase.drop-first &#x3D; false #首先删除数据库模式。liquibase.enabled &#x3D; true #启用liquidibase支持。liquibase.labels &#x3D; #使用逗号分隔的运行时标签列表。liquibase.parameters。* &#x3D; #更改日志参数。liquibase.password &#x3D; #登录要迁移的数据库的密码。liquibase.url &#x3D; #要迁移的数据库的JDBC url。 如果未设置，则使用主配置的数据源。liquibase.user &#x3D; #登录要迁移的数据库的用户。# DAO (PersistenceExceptionTranslationAutoConfiguration)spring.dao.exceptiontranslation.enabled&#x3D; true # 启用持久异常翻译后处理器。# CASSANDRA (CassandraProperties)spring.data.cassandra.cluster-name &#x3D; #Cassandra群集的名称。spring.data.cassandra.compression &#x3D; #由Cassandra二进制协议支持的压缩。spring.data.cassandra.connect-timeout-millis &#x3D; #套接字选项：连接超时。spring.data.cassandra.consistency-level &#x3D; #查询一致性级别。spring.data.cassandra.contact-points &#x3D; localhost #集群节点地址的逗号分隔列表。spring.data.cassandra.fetch-size &#x3D; #查询默认的抓取大小。spring.data.cassandra.keyspace-name &#x3D; #要使用的密钥空间名称。spring.data.cassandra.load-balancing-policy &#x3D; #负载均衡策略的类名。spring.data.cassandra.port &#x3D; #Cassandra服务器端口。spring.data.cassandra.password &#x3D; #登录服务器的密码。spring.data.cassandra.read-timeout-millis &#x3D; #套接字选项：读取超时。spring.data.cassandra.reconnection-policy &#x3D; #重新连接策略类。spring.data.cassandra.retry-policy &#x3D; #重试策略的类名。spring.data.cassandra.serial-consistency-level &#x3D; #查询串行一致性级别。spring.data.cassandra.ssl &#x3D; false #启用SSL支持。spring.data.cassandra.username &#x3D; #登录用户的服务器。# ELASTICSEARCH (ElasticsearchProperties)spring.data.elasticsearch.cluster-name &#x3D; elasticsearch #弹性搜索集群名称。spring.data.elasticsearch.cluster-nodes &#x3D; #集群节点地址的逗号分隔列表。 如果未指定，则启动客户端节点。spring.data.elasticsearch.properties。* &#x3D; #用于配置客户端的其他属性。spring.data.elasticsearch.repositories.enabled &#x3D; true #启用Elasticsearch存储库。# MONGODB (MongoProperties)spring.data.mongodb.authentication-database &#x3D; #验证数据库名称。spring.data.mongodb.database &#x3D; test #数据库名称。spring.data.mongodb.field-naming-strategy &#x3D; #要使用的FieldNamingStrategy的完全限定名称。spring.data.mongodb.grid-fs-database &#x3D; #GridFS数据库名称。spring.data.mongodb.host &#x3D; localhost #Mongo服务器主机。spring.data.mongodb.password &#x3D; #登录mongo服务器的密码。spring.data.mongodb.port &#x3D; 27017 #Mongo服务器端口。spring.data.mongodb.repositories.enabled &#x3D; true #启用Mongo存储库。spring.data.mongodb.uri &#x3D; mongodb：&#x2F;&#x2F; localhost &#x2F; test #Mongo数据库URI。 设置时，主机和端口将被忽略。spring.data.mongodb.username &#x3D; #登录mongo服务器的用户。# DATA REST (RepositoryRestProperties)spring.data.rest.base-path &#x3D; #由Spring Data REST用于公开存储库资源的基本路径。spring.data.rest.default-page-size &#x3D; #页面的默认大小。spring.data.rest.enable-enum-translation &#x3D; #通过Spring Data REST默认资源包启用枚举值转换。spring.data.rest.limit-param-name &#x3D; #指示一次返回多少结果的URL查询字符串参数的名称。spring.data.rest.max-page-size &#x3D; #最大页面大小。spring.data.rest.page-param-name &#x3D; #指示要返回的页面的URL查询字符串参数的名称。spring.data.rest.return-body-on-create &#x3D; #创建一个实体后返回响应体。spring.data.rest.return-body-on-update &#x3D; #更新实体后返回响应体。spring.data.rest.sort-param-name &#x3D; #指示排序结果的方向的URL查询字符串参数的名称。# SOLR (SolrProperties)spring.data.solr.host &#x3D; http:&#x2F;&#x2F;127.0.0.1:8983&#x2F;solr #Solr主机。 如果设置了“zk-host”，则被忽略。spring.data.solr.repositories.enabled &#x3D; true #启用Solr存储库。spring.data.solr.zk-host &#x3D; #ZooKeeper主机地址，格式为HOST：PORT。# 数据源 配置 (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.continue-on-error &#x3D; false #初始化数据库时发生错误时不要停止。spring.datasource.data &#x3D; #Data（DML）脚本资源引用。spring.datasource.driver-class-name &#x3D; #JDBC驱动程序的完全限定名称。默认情况下，根据URL自动检测。spring.datasource.initialize &#x3D; true #使用&#39;data.sql&#39;填充数据库。spring.datasource.jmx-enabled &#x3D; false #启用JMX支持（如果由底层池提供）。spring.datasource.jndi-name &#x3D; #数据源的JNDI位置。设置时，类，网址，用户名和密码将被忽略。spring.datasource.max-active &#x3D; #例如100spring.datasource.max-idle &#x3D; #例如8spring.datasource.max等待&#x3D;spring.datasource.min-evictable空闲时间-米利斯&#x3D;spring.datasource.min-idle &#x3D; 8spring.datasource.name &#x3D; testdb #数据源的名称。spring.datasource.password &#x3D; #登录数据库的密码。spring.datasource.platform &#x3D; all #在资源模式（schema - $ &#123;platform&#125; .sql）中使用的平台。spring.datasource.schema &#x3D; #Schema（DDL）脚本资源引用。spring.datasource.separator &#x3D;; #语句分隔符在SQL初始化脚本中。spring.datasource.sql-script-encoding &#x3D; #SQL脚本编码。spring.datasource.test-on-borrow &#x3D; #例如&#96;false&#96;spring.datasource.test-on-return &#x3D; #例如&#96;false&#96;spring.datasource.test-while-idle &#x3D; #spring.datasource.time-between-eviction-runs-millis &#x3D; 1spring.datasource.type &#x3D; #要使用的连接池实现的完全限定名称。默认情况下，它是从类路径自动检测的。spring.datasource.url &#x3D; #数据库的JDBC url。spring.datasource.username&#x3D; spring.datasource.validation-query&#x3D; # H2 Web Console (H2ConsoleProperties) spring.h2.console.enabled &#x3D; false #启用控制台。spring.h2.console.path &#x3D; &#x2F; h2-console #控制台可用的路径。# JOOQ (JooqAutoConfiguration)spring.jooq.sql-dialect&#x3D; # 与配置的数据源通信时使用的SQLDialect JOOQ。 例如&#96;POSTGRES&#96;# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.data.jpa.repositories.enabled &#x3D; true #启用JPA存储库。spring.jpa.database &#x3D; #目标数据库进行操作，默认情况下自动检测。可以使用“databasePlatform”属性设置。spring.jpa.database-platform &#x3D; #要运行的目标数据库的名称，默认情况下自动检测。可以使用“数据库”枚举来设置。spring.jpa.generate-ddl &#x3D; false #启动时初始化模式。spring.jpa.hibernate.ddl-auto &#x3D; #DDL模式。这实际上是“hibernate.hbm2ddl.auto”属性的快捷方式。使用嵌入式数据库时默认为“创建删除”，否则为“否”。spring.jpa.hibernate.naming-strategy &#x3D; #命名策略完全限定名。spring.jpa.open-in-view &#x3D; true #注册OpenEntityManagerInViewInterceptor。将JPA EntityManager绑定到线程以进行请求的整个处理。spring.jpa.properties。* &#x3D; #在JPA提供程序上设置的其他本机属性。spring.jpa.show-sql &#x3D; false #启用SQL语句的日志记录。# JTA (JtaAutoConfiguration)spring.jta。* &#x3D; #技术特定配置spring.jta.log-dir &#x3D; #Transaction logs目录。# ATOMIKOSspring.jta.atomikos.connectionfactory.borrow-connection-timeout &#x3D; 30 #从池中借用连接的超时（以秒为单位）。spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag &#x3D; true #创建会话时是否忽略事务标志。spring.jta.atomikos.connectionfactory.local-transaction-mode &#x3D; false #是否需要本地事务。spring.jta.atomikos.connectionfactory.maintenance-interval &#x3D; 60 #池的维护线程运行之间的时间（以秒为单位）。spring.jta.atomikos.connectionfactory.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.atomikos.connectionfactory.max-lifetime &#x3D; 0 #在被破坏之前可以将连接合并的时间（以秒为单位）。 0表示无限制。spring.jta.atomikos.connectionfactory.max-pool-size &#x3D; 1 #池的最大大小。spring.jta.atomikos.connectionfactory.min-pool-size &#x3D; 1 #池的最小大小。spring.jta.atomikos.connectionfactory.reap-timeout &#x3D; 0 #借用连接的收获超时（以秒为单位）。 0表示无限制。spring.jta.atomikos.connectionfactory.unique-resource-name &#x3D; jmsConnectionFactory #用于在恢复期间标识资源的唯一名称。spring.jta.atomikos.datasource.borrow-connection-timeout &#x3D; 30 #从池中借出连接的超时（秒）。spring.jta.atomikos.datasource.default-isolation-level &#x3D; #池提供的连接的默认隔离级别。spring.jta.atomikos.datasource.login-timeout &#x3D; #用于建立数据库连接的超时（以秒为单位）。spring.jta.atomikos.datasource.maintenance-interval &#x3D; 60 #池的维护线程运行之间的时间（以秒为单位）。spring.jta.atomikos.datasource.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.atomikos.datasource.max-lifetime &#x3D; 0 #在被破坏之前可以将连接合并的时间（以秒为单位）。 0表示无限制。spring.jta.atomikos.datasource.max-pool-size &#x3D; 1 #池的最大大小。spring.jta.atomikos.datasource.min-pool-size &#x3D; 1 #池的最小大小。spring.jta.atomikos.datasource.reap-timeout &#x3D; 0 #借用连接的收获超时（以秒为单位）。 0表示无限制。spring.jta.atomikos.datasource.test-query &#x3D; #用于在返回连接之前验证连接的SQL查询或语句。spring.jta.atomikos.datasource.unique-resource-name &#x3D; dataSource #用于在恢复期间识别资源的唯一名称。# BITRONIXspring.jta.bitronix.connectionfactory.acquire-increment &#x3D; 1 #生成池时要创建的连接数。spring.jta.bitronix.connectionfactory.acquisition-interval &#x3D; 1 #在获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。spring.jta.bitronix.connectionfactory.acquisition-timeout &#x3D; 30 #从池中获取连接的超时（以秒为单位）。spring.jta.bitronix.connectionfactory.allow-local-transactions &#x3D; true #事务管理器是否允许混合XA和非XA事务。spring.jta.bitronix.connectionfactory.apply-transaction-timeout &#x3D; false #当XAResource被登记时，是否应该设置事务超时。spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled &#x3D; true #资源是否应该被自动登记和删除。spring.jta.bitronix.connectionfactory.cache-producer-consumer &#x3D; true #是否生产和消费者应该被缓存。spring.jta.bitronix.connectionfactory.defer-connection-release &#x3D; true #提供程序是否可以在同一连接上运行许多事务，并支持事务交织。spring.jta.bitronix.connectionfactory.ignore-recovery-failures &#x3D; false #是否应忽略恢复失败。spring.jta.bitronix.connectionfactory.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.bitronix.connectionfactory.max-pool-size &#x3D; 10 #池的最大大小。 0表示无限制。spring.jta.bitronix.connectionfactory.min-pool-size &#x3D; 0 #池的最小大小。spring.jta.bitronix.connectionfactory.password &#x3D; #用于连接到JMS提供程序的密码。spring.jta.bitronix.connectionfactory.share-transaction-connections &#x3D; false #ACCESSIBLE状态中的连接是否可以在事务的上下文中共享。spring.jta.bitronix.connectionfactory.test-connections &#x3D; true #从池中获取连接是否应该进行测试。spring.jta.bitronix.connectionfactory.two-pc-ordering-position &#x3D; 1 #在两阶段提交期间该资源应该采取的位置（始终为Integer.MIN_VALUE，始终为Integer.MAX_VALUE）。spring.jta.bitronix.connectionfactory.unique-name &#x3D; jmsConnectionFactory #用于在恢复期间标识资源的唯一名称。spring.jta.bitronix.connectionfactory.use-tm-join &#x3D; true启动XAResource时是否应使用TMJOIN。spring.jta.bitronix.connectionfactory.user &#x3D; #用于连接到JMS提供者的用户。spring.jta.bitronix.datasource.acquire-increment &#x3D; 1 #生成池时要创建的连接数。spring.jta.bitronix.datasource.acquisition-interval &#x3D; 1 #在获取无效连接后再尝试获取连接之前等待的时间（以秒为单位）。spring.jta.bitronix.datasource.acquisition-timeout &#x3D; 30 #从池中获取连接的超时（以秒为单位）。spring.jta.bitronix.datasource.allow-local-transactions &#x3D; true #事务管理器是否允许混合XA和非XA事务。spring.jta.bitronix.datasource.apply-transaction-timeout &#x3D; false #当XAResource被登记时，是否应该设置事务超时。spring.jta.bitronix.datasource.automatic-enlisting-enabled &#x3D; true #资源是否应该被登记和自动删除。spring.jta.bitronix.datasource.cursor-holdability &#x3D; #连接的默认游标保持性。spring.jta.bitronix.datasource.defer-connection-release &#x3D; true #数据库是否可以在同一连接上运行许多事务，并支持事务交织。spring.jta.bitronix.datasource.enable-jdbc4-connection-test &#x3D; #从池中获取连接时是否调用Connection.isValid（）。spring.jta.bitronix.datasource.ignore-recovery-failures &#x3D; false #是否应忽略恢复失败。spring.jta.bitronix.datasource.isolation-level &#x3D; #连接的默认隔离级别。spring.jta.bitronix.datasource.local-auto-commit &#x3D; #本地事务的默认自动提交模式。spring.jta.bitronix.datasource.login-timeout &#x3D; #用于建立数据库连接的超时（以秒为单位）。spring.jta.bitronix.datasource.max-idle-time &#x3D; 60 #从池中清除连接之后的时间（以秒为单位）。spring.jta.bitronix.datasource.max-pool-size &#x3D; 10 #池的最大大小。 0表示无限制。spring.jta.bitronix.datasource.min-pool-size &#x3D; 0 #池的最小大小。spring.jta.bitronix.datasource.prepared-statement-cache-size &#x3D; 0 #准备好的语句高速缓存的目标大小。 0禁用缓存。spring.jta.bitronix.datasource.share-transaction-connections &#x3D; false #ACCESSIBLE状态下的连接是否可以在事务的上下文中共享。spring.jta.bitronix.datasource.test-query &#x3D; #用于在返回连接之前验证连接的SQL查询或语句。spring.jta.bitronix.datasource.two-pc-ordering-position &#x3D; 1 #在两阶段提交期间该资源应该采取的位置（始终为Integer.MIN_VALUE，始终为Integer.MAX_VALUE）。spring.jta.bitronix.datasource.unique-name &#x3D; dataSource #用于在恢复期间标识资源的唯一名称。spring.jta.bitronix.datasource.use-tm-join &#x3D; true启动XAResource时是否应使用TMJOIN。# EMBEDDED MONGODB (EmbeddedMongoProperties)spring.mongodb.embedded.features &#x3D; SYNC_DELAY #启用功能的逗号分隔列表。spring.mongodb.embedded.version &#x3D; 2.6.10 #Mongo使用版本。# ----------------------------------------# 整合属性# ---------------------------------------- #ACTIVEMQ（ActiveMQProperties）spring.activemq.broker-url &#x3D; #ActiveMQ代理的URL。 默认自动生成。 例如&#96;tcp：&#x2F;&#x2F; localhost：61616&#96;spring.activemq.in-memory &#x3D; true #指定默认代理URL是否应在内存中。 如果指定了一个显式代理，则被忽略。spring.activemq.password &#x3D; #登录密码的代理。spring.activemq.pooled &#x3D; false #指定是否创建PooledConnectionFactory而不是常规的ConnectionFactory。spring.activemq.user &#x3D; #代理登录用户。# ARTEMIS (ArtemisProperties)spring.artemis.embedded.cluster-password &#x3D; #群集密码。 默认情况下随机生成。spring.artemis.embedded.data-directory &#x3D; #日志文件目录。 如果持久性被关闭，则不需要。spring.artemis.embedded.enabled &#x3D; true #如果Artemis服务器API可用，启用嵌入式模式。spring.artemis.embedded.persistent &#x3D; false #启用持久存储。spring.artemis.embedded.queues &#x3D; #启动时要创建的队列的逗号分隔列表。spring.artemis.embedded.server-id &#x3D; #服务器ID。 默认情况下，使用自动递增的计数器。spring.artemis.embedded.topics &#x3D; #启动时要创建的主题的逗号分隔列表。spring.artemis.host &#x3D; localhost #Artemis代理主机。spring.artemis.mode &#x3D; #Artemis部署模式，默认情况下自动检测。 可以显式设置为“native”或“embedded”。spring.artemis.port &#x3D; 61616 #Artemis 中间件端口。# SPRING BATCH(Batch 配置)spring.batch.initializer.enabled &#x3D; true #如果需要，在启动时创建所需的批处理表。spring.batch.job.enabled &#x3D; true #在启动时执行上下文中的所有Spring批处理作业。spring.batch.job.names &#x3D; #在启动时执行的作业名称的逗号分隔列表（例如&#96;job1，job2&#96;）。 默认情况下，执行在上下文中找到的所有作业。spring.batch.schema &#x3D; classpath：org &#x2F; springframework &#x2F; batch &#x2F; core &#x2F; schema - @@ platform @@。sql #用于初始化数据库模式的SQL文件的路径。spring.batch.table-prefix &#x3D; #所有批次元数据表的表前缀。# HORNETQ (HornetQ 配置)spring.hornetq.embedded.cluster-password &#x3D; #集群密码。 默认情况下随机生成。spring.hornetq.embedded.data-directory &#x3D; #日志文件目录。 如果持久性被关闭，则不需要。spring.hornetq.embedded.enabled &#x3D; true #如果HornetQ服务器API可用，启用嵌入式模式。spring.hornetq.embedded.persistent &#x3D; false #启用持久存储。spring.hornetq.embedded.queues &#x3D; #启动时要创建的队列的逗号分隔列表。spring.hornetq.embedded.server-id &#x3D; #服务器ID。 默认情况下，使用自动递增的计数器。spring.hornetq.embedded.topics &#x3D; #在启动时创建的主题的逗号分隔列表。spring.hornetq.host &#x3D; localhost #HornetQ代理主机。spring.hornetq.mode &#x3D; #HornetQ部署模式，默认情况下自动检测。 可以显式设置为“native”或“embedded”。spring.hornetq.port &#x3D; 5445 #HornetQ代理端口。# JMS (Jms 配置)# 连接工厂JNDI名称。 设置时，优先于其他连接工厂自动配置。spring.jms.jndi-name&#x3D; # 容器的确认模式。 默认情况下，监听器被自动确认处理。spring.jms.listener.acknowledge-mode&#x3D; # 启动时自动启动容器。spring.jms.listener.auto-startup&#x3D; true# 最小并发消费者数。spring.jms.listener.concurrency&#x3D; # 最大并发消费者数。spring.jms.listener.max-concurrency&#x3D; # 指定默认的目的地类型是否为主题。spring.jms.pub-sub-domain&#x3D; false# RABBIT (Rabbit 配置)# 客户端应连接到的逗号分隔的地址列表。spring.rabbitmq.addresses &#x3D; spring.rabbitmq.dynamic &#x3D; true # 创建一个AmqpAdmin bean。spring.rabbitmq.host &#x3D; localhost# RabbitMQ主机。spring.rabbitmq.listener.acknowledge-mode &#x3D; # 容器的确认模式。spring.rabbitmq.listener.auto-startup &#x3D; true# 启动时自动启动容器。spring.rabbitmq.listener.concurrency &#x3D; # 最少消费者数。spring.rabbitmq.listener.max-concurrency &#x3D; # 最大消费者数。spring.rabbitmq.listener.prefetch &#x3D; # 在单个请求中要处理的消息数。它应该大于或等于事务大小（如果使用）。spring.rabbitmq.listener.transaction-size &#x3D; # 在事务中要处理的消息数。为了获得最佳结果，它应该小于或等于预取计数。spring.rabbitmq.password &#x3D; # 登录以对代理进行身份验证。spring.rabbitmq.port &#x3D; 5672# RabbitMQ端口。spring.rabbitmq.requested-heartbeat &#x3D; # 请求的心跳超时，以秒为单位;零为无。spring.rabbitmq.ssl.enabled &#x3D; false# 启用SSL支持。spring.rabbitmq.ssl.key-store &#x3D; # 保存SSL证书的密钥存储区的路径。spring.rabbitmq.ssl.key-store-password &#x3D; # 用于访问密钥库的密码。spring.rabbitmq.ssl.trust-store &#x3D; # 保存SSL证书的Trust存储。spring.rabbitmq.ssl.trust-store-password &#x3D; # 用于访问信任存储的密码。spring.rabbitmq.username &#x3D; # 登录用户对代理进行身份验证。spring.rabbitmq.virtual-host &#x3D; # 连接到代理时使用的虚拟主机。# 端点配置（EndpointCorsProperties）# 设置是否支持凭据。 未设置时，不支持凭据。endpoints.cors.allow-credentials&#x3D; # 在请求中允许的头文件逗号分隔列表。 &#39;*&#39;允许所有标题。endpoints.cors.allowed-headers&#x3D; # 逗号分隔的允许的方法列表。 &#39;*&#39;允许所有方法。endpoints.cors.allowed-methods&#x3D; GET# 逗号分隔的起始列表允许。 &#39;*&#39;允许所有来源。 未设置时，禁用CORS支持。endpoints.cors.allowed-origins&#x3D; # 包含在响应中的标题的逗号分隔列表。endpoints.cors.exposed-headers&#x3D; # 客户端可以缓存飞行前请求的响应时间（秒）。endpoints.cors.max-age&#x3D; 1800# JMX ENDPOINT (EndpointMBeanExportProperties) （端点MBean导出属性）# JMX域名。 如果设置为&#39;spring.jmx.default-domain&#39;的值初始化。endpoints.jmx.domain&#x3D; # 启用所有端点的JMX导出。endpoints.jmx.enabled&#x3D; true# 附加静态属性以附加到表示端点的MBean的所有对象名称。endpoints.jmx.static-names&#x3D; # 确保在发生冲突时修改ObjectNames。endpoints.jmx.unique-names&#x3D; false# JOLOKIA JOLOKIA 配置# 见Jolokia手册jolokia.config.*&#x3D; # 管理HTTP服务器（管理服务器属性）# 在每个响应中添加“X-Application-Context”HTTP头。management.add-application-context-header&#x3D; true# 管理端点应绑定到的网络地址。management.address&#x3D; # 管理端点上下文路径。 例如&#96;&#x2F; actuator&#96;management.context-path&#x3D; # 管理端点HTTP端口。 默认使用与应用程序相同的端口。management.port&#x3D; # 启用安全性management.security.enabled&#x3D; true# 访问管理端点所需的角色。management.security.role&#x3D; ADMIN# 会话创建策略使用（always，never，if_required，stateless）（总是，永远，if_required，无状态）。management.security.sessions&#x3D; stateless# HEALTH INDICATORS (previously health.*)# 启用数据库运行状况检查management.health.db.enabled&#x3D; true# 启用默认的健康指标。management.health.defaults.enabled&#x3D; true# 启用磁盘空间运行状况检查。management.health.diskspace.enabled&#x3D; true# 用于计算可用磁盘空间的路径。management.health.diskspace.path&#x3D; # 应该可用的最小磁盘空间（以字节为单位）。management.health.diskspace.threshold&#x3D; 0# 启用弹性搜索健康检查。management.health.elasticsearch.enabled&#x3D; true# 逗号分隔的索引名称。management.health.elasticsearch.indices&#x3D; # 等待群集响应的时间（以毫秒为单位）。management.health.elasticsearch.response-timeout&#x3D; 100# 启用JMS健康检查。management.health.jms.enabled&#x3D; true# 启用邮件运行状况检查。management.health.mail.enabled&#x3D; true# 启用MongoDB健康检查。management.health.mongo.enabled&#x3D; true# 启用RabbitMQ运行状况检查。management.health.rabbit.enabled&#x3D; true# 启用Redis健康检查。management.health.redis.enabled&#x3D; true# 启用Solr运行状况检查。management.health.solr.enabled&#x3D; true# 按照严重性的顺序，以逗号分隔的健康状态列表。management.health.status.order&#x3D; DOWN, OUT_OF_SERVICE, UNKNOWN, UP# TRACING ((TraceProperties) 跟踪性能# 跟踪中包含的项目。management.trace.include&#x3D; request-headers,response-headers,errors# 远程 shell配置# 验证类型。 根据环境自动检测。shell.auth&#x3D; simple# JAAS域。shell.auth.jaas.domain&#x3D; my-domain# 验证密钥的路径。 这应该指向一个有效的“.pem”文件。shell.auth.key.path&#x3D; # 登录用户。shell.auth.simple.user.name&#x3D; user# 登录用户的密码。shell.auth.simple.user.password&#x3D; # 登录到CRaSH控制台的所需的角色，以逗号分隔列表。shell.auth.spring.roles&#x3D; ADMIN# 用于查找命令的模式。shell.command-path-patterns&#x3D; classpath*:&#x2F;commands&#x2F;**,classpath*:&#x2F;crash&#x2F;commands&#x2F;**# 扫描更改并在必要时更新命令（以秒为单位）。shell.command-refresh-interval&#x3D; -1# 用于查找配置的模式。shell.config-path-patterns&#x3D; classpath*:&#x2F;crash&#x2F;*# 逗号分隔的要禁用的命令列表。shell.disabled-commands&#x3D; jpa*,jdbc*,jndi*# 禁用逗号分隔的插件列表。 默认情况下，根据环境禁用某些插件。shell.disabled-plugins&#x3D; # 用户被提示再次登录后的毫秒数。shell.ssh.auth-timeout &#x3D; # 启用CRaSH SSH支持。shell.ssh.enabled&#x3D; true# 未使用的连接关闭之后的毫秒数。shell.ssh.idle-timeout &#x3D; # SSH服务器密钥路径。shell.ssh.key-path&#x3D; # SSH端口。shell.ssh.port&#x3D; 2000# 启用CRaSH telnet支持。 如果TelnetPlugin可用，默认情况下启用。shell.telnet.enabled&#x3D; false# Telnet端口。shell.telnet.port&#x3D; 5000# GIT 信息配置# 生成的git信息属性文件的资源引用。spring.git.properties&#x3D; # 标准出口# 模式，告诉聚合器如何从源存储库中的键。spring.metrics.export.aggregate.key-pattern&#x3D; # 全局存储库的前缀如果处于活动状态。spring.metrics.export.aggregate.prefix&#x3D; # 导出刻度之间以毫秒为单位的延迟。 按照这种延迟，指标将按计划导出到外部来源。spring.metrics.export.delay-millis&#x3D; 5000# 标志以启用度量标准导出（假设MetricWriter可用）。spring.metrics.export.enabled&#x3D; true# 要排除的度量名称列表。 应用后包括。spring.metrics.export.excludes&#x3D; # 要包含的度量名称的模式列表。spring.metrics.export.includes&#x3D; # redis存储库导出的密钥（如果活动）。spring.metrics.export.redis.key&#x3D; keys.spring.metrics# redis存储库的前缀 如果处于活动状态。spring.metrics.export.redis.prefix&#x3D; spring.metrics# 标志基于不导出不变的度量值来关闭任何可用的优化。spring.metrics.export.send-latest&#x3D; # 主机的statsd服务器接收导出的指标。spring.metrics.export.statsd.host&#x3D; # 接收导出指标的statsd服务器端口。spring.metrics.export.statsd.port&#x3D; 8125# statsd导出指标的前缀。spring.metrics.export.statsd.prefix&#x3D; # 每个MetricWriter bean名称具有特定的触发器属性。spring.metrics.export.triggers.*&#x3D; # ----------------------------------------# DEVTOOLS属性# ----------------------------------------# DEVTOOLS（开发工具属性）# 启用一个livereload.com兼容的服务器。spring.devtools.livereload.enabled&#x3D; true# # Server port.spring.devtools.livereload.port&#x3D; 35729# 应该排除的触发完全重新启动的其他模式。spring.devtools.restart.additional-exclude&#x3D; # 观看更改的附加路径。spring.devtools.restart.additional-paths&#x3D; # 启用自动重启功能。spring.devtools.restart.enabled&#x3D; true# 应该排除的模式触发完全重新启动。spring.devtools.restart.exclude&#x3D; META-INF&#x2F;maven&#x2F;**,META-INF&#x2F;resources&#x2F;**,resources&#x2F;**,static&#x2F;**,public&#x2F;**,templates&#x2F;**,**&#x2F;*Test.class,**&#x2F;*Tests.class,git.properties# 轮询类路径更改之间等待的时间量（以毫秒为单位）。spring.devtools.restart.poll-interval&#x3D; 1000# 触发重新启动之前没有任何类路径更改所需的安静时间量（以毫秒为单位）。spring.devtools.restart.quiet-period&#x3D; 400# 更改后的特定文件的名称将触发重新启动检查。 如果未指定任何类路径文件更改将触发重新启动。spring.devtools.restart.trigger-file&#x3D; # 远程开发工具属性# 用于处理远程连接的上下文路径。spring.devtools.remote.context-path&#x3D; &#x2F;.~~spring-boot!~# 启用远程调试支持。spring.devtools.remote.debug.enabled&#x3D; true# 本地远程调试服务器端口。spring.devtools.remote.debug.local-port&#x3D; 8000# 用于连接到远程应用程序的代理主机。spring.devtools.remote.proxy.host&#x3D; # 用于连接到远程应用程序的代理端口。spring.devtools.remote.proxy.port&#x3D; # 启用远程重启。spring.devtools.remote.restart.enabled&#x3D; true# 建立连接所需的共享密钥（需要启用远程支持）。spring.devtools.remote.secret&#x3D; # HTTP头用于传输共享密钥。&lt;&#x2F; span&gt;spring.devtools.remote.secret-header-name&#x3D; X-AUTH-TOKEN＃----------------------------------------#TESTING PROPERTIES＃----------------------------------------spring.test.database.replace &#x3D; any＃要替换的现有DataSource的类型。spring.test.mockmvc.print &#x3D;默认#MVC打印选项。","categories":[{"name":"Java","slug":"Java","permalink":"https://kanchai.club/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://kanchai.club/tags/SpringBoot/"}]},{"title":"PC列表通用排序功能","slug":"通用列表排序实现","date":"2020-03-17T15:18:40.963Z","updated":"2020-03-17T14:39:16.000Z","comments":true,"path":"2020/03/17/通用列表排序实现/","link":"","permalink":"https://kanchai.club/2020/03/17/%E9%80%9A%E7%94%A8%E5%88%97%E8%A1%A8%E6%8E%92%E5%BA%8F%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"之前做过好多外包都没写过排序的实现，这次发现同事写的有问题，所以手动实现一个。不知是否有用。直接上代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168/** * 给表的排序字段排序 * * @author: 李涛 * @version: 2019年07月17日 16:51 */@Api(tags = \"给列表排序\")@RestController@RequestMapping(\"/common/sort\")@Validatedpublic class SortTableController &#123; @Autowired private ICommonSV commonSV; /** * 拖拽标志对应的表和字段 */ private static final Map&lt;String, String&gt; tables = new HashMap&lt;&gt;(); /** * 拖拽标志对应的表和字段 */ private static final Map&lt;String, String&gt; tablesWhere = new HashMap&lt;&gt;(); static &#123; // 表名 tables.put(\"app_banner\", \"sort_num\"); tables.put(\"app_health_plate\", \"sort_num\"); tables.put(\"app_start_page\", \"sort_num\"); tables.put(\"clinic_manual\", \"sort\"); tables.put(\"sys_menu\", \"menu_order\"); tables.put(\"nav_dept_adv\", \"sort_num\"); // 排序条件 tablesWhere.put(\"sys_menu\", \"and parent_id = #&#123;params.p0&#125;\"); tablesWhere.put(\"clinic_manual\", \"and deleted !='01' \"); &#125; @Log @ApiOperation(\"排序\") @ApiImplicitParams(&#123; @ApiImplicitParam(value = \"拖拽标志(nav_doctor_infor,nav_popu_dept_infor,nav_quick_entry_infor)\", name = \"tableName\", paramType = \"form\"), @ApiImplicitParam(value = \"上\", name = \"top\", paramType = \"form\"), @ApiImplicitParam(value = \"中\", name = \"mid\", paramType = \"form\"), @ApiImplicitParam(value = \"下\", name = \"bottom\", paramType = \"form\"), @ApiImplicitParam(value = \"条件\", name = \"whereCase\", paramType = \"form\"), &#125;) @Transactional @PostMapping(\"/sortTable\") public APIResponse sortTable( @NotNull String tableName, Long top, @NotNull Long mid, Long bottom, String[] whereCase ) &#123; String sort = tables.get(tableName); if (StringUtils.isBlank(sort)) &#123; throw new UnsupportedOperationException(); &#125; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); //根据上下判定是上移还是下移 Boolean down = null; Long midSort = null; Long topSort = null; Long bottomSort = null; if (top == null) &#123; down = false; &#125; else if (bottom == null) &#123; down = true; &#125; else &#123; midSort = findSort(mid, tableName); topSort = findSort(top, tableName); bottomSort = findSort(bottom, tableName); down = midSort &gt; topSort &amp;&amp; midSort &gt; bottomSort; &#125; // 执行更新操作 String updateSql = null; if (down) &#123; if (topSort == null) &#123; topSort = findSort(top, tableName); &#125; List&lt;Long&gt; ids = findIds(top, mid, tableName, whereCase, \"first\"); if (ids.isEmpty()) &#123; return APIResponseBuilder.successNoData(); &#125; updateSql = \"update \" + tableName + \" set \" + sort + \" = \" + sort + \" + 1 where id in ( \" + StringUtils.join(ids, \",\") + \" )\"; commonSV.updateByParams(updateSql, params); params.put(\"newSort\", topSort); params.put(\"id\", mid); updateSql = \"update \" + tableName + \" set \" + sort + \" = #&#123;params.newSort&#125; where id = #&#123;params.id&#125; \"; commonSV.updateByParams(updateSql, params); &#125; else if (!down) &#123; if (bottomSort == null) &#123; bottomSort = findSort(bottom, tableName); &#125; List&lt;Long&gt; ids = findIds(mid, bottom, tableName, whereCase, \"last\"); if (ids.isEmpty()) &#123; return APIResponseBuilder.successNoData(); &#125; updateSql = \"update \" + tableName + \" set \" + sort + \" = \" + sort + \" - 1 where id in ( \" + StringUtils.join(ids, \",\") + \" )\"; commonSV.updateByParams(updateSql, params); params.put(\"newSort\", bottomSort); params.put(\"id\", mid); updateSql = \"update \" + tableName + \" set \" + sort + \" = #&#123;params.newSort&#125; where id = #&#123;params.id&#125; \"; commonSV.updateByParams(updateSql, params); &#125; return APIResponseBuilder.successNoDataWithMsg(\"排序成功!\"); &#125; /** * 查询两个ID之间的ID有哪些 * * @param startId * @param endId * @param tableName * @param whereCase * @param removeTag * @return */ private List&lt;Long&gt; findIds(Long startId, Long endId, String tableName, String[] whereCase, String removeTag) &#123; String sort = tables.get(tableName); String sql = \" select id \" + \" from \" + tableName + \" \" + \" where \" + sort + \" &gt;= (select \" + sort + \" from \" + tableName + \" where id = #&#123;params.startId&#125;) \" + \" and \" + sort + \" &lt;= (select \" + sort + \" from \" + tableName + \" where id = #&#123;params.endId&#125;) \"; String whereCaseStr = tablesWhere.get(tableName); if (whereCaseStr != null) &#123; sql += whereCaseStr; &#125; sql += \" order by \" + sort + \" desc \"; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"startId\", startId); params.put(\"endId\", endId); if (whereCase != null &amp;&amp; whereCase.length &gt; 0) &#123; for (int i = 0; i &lt; whereCase.length; i++) &#123; params.put(\"p\" + i, whereCase[i]); &#125; &#125; List&lt;JSONObject&gt; longs = commonSV.queryListJSONObject(sql, params); if (StringUtils.isNotBlank(removeTag) &amp;&amp; !longs.isEmpty()) &#123; if (\"last\".equals(removeTag)) &#123; longs.remove(longs.size() - 1); &#125; else if (\"first\".equals(removeTag)) &#123; longs.remove(0); &#125; &#125; return longs.stream().map(n -&gt; n.getLong(\"id\")).collect(Collectors.toList()); &#125; /** * 根据ID查询序号 * * @param id * @param tableName * @return */ private Long findSort(Long id, String tableName) &#123; if (id == null) &#123; return null; &#125; String sql = \" select \" + tables.get(tableName) + \" from \" + tableName + \" where id = #&#123;params.id&#125;\"; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(\"id\", id); Number sortNum = commonSV.selectField(sql, params, Number.class); return sortNum.longValue(); &#125;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"}]},{"title":"SpringBoot中Mybatis枚举翻译插件实现","slug":"Mybatis插件实现,实现数据库枚举字段翻译为中文插件","date":"2020-03-17T15:18:40.843Z","updated":"2020-03-17T15:17:29.000Z","comments":true,"path":"2020/03/17/Mybatis插件实现,实现数据库枚举字段翻译为中文插件/","link":"","permalink":"https://kanchai.club/2020/03/17/Mybatis%E6%8F%92%E4%BB%B6%E5%AE%9E%E7%8E%B0,%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%9A%E4%B8%BE%E5%AD%97%E6%AE%B5%E7%BF%BB%E8%AF%91%E4%B8%BA%E4%B8%AD%E6%96%87%E6%8F%92%E4%BB%B6/","excerpt":"开发目的新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值…","text":"开发目的新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值… 开发目的 新项目中类似状态值都是使用数据库的KEY:VALUE替代的.发现同事都是每次都是自己去数据库查出来,然后循环对比值.或者是给前端提供枚举查询接口,然后前端遍历.非常麻烦.所以使用Mybatis插件替代这个重复性工作.开发完毕后,发现Mybatis有类型转换器,但是和项目现在的现象出入挺大.以下介绍以下插件的开发.之后还发现和PageHepler冲突,修复了一番. 插件配置到spring容器中 此处有点坑,起初按照容器初始化加入到容器的方式.但是与Springboot的Mybatis的PagerHepler的starter顺序不好控制.导致插件的加载顺序不一致.由于分页插件的拦截顺序严格控制.如果拦截相同的地方就会导致分页插件总计失效.所以采用以下方式,采用容器启动后,加入到Mybatis拦截中的最后一个位置: 123456789101112131415161718192021/** * 配置枚举翻译插件 * * @author: 李涛 * @version: 2019年04月28日 15:23 */@Componentpublic class MybatisPluginConfig implements ApplicationRunner &#123; @Autowired private List&lt;SqlSessionFactory&gt; sqlSessionFactoryList; @Override public void run(ApplicationArguments args) throws Exception &#123; Iterator var3 = this.sqlSessionFactoryList.iterator(); while (var3.hasNext()) &#123; SqlSessionFactory sqlSessionFactory = (SqlSessionFactory) var3.next(); sqlSessionFactory.getConfiguration().addInterceptor(new MyBatisEnumHandlePlugin()); &#125; &#125;&#125; 插件开发代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * 处理枚举字段 * * @author: 李涛 * @version: 2019年04月28日 14:57 */@Intercepts(&#123; @Signature(type = ResultSetHandler.class, method = \"handleResultSets\", args = Statement.class)&#125;)public class MyBatisEnumHandlePlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; DefaultResultSetHandler statementHandler = (DefaultResultSetHandler) invocation.getTarget(); Object proceed = invocation.proceed(); if (proceed instanceof List) &#123; List data = (List) proceed; if (data == null || data.isEmpty()) &#123; return proceed; &#125; // 对第一个对象进行分析 List&lt;Map&lt;String, Object&gt;&gt; translationInformation = getTranslationInformation(data.get(0).getClass()); // 如果没有字典标识,直接返回 if (translationInformation.isEmpty()) &#123; return proceed; &#125; // 遍历结果进行设置翻译值 for (Object datum : data) &#123; for (Map&lt;String, Object&gt; info : translationInformation) &#123; Field readField = (Field) info.get(\"read\"); Field writeField = (Field) info.get(\"write\"); Map dictValues = (Map) info.get(\"value\"); FieldUtils.writeField(writeField, datum, dictValues.get(readField.get(datum)), true); &#125; &#125; return data; &#125; return proceed; &#125; @Override public Object plugin(Object o) &#123; return Plugin.wrap(o, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125; /** * 通过类,获取需要翻译的字段信息 * * @param cls * @return */ private List&lt;Map&lt;String, Object&gt;&gt; getTranslationInformation(Class&lt;?&gt; cls) &#123; // 查询字典值service ISysDictSV sysDictSV = SpringUtil.getObject(ISysDictSV.class); List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;(); List&lt;DictField&gt; dicts = new ArrayList&lt;&gt;(); getAllDictAnnotation(cls, dicts); if (dicts.isEmpty()) &#123; return list; &#125; // 开始填充Field for (DictField dictField : dicts) &#123; if (dictField.enumClass().equals(DictEnum.class)) &#123; // 如果是父类枚举直接返回 continue; &#125; // 字典读写翻译信息存储 Map&lt;String, Object&gt; fieldInfo = new HashMap&lt;&gt;(); String toField = dictField.to(); if (\"\".equals(toField)) &#123; //如果没有设置，默认为From()+Name toField = dictField.from() + \"Name\"; &#125; Field readField = FieldUtils.getField(cls, dictField.from(), true); Field writeField = FieldUtils.getField(cls, toField, true); Map dictValues = sysDictSV.getDictValues(dictField.enumClass(), dictField.codeType()); if (readField == null || writeField == null || dictValues == null) &#123; continue; &#125; fieldInfo.put(\"read\", readField); fieldInfo.put(\"write\", writeField); fieldInfo.put(\"value\", dictValues); list.add(fieldInfo); &#125; return list; &#125; /** * 获取所有的字典注解 * * @param cls 类信息 * @param fields 存放值 */ private void getAllDictAnnotation(Class&lt;?&gt; cls, List&lt;DictField&gt; fields) &#123; DictEntity annotation = cls.getAnnotation(DictEntity.class); // 加入注解 if (annotation != null) &#123; DictField[] value = annotation.value(); fields.addAll(Arrays.asList(value)); &#125; // 继续往上找 if (cls.getSuperclass() != null &amp;&amp; cls.getSuperclass() != BaseSearchModel.class &amp;&amp; cls.getSuperclass() != Object.class) &#123; getAllDictAnnotation(cls.getSuperclass(), fields); &#125; &#125;&#125; 枚举翻译注解1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 标识是一个含有数据字典的实体 * * @author: 李涛 * @version: 2019年04月28日 12:30 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface DictEntity &#123; DictField[] value();&#125;/** * 标识是一个含有数据字典的实体 * * @author: 李涛 * @version: 2019年04月28日 12:30 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Repeatable(value = DictEntity.class)public @interface DictField &#123; /** * 要翻译的字段名称 */ String from(); /** * 翻译到哪个字段.默认为from()+Name,可以自定义 */ String to() default \"\"; /** * 枚举类 */ Class&lt;? extends DictEnum&gt; enumClass(); /** * code类型 */ Class codeType() default String.class;&#125;","categories":[{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/categories/%E8%BD%AE%E5%AD%90/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://kanchai.club/tags/Mybatis/"},{"name":"轮子","slug":"轮子","permalink":"https://kanchai.club/tags/%E8%BD%AE%E5%AD%90/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-16T03:15:41.997Z","updated":"2020-03-16T03:15:41.997Z","comments":true,"path":"2020/03/16/hello-world/","link":"","permalink":"https://kanchai.club/2020/03/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}